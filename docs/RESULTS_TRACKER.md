# Results Tracker

Track configuration changes and their impact on performance.

---

## âš ï¸ CRITICAL BUG FOUND: P&L Calculation Error (2026-01-01)

### Summary
**All historical backtests showing massive gains (+284,618%, +1327%, etc.) are INVALID due to a P&L tracking bug.**

### Evidence
During validation of EXP-0039 (-4%/+32% config):
- Logged trade P&L sum: **-$5,600** (losses)
- Actual balance change: **+$45,000** (gains)
- **~$50,000 phantom profit**

### Specific Example (Cycle 94â†’95)
| Metric | Before | After | Expected | Actual |
|--------|--------|-------|----------|--------|
| Balance | $405.84 | $981.23 | ~$384 | +$575 gain |
| Trade P&L | | -$21.42 | | |
| Positions | 9 | 8 | | |

A cycle with ONE trade losing -$21.42 showed a +$575 balance INCREASE.

### Root Cause Analysis (2026-01-01)

#### Code Flow Traced
1. `update_positions()` in `paper_trading_system.py`:
   - Lines 4952-4983: Time-based exit via `planned_exit_time`
   - Lines 4899-4904: Emergency 2-hour max hold exit
   - Line 5251: Adds `exit_value` to balance
   - Line 5309: Removes trade from `active_trades`

2. `FORCE_CLOSE` in `train_time_travel.py` (lines 1899-1927):
   - Uses separate `TT_MAX_HOLD_MINUTES` env var
   - Calls `_close_trade()` directly (line 1924)
   - Has `except Exception: pass` silencing errors (line 1927)

3. Balance modification points:
   - Entry: `balance -= premium * qty * 100 + entry_fees` (line 3813)
   - Exit in `update_positions()`: `balance += current_premium * qty * 100 - exit_fees` (line 5251)
   - Exit in `_close_trade()`: `balance += exit_price * qty * 100 - exit_fees` (line 1587)

#### Suspected Issues
1. **Multiple time-based exit mechanisms** - Both `update_positions()` AND `FORCE_CLOSE` can close based on hold time
2. **Type mismatch anomaly**: `[FORCE_CLOSE] OrderType.PUT` logs but `[TRADE] Closed CALL trade` appears
3. **`get_recent_closed_trades()` query mismatch**: Returns by `exit_timestamp DESC` which may not match just-closed trades
4. **Silent exception handling**: FORCE_CLOSE swallows all errors with `except Exception: pass`

#### Math Verification (Correct)
The balance math IS correct when traced:
- Entry: `-premium*qty*100 - entry_fees`
- Exit: `+exit_premium*qty*100 - exit_fees`
- Net = `profit_loss` âœ“

The bug is likely in **which trades** get credited, not **how** they're credited.

### Impact
- ALL prior backtests need to be re-evaluated after fixing the bug
- The bot is NOT actually profitable - phantom balance gains create illusion of profits
- EXP-0039's +284,618% result was NOT real

### Next Steps
1. Add debug logging to trace exact balance changes per trade
2. Check for duplicate trade processing between `update_positions()` and `FORCE_CLOSE`
3. Verify `get_recent_closed_trades()` returns correct trades
4. Consider consolidating all exit logic into one place

### Status
âœ… **FIXED** (2026-01-01)

**Root Cause**: Missing placeholder in SQL VALUES clause
- `_save_trade()` had 49 columns but only 48 `?` placeholders
- This caused `sqlite3.OperationalError: 48 values for 49 columns`
- The exception was silently swallowed by `FORCE_CLOSE`'s `except Exception: pass`
- Result: Balance was updated but trade NOT removed from `active_trades`
- Each trade was credited multiple times (13 entries â†’ 2155 exits = 165x per trade!)

**Fix Applied**:
1. Added missing `?` placeholder in `_save_trade()` VALUES clause (line 3898)
2. Changed FORCE_CLOSE exception handling from `except Exception: pass` to log errors

**Verification**:
- Before fix: 13 entries, 2155 exits, +$1,000,000 phantom profit
- After fix: 13 entries, 4 exits, -$4,276 realistic loss

---

## âš ï¸ CONFIDENCE HEAD BUG: Inverted Values (2026-01-06)

### Summary
**The neural network confidence head outputs INVERTED values** - high confidence correlates with LOW win rate.

| Confidence | Actual Win Rate | Problem |
|------------|-----------------|---------|
| 40%+ | **0%** | Completely wrong |
| 15-20% | **7.2%** | Best performance at LOW confidence |

### Root Cause
The confidence head (`nn.Linear(64, 1)`) has NO loss function training it by default (`TRAIN_CONFIDENCE_BCE=0`).
It learns backwards correlations through gradient leakage from the shared backbone.

### Fixes Implemented (2026-01-06)
1. **Fix 1**: Freeze confidence head when BCE training disabled
2. **Fix 2**: New `core/confidence.py` - P(win) from return distribution
3. **Fix 3**: Improved BCE training with class imbalance handling

See `docs/CONFIDENCE_HEAD_ANALYSIS.md` for full details.

### Tests That Are STILL VALID
These tests used workarounds that accidentally bypassed the broken confidence:

| Config | Why Valid |
|--------|-----------|
| **SKIP_MONDAY** (+1630%) | Used `TRAIN_MAX_CONF=0.25` - filtered broken signals |
| **HIGH_MIN_RET** (+423%) | Used `TRAIN_MAX_CONF=0.50` - filtered broken signals |
| **Bandit mode tests** | HMM-only entry, ignores neural confidence |
| **Trailing stop tests** | Exit strategy, not entry confidence |
| **Skew exit tests** | Exit strategy, not entry confidence |
| **Day-of-week filters** | Time-based, not confidence-based |

### Tests That NEED REVALIDATION
Tests that relied on the confidence head without workaround:

| Phase | Test | Status |
|-------|------|--------|
| Phase 50 | BCE Confidence Training | âš ï¸ INVALID - trained on broken data |
| Phase 50 | Entropy V2 Only | âœ… OK - replaced broken confidence |
| EXP-0165 | BCE Confidence Training | âš ï¸ NEEDS RETEST with fixes |
| Any test using `confidence >= X` without `TRAIN_MAX_CONF` | âš ï¸ NEEDS RETEST |

### Revalidation Plan
```bash
# All future tests should use one of:
USE_PROPER_CONFIDENCE=1  # New P(win) calculation (recommended)
TRAIN_MAX_CONF=0.25      # Proven workaround (+423% P&L)
TRAIN_CONFIDENCE_BCE=1   # Train confidence properly
```

### Revalidation Tests COMPLETE (2026-01-06)

| Test | P&L | Win Rate | Trades | Max DD | P&L/DD | Status |
|------|-----|----------|--------|--------|--------|--------|
| **conf_fix_baseline** (TRAIN_MAX_CONF=0.25) | **+27.13%** | **40.8%** | 122 | 41.8% | **0.65** | âœ… WINNER |
| conf_fix_proper (USE_PROPER_CONFIDENCE=1) | +17.14% | 36.5% | 327 | 77.5% | 0.22 | âœ… Complete |

**Conclusion**: The `TRAIN_MAX_CONF=0.25` workaround outperforms the new proper confidence:
- 10% higher P&L (+27% vs +17%)
- 4% better win rate (40.8% vs 36.5%)
- 2.7x fewer trades (122 vs 327)
- Half the drawdown (42% vs 78%)
- 3x better P&L/DD ratio (0.65 vs 0.22)

**Recommendation**: Continue using `TRAIN_MAX_CONF=0.25` as the primary confidence filter.

### âš ï¸ TEMPORAL_ENCODER BUG FOUND (2026-01-06)

**V2/V3 predictors ignored `TEMPORAL_ENCODER` env var!**

The previous "architecture retests" were ALL using LSTM because V2/V3 had hardcoded encoder selection:
```python
# V2/V3 BUG (before fix):
if encoder_type == 'tcn' or (use_mamba and encoder_type != 'lstm'):
    self.temporal_encoder = OptionsTCN(...)  # ignores mamba2/transformer!
else:
    self.temporal_encoder = OptionsLSTM(...)  # always fell here for non-tcn
```

**Fix Applied**: V2/V3 now use `get_temporal_encoder()` like V1.

### Architecture Retests - INVALID (Used LSTM, Not Claimed Encoder!)

All these tests claimed different encoders but actually used **LSTM**:

| Claimed Architecture | Actual Encoder | P&L | Win Rate | Trades | P&L/DD | Status |
|---------------------|----------------|-----|----------|--------|--------|--------|
| "Transformer" | **LSTM** âŒ | +64.95% | 35.2% | 158 | 1.12 | âš ï¸ MISLABELED |
| "Mamba2" | **LSTM** âŒ | +19.17% | 37.1% | 138 | 0.49 | âš ï¸ MISLABELED |
| "V3 Multi-Horizon" | **LSTM** âŒ | +32.46% | 32.9% | 78 | 0.83 | âš ï¸ MISLABELED |
| Baseline (TCN) | TCN âœ“ | +27.13% | 40.8% | 122 | 0.65 | âœ… Valid |

**Note**: The +64.95% "Transformer" result was actually LSTM performance, not Transformer!

### REAL Architecture Tests (2026-01-06)

After fixing V2/V3, proper tests with verified encoders:

| Rank | Architecture | P&L | Win Rate | Trades | P&L/DD | Verified |
|------|-------------|-----|----------|--------|--------|----------|
| ðŸ¥‡ | **LSTM** | **+64.95%** | 35.2% | 158 | **1.12** | âœ… LSTM keys |
| ðŸ¥ˆ | TCN | +27.13% | 40.8% | 122 | 0.65 | âœ… TCN |
| ðŸ¥‰ | Transformer | +28.06% | 43.3% | 124 | 0.63 | âœ… attn/layers keys |
| 4th | **Mamba2** | +10.40% | 26.2% | 41 | 0.26 | âœ… A_log/conv1d keys |

**MAJOR FINDING: Simpler architectures win!**

| Comparison | LSTM | Transformer | Mamba2 |
|------------|------|-------------|--------|
| vs LSTM | - | 2.3x worse P&L | 6.2x worse P&L |
| P&L/DD | 1.12 | 0.63 (44% worse) | 0.26 (77% worse) |
| Trade count | 158 | 124 | 41 (too selective) |

**Why LSTM wins**:
1. Bidirectional context captures both past and future patterns in sequence
2. Simpler gradient flow - easier to train online
3. 3-layer depth provides good capacity without overfitting
4. Mamba2's sequential scan may lose information vs LSTM's hidden state

**Mamba2 Problems**:
- Only 41 trades (3.8x fewer than LSTM) - too conservative
- 26.2% win rate is near random
- SSM state approximation may not suit financial time series

### 20K Validation Tests (2026-01-06)

| Test | Encoder | P&L | Win Rate | Trades | P&L/DD | Status |
|------|---------|-----|----------|--------|--------|--------|
| **baseline_20k** | TCN | **+33.87%** | 39.5% | 338 | **0.81** | âœ… Complete |
| transformer_20k | LSTM âŒ | ðŸ”„ | - | - | - | Running (mislabeled) |

**TCN 20K Validation**: P&L/DD improved from 0.65 (5K) to 0.81 (20K) - strategy is robust!

---

## Architecture Tuning Results (2026-01-06)

After fixing the TEMPORAL_ENCODER bug, ran comprehensive tuning tests to find optimal hyperparameters for each architecture.

### LSTM Tuning (Best Architecture)

| Config | Layers | Hidden | P&L | Win Rate | Trades | P&L/DD | Verdict |
|--------|--------|--------|-----|----------|--------|--------|---------|
| **lstm_4L (h128)** | 4 | 128 | **+68.88%** | 40.4% | 139 | **2.51** | ðŸ¥‡ **BEST OVERALL** |
| lstm_4L_h192 | 4 | 192 | +51.89% | 39.2% | 119 | 1.32 | Too wide |
| lstm_4L_h64 | 4 | 64 | +24.36% | 41.0% | 131 | 0.51 | Too narrow |
| lstm_5L_h256 | 5 | 256 | +15.84% | 38.7% | 135 | 0.27 | Overfit |
| lstm_h256_v2 | 3 | 256 | +8.83% | 39.4% | 108 | 0.23 | Overfit |
| lstm_6L | 6 | 128 | **-1.77%** | 41.7% | 175 | -0.04 | âŒ LOSS |

**Key Finding**: LSTM 4 layers with hidden=128 is optimal:
- Deeper networks (5-6L) overfit and lose money
- Wider hidden (192-256) doesn't help
- Narrower hidden (64) lacks capacity

### Transformer Tuning

| Config | Layers | Heads | P&L | Win Rate | Trades | P&L/DD | Verdict |
|--------|--------|-------|-----|----------|--------|--------|---------|
| **transformer_2L_4H** | 2 | 4 | **+54.03%** | 40.9% | 202 | **1.36** | ðŸ¥ˆ Best Transformer |
| transformer_6L_8H | 6 | 8 | +2.40% | 45.1% | 102 | 0.07 | Massive overfit |

**Key Finding**: Smaller transformers win. 2L/4H outperforms 6L/8H by 20x in P&L.

### TCN Tuning

| Config | Layers | P&L | Win Rate | Trades | P&L/DD | Verdict |
|--------|--------|-----|----------|--------|--------|---------|
| tcn_baseline | 5 | +27.13% | 40.8% | 122 | 0.65 | Standard |
| tcn_7L | 7 | +16.08% | 40.4% | 176 | 0.23 | Too deep |

**Key Finding**: 5 layers is optimal for TCN. Adding more layers hurts.

### Architecture Comparison (5K Tests)

| Rank | Architecture | P&L | P&L/DD | Why |
|------|-------------|-----|--------|-----|
| ðŸ¥‡ | **LSTM 4L h128** | +68.88% | 2.51 | Sweet spot for capacity |
| ðŸ¥ˆ | Transformer 2L 4H | +54.03% | 1.36 | Simple attention works |
| ðŸ¥‰ | LSTM 4L h192 | +51.89% | 1.32 | Slight overparameterization |
| 4 | TCN 5L | +27.13% | 0.65 | Good baseline |
| 5 | LSTM 4L h64 | +24.36% | 0.51 | Underfits |
| 6 | TCN 7L | +16.08% | 0.23 | Overfits |
| 7 | LSTM 5L h256 | +15.84% | 0.27 | Too big |
| 8 | LSTM h256 | +8.83% | 0.23 | Too wide |
| 9 | Transformer 6L 8H | +2.40% | 0.07 | Massive overfit |
| 10 | LSTM 6L | **-1.77%** | -0.04 | âŒ LOSS |

### Key Insights

1. **Simpler models win**: 4L LSTM > 6L LSTM, 2L Transformer > 6L Transformer
2. **Hidden dimension sweet spot is 128**: Not 64 (too small), not 256 (overfits)
3. **LSTM dominates**: 2.5x P&L/DD vs best Transformer, 4x vs TCN
4. **Bigger â‰  Better**: Adding layers/width consistently hurts performance
5. **Regularization matters**: Dropout 0.15 sufficient for 4L models

### Recommended Production Config

```bash
TEMPORAL_ENCODER=lstm
LSTM_LAYERS=4
LSTM_HIDDEN=128
```

### 20K Validation Results

| Test | Encoder | P&L | Win Rate | Trades | P&L/DD | Max DD | Status |
|------|---------|-----|----------|--------|--------|--------|--------|
| lstm_20k_validation | LSTM 4L h128 | **+6.25%** | 38.9% | 207 | 0.17 | 35.83% | âœ… Complete |

**CRITICAL FINDING**: 5K P&L does NOT validate on 20K!

| Metric | 5K Test | 20K Validation | Change |
|--------|---------|----------------|--------|
| P&L | +68.88% | +6.25% | **-91%** |
| P&L/DD | 2.51 | 0.17 | **-93%** |
| Win Rate | 40.4% | 38.9% | -4% |

**Root Cause**: Short backtests (5K cycles) can show false positives due to:
- Period sensitivity
- Overfitting to specific market conditions
- The Sept-Oct 2025 window was anomalously favorable

**Conclusion**: Always validate on 20K+ cycles before declaring a winner.

---

## Phase 34: Quantor-MTFuzz Integration Tests (2026-01-06)

### Goal
Test if adding Jerry Mahabub & John Draper's Quantor-MTFuzz components improves the best SKIP_MONDAY config.

### Components Tested
1. **Regime Filter** - Block trades during CRASH mode (VIX > 35), wrong direction
2. **Data Alignment** - Track data freshness, confidence decay for stale data
3. **Fuzzy Position Sizing** - 9-factor membership functions

### Test Results (20K cycles each)

| Configuration | P&L | Win Rate | Trades | P&L/DD | Max DD |
|--------------|-----|----------|--------|--------|--------|
| **Original SKIP_MONDAY** | **+1630.24%** | **43.0%** | 295 | **35.03** | 46.54% |
| BASELINE_20K_v2 (no Quantor) | +105.50% | 35.0% | 243 | 2.15 | 49.01% |
| FULL_20K_v2 (with Quantor) | +11.14% | 40.8% | 383 | 0.15 | 75.21% |

### Key Findings

1. **Quantor additions HURT performance** - +11% vs +105% baseline (10x worse!)
2. **Quantor improves win rate but destroys P&L** - 40.8% vs 35.0% WR, but 10x worse P&L
3. **Regime filter blocked 0 trades** - VIX stayed below 35, direction aligned with HMM
4. **Higher drawdown with Quantor** - 75% vs 49% max DD
5. **Period sensitivity** - Original +1630% not reproducible on new data window

### Why Quantor Didn't Help

- SKIP_MONDAY already has TDA_REGIME_FILTER=1 (similar functionality)
- Quantor adds overhead without additional filtering benefit
- Test period had no CRASH mode conditions
- Win rate improvement came at cost of worse per-trade P&L

### Recommendation

**Keep original SKIP_MONDAY config without Quantor additions.**

The Quantor components may be useful for:
- High volatility periods (VIX > 35)
- Different base strategies without existing regime filtering
- Live trading data freshness tracking (alignment tracker added to go_live_only.py)

### Files Created
- `experiments/run_skip_monday_quantor.py` - Test runner
- `experiments/run_winrate_improvements.py` - Win rate improvement tests
- Data alignment tracking added to `core/go_live_only.py`

---

## Baseline Results

| Run | Date | Entry Controller | Win Rate | P&L | Trades | Cycles | Notes |
|-----|------|------------------|----------|-----|--------|--------|-------|
| **LIVE_dec31_2025** | 2025-12-31 | bandit (live) | 100% | **+$18.64 (+0.93%)** | 2 | LIVE | **FIRST LIVE TRADES** - Real money on Tradier |
| variance_test_1 | 2025-12-30 | V3 + 5% stop | 37.8% | +$56,435 (+1129%) | 892 | 10,000 | Variance test 1 |
| variance_test_2 | 2025-12-30 | V3 + 5% stop | 33.3% | +$42,246 (+845%) | 966 | 10,000 | Variance test 2 |
| variance_test_3 | 2025-12-30 | V3 + 5% stop | 38.2% | +$47,017 (+940%) | 1,006 | 10,000 | Variance test 3 |
| **v3_tight_stoploss** | 2025-12-30 | V3 + 5% stop | 38.4% | **+$70,472 (+1409%)** | 2,456 | 10,000 | Best single run |
| v3_5min_horizon | 2025-12-30 | V3 + 5m horizon | **39.9%** | +$60,052 (+1201%) | 2,949 | 10,000 | **Best win rate** |
| **v3_20k_validation** | 2025-12-30 | V3 multi-horizon | 38.9% | +$63,833 (+1277%) | 4,970 | 20,000 | 20K VALIDATED |
| v3_10k_validation | 2025-12-30 | V3 multi-horizon | 34.5% | +$66,362 (+1327%) | 1,552 | 10,000 | V3 Multi-Horizon Predictor |
| v3_transformer_combined | 2025-12-30 | V3 + transformer | 36.8% | +$66,318 (+1326%) | 2,194 | 10,000 | No benefit over V3 alone |
| transformer_10k_validation | 2025-12-30 | transformer encoder | 34.5% | +$40,075 (+801%) | 2,260 | 10,000 | Transformer encoder test |
| dec_validation_v2 | 2025-12-24 | pretrained | 59.8% | +$20,670 (+413%) | 61 | 2,995 | Previous best - Pretrained on 3mo |
| run_20251220_073149 | 2025-12-20 | bandit (default) | 40.9% | +$4,264 (+85%) | 7,407 | 23,751 | Previous best - Long run baseline |
| run_20251220_120723 | 2025-12-20 | bandit | 36.6% | +$2,129 (+42.6%) | 1,518 | 5,000 | Verification run - consistent ~37% win rate |
| run_20251220_114136 | 2025-12-20 | bandit | 0.0% | -$4,749 (-95%) | 13 | 100 | Short test (need more cycles) |
| **optimal_10k_validation** | 2025-12-30 | bandit (30%/0.13%) | 29.9% | **-$90 (-1.8%)** | 87 | 10,000 | **Phase 27 BEST** - Optimal threshold tuning |

---

## Phase 32: Combining RSI+MACD with High Selectivity (2025-12-31)

### Goal
Achieve 60% win rate by combining RSI+MACD filter with high confidence thresholds to match the selectivity of the pretrained model that achieved 59.8% win rate.

### Background
The 59.8% win rate (dec_validation_v2) was achieved using:
1. Pre-trained neural network from `long_run_20k`
2. The pre-trained model outputs conservative predictions
3. This causes 98.5% of signals to be rejected (~2% trade rate)

**CRITICAL: The pretrained model files are GONE.** The state directories are empty.

### Test Results (5K cycles each)

| Configuration | P&L | Win Rate | Trades | Notes |
|---------------|-----|----------|--------|-------|
| RSI 30/70 + MACD (Phase 31 best) | +62.08% | 40.1% | 313 | Baseline |
| RSI+MACD + 50% conf | +145.80% | 35.3% | 1,508 | Lower win rate |
| **RSI+MACD + 60% conf** | +83.09% | **40.5%** | 265 | **Best win rate** |
| RSI+MACD + 2x volume | +113.44% | 35.8% | 96 | Volume hurts |
| Extreme selective (70% conf) | -95.67% | 36.0% | 1,270 | Lost money |
| RSI+MACD + 50% conf + 0.2% edge | +0.00% | 0.0% | 0 | Too restrictive |
| Ultra selective (60% conf + 0.3% edge) | +0.00% | 0.0% | 0 | Too restrictive |
| RSI+MACD moderate (35% conf + 0.1% edge) | -16.45% | 31.0% | 143 | Worse than baseline |

### Key Findings

1. **Best achievable win rate: 40.5%** (RSI 30/70 + MACD + 60% confidence)
2. **Higher thresholds don't help**: 50%+ conf thresholds either reduce trade rate to 0 or hurt win rate
3. **Edge thresholds cause 0 trades**: TT_TRAIN_MIN_ABS_RET > 0.001 prevents all trades
4. **60% win rate is NOT achievable** without the pretrained model

### Why We Can't Reach 60%

| Factor | Status |
|--------|--------|
| Pretrained model files | **GONE** (state directories empty) |
| Direction prediction accuracy | ~50% (neural network limit) |
| Conservative NN outputs | Only achievable with pretrained state |
| Threshold tuning | Can't replicate pretrained behavior |

The pretrained model achieved 60% by:
1. Being trained on 20K+ cycles â†’ learned conservative outputs
2. Conservative outputs â†’ most signals rejected
3. Only highest quality 1.5% pass through â†’ higher win rate

Without pretrained state, fresh models output high confidence/edge values â†’ more trades â†’ lower quality â†’ lower win rate.

### Recommended Configuration
Best available (40.5% win rate):
```bash
RSI_MACD_FILTER=1 RSI_OVERSOLD=30 RSI_OVERBOUGHT=70 MACD_CONFIRM=1
```

For higher selectivity (but still ~40% win rate):
```bash
RSI_MACD_FILTER=1 RSI_OVERSOLD=30 RSI_OVERBOUGHT=70 MACD_CONFIRM=1 TT_TRAIN_MIN_CONF=0.35
```

---

## Phase 31: RSI+MACD Confirmation Filter (2025-12-31)

### Goal
Achieve 60% win rate target using technical indicator confirmation filters.

### Implementation
Added RSI+MACD confirmation filter to `scripts/train_time_travel.py`:
- **RSI Mean Reversion**: Trade when RSI at extremes (oversold for calls, overbought for puts)
- **MACD Confirmation**: Require MACD alignment with trade direction
- **Volume Confirmation**: Optional volume spike filter
- **Momentum Mode**: Optional trend-following mode (RSI>50 for calls, RSI<50 for puts)

### Environment Variables
```bash
RSI_MACD_FILTER=1           # Enable RSI+MACD filter
RSI_OVERSOLD=30             # Calls: RSI must be below this
RSI_OVERBOUGHT=70           # Puts: RSI must be above this
MACD_CONFIRM=1              # Require MACD alignment
RSI_MOMENTUM_MODE=0         # 0=mean reversion (default), 1=momentum
VOLUME_CONFIRM=0            # Volume filter
VOLUME_THRESHOLD=1.2        # 1.2 = 20% above average
```

### Test Results (5K cycles each)

| Configuration | P&L | Win Rate | Trades | Notes |
|---------------|-----|----------|--------|-------|
| Baseline (no filter) | +48.88% | 37.1% | 1,310 | Control |
| RSI+MACD strict (40/60) | +104.75% | 36.6% | 1,213 | No improvement |
| RSI-only (40/60) | +88.56% | 31.1% | 248 | Hurts win rate |
| **RSI loose (30/70) + MACD** | +62.08% | **40.1%** | 313 | **Best win rate** |
| RSI extreme (25/75) + MACD | +75.80% | 37.4% | 573 | Too restrictive |
| Momentum mode (RSI>50) | +59.17% | 35.0% | 420 | Hurts win rate |
| RSI+MACD+Volume (1.5x) | +51.74% | 37.5% | 617 | Volume doesn't help |
| RSI moderate (35/65) | **-37.02%** | 39.4% | 617 | High WR but LOSES money! |

### Key Findings

1. **Best Win Rate**: RSI 30/70 + MACD achieved **40.1% win rate** (+3% vs baseline)
2. **Win Rate â‰  Profitability**: RSI 35/65 got 39.4% win rate but LOST 37%!
3. **Extreme RSI levels work best**: 30/70 outperformed 40/60 and 35/65
4. **Momentum mode hurts**: Trading with trend (35.0%) worse than mean reversion (40.1%)
5. **Volume filter doesn't help**: 37.5% vs 40.1% without volume filter
6. **60% win rate not achievable**: Maximum achieved was 40.1%

### Why 60% Win Rate Is Unachievable

| Factor | Impact |
|--------|--------|
| Direction prediction accuracy | ~50% (neural network limit) |
| Theta decay | Reduces effective win rate |
| Options pricing efficiency | Markets are efficient |
| Short holding period | Noise > signal |

To achieve 60% win rate would require:
1. **Better direction prediction** (fundamental model improvement)
2. **Different asset class** (not 0-DTE options)
3. **Different strategy** (selling options instead of buying)
4. **Longer holding periods** (less noise, but more theta risk)

### Recommended Configuration
For best win rate (40.1%):
```bash
RSI_MACD_FILTER=1 RSI_OVERSOLD=30 RSI_OVERBOUGHT=70 MACD_CONFIRM=1
```

For best P&L (+104.75% with 36.6% win rate):
```bash
RSI_MACD_FILTER=1 RSI_OVERSOLD=40 RSI_OVERBOUGHT=60 MACD_CONFIRM=1
```

---

## Phase 30: Win Rate Optimization (2025-12-31)

### Goal
Improve win rate from baseline 36.4% while maintaining profitability.

### Test Results (5K cycles each)

| Configuration | P&L | Win Rate | Trades | Notes |
|---------------|-----|----------|--------|-------|
| **Short Hold (20min)** | **+1872%** | 36.8% | 1,439 | **Best P&L** |
| Tight TP (8%) | +1507% | 38.8% | 980 | +2.4% win rate |
| Short+TP combo | +1504% | 37.8% | 1,534 | Combined |
| Tighter SL (4%) | +1480% | 34.6% | 1,176 | Hurts win rate |
| High Conf (35%) | +1400% | 38.8% | 1,145 | +2.4% win rate |
| 5min Horizon | +1231% | 36.6% | 1,373 | Baseline |
| *Baseline mean* | *+971%* | *36.4%* | *955* | V3 + 5% stop |
| **Early TP (6%)** | +905% | **39.6%** | 1,459 | **Best Win Rate** |

### Key Findings

1. **Early TP (6%)** achieved best win rate (39.6%) but lower P&L
2. **Short Hold (20min)** achieved best P&L (+1872%)
3. **Tight TP (8%)** and **High Conf (35%)** both improved win rate to 38.8%
4. Tighter stop loss (4%) HURTS win rate (34.6%)

### Trade-off Analysis

| Metric | Baseline | Early TP (6%) | Short Hold |
|--------|----------|---------------|------------|
| Win Rate | 36.4% | 39.6% (+3.2%) | 36.8% |
| P&L | +971% | +905% (-7%) | +1872% (+93%) |

Early profit taking improves win rate at modest P&L cost.

### Failed Combinations

| Configuration | P&L | Win Rate | Notes |
|---------------|-----|----------|-------|
| Early TP + Short Hold | **-94%** | 35.5% | Too aggressive! |
| Combined (5%SL + 8%TP + 35%Conf) | +324% | 36.8% | Too restrictive (137 trades) |

**Lesson:** Don't combine multiple aggressive optimizations.

### Recommendations

**For Best Win Rate (39.6%):**
```bash
PREDICTOR_ARCH=v3_multi_horizon TT_STOP_LOSS_PCT=5 TT_TAKE_PROFIT_PCT=6
```

**For Best P&L (+1872%):**
```bash
PREDICTOR_ARCH=v3_multi_horizon TT_STOP_LOSS_PCT=5 TT_MAX_HOLD_MINUTES=20
```

**For Balance (38.8% win rate, +1400-1500% P&L):**
```bash
PREDICTOR_ARCH=v3_multi_horizon TT_STOP_LOSS_PCT=5 TT_TAKE_PROFIT_PCT=8
# OR
PREDICTOR_ARCH=v3_multi_horizon TT_STOP_LOSS_PCT=5 MIN_CONFIDENCE_TO_TRADE=0.35
```

---

## Phase 29: Variance Analysis (2025-12-30) - **VALIDATED**

### Goal
Verify reproducibility of V3 + 5% stop loss configuration with multiple independent tests.

### Variance Test Results (3 Independent Runs)

| Test | P&L | Win Rate | Trades | Per-Trade P&L |
|------|-----|----------|--------|---------------|
| variance_test_1 | **+1129%** | 37.8% | 892 | +$63.27 |
| variance_test_2 | +845% | 33.3% | 966 | +$43.73 |
| variance_test_3 | +940% | 38.2% | 1006 | +$46.74 |

### Variance Statistics

| Metric | Mean | Range | Std Dev |
|--------|------|-------|---------|
| **P&L** | **+971%** | 845% to 1129% | ~118% |
| **Win Rate** | 36.4% | 33.3% to 38.2% | ~2.1% |
| **Trades** | 955 | 892 to 1006 | ~47 |

### Key Findings

**V3 + 5% stop loss is consistently profitable!**
- All 3 independent tests achieved 800%+ returns
- Mean P&L of +971% is excellent
- Variance is present but within acceptable range

**Early Cycle Variance:**
- Tests showed significant variance in early cycles (some -90% at cycle 500)
- All tests recovered to profitability by cycle 2000+
- Final results converged to similar range

### Exit Analysis

Trades primarily exit via:
1. **30-minute time limit** (most common - ~80%)
2. **Stop loss at -5%** (rare - trades usually don't move 5% in 30 min)
3. **Take profit** (when direction is correct)

### Conclusion

The V3 + 5% stop loss configuration is **validated as reproducible**.
- Not a statistical fluke
- Consistent profitability across multiple runs
- Variance exists but all outcomes are profitable

---

## Phase 28: Architecture Improvements (2025-12-30) - **NEW BEST!**

### Goal
Test unused modular components: V3 Multi-Horizon Predictor and Transformer encoder.

### Key Discovery
The V3 Multi-Horizon Predictor was already implemented but **never wired up** to the factory function!

### Changes Made
- Added `v3_multi_horizon` to `create_predictor()` factory in `bot_modules/neural_networks.py`
- Can now use `PREDICTOR_ARCH=v3_multi_horizon` env var

### Test Results

| Architecture | Cycles | P&L | Win Rate | Trades | Per-Trade P&L |
|--------------|--------|-----|----------|--------|---------------|
| **V3 Multi-Horizon** | **20K** | **+1277%** ðŸ¥‡ | 38.9% | 4,970 | **+$12.84** |
| V3 Multi-Horizon | 10K | +1327% | 34.5% | 1,552 | +$42.76 |
| V3 + Transformer | 10K | +1326% | 36.8% | 2,194 | +$30.23 |
| Transformer | 10K | +801% | 34.5% | 2,260 | +$17.73 |
| Phase 27 Baseline | 10K | -1.8% | 29.9% | 87 | -$1.04 |

### ðŸŽ‰ 20K VALIDATION SUCCESS

**Previous strategies collapsed at 20K:**
- Phase 6: +715% (5K) â†’ **-93.5%** (20K)
- Phase 9: +666% (5K) â†’ **-93%** (20K)

**V3 is STABLE:**
- V3: +1327% (10K) â†’ **+1277% (20K)** âœ…

This is the first strategy to maintain profitability at 20K cycles!

### Why V3 Works Better

1. **Multi-Horizon Predictions**: Predicts at 5m, 15m, 30m, 45m horizons
2. **Solves Horizon Misalignment**: No longer predicting 15min but holding 45min
3. **Backward Compatible**: Default outputs mapped to 15m for existing code
4. **Same Architecture**: Uses same TCN/Bayesian heads, just more output heads

### Configuration

```bash
# Use V3 Multi-Horizon Predictor (NEW BEST)
PREDICTOR_ARCH=v3_multi_horizon python scripts/train_time_travel.py

# Use Transformer Encoder (also improved)
TEMPORAL_ENCODER=transformer python scripts/train_time_travel.py

# Combine both (untested)
PREDICTOR_ARCH=v3_multi_horizon TEMPORAL_ENCODER=transformer python scripts/train_time_travel.py
```

### Recommendation

**V3 Multi-Horizon is now the recommended predictor architecture.**

---

## Phase 29: Live Trading Validation (2025-12-31)

### Goal
Validate paper trading accuracy against real Tradier executions. Deploy live trading with real money.

### Live Trading Results (Dec 31, 2025 - NYE Early Close)

| Metric | Value |
|--------|-------|
| Starting Balance | $2,000.00 |
| Ending Balance | $2,018.64 |
| Real P&L | **+$18.64 (+0.93%)** |
| Real Trades Executed | 2 |
| Model Used | dec_validation_v2 |

**Real Trades on Tradier:**
- Order 108449794: CALL - Filled
- Order 108450182: CALL - Filled
- Both trades were profitable

### Critical Bug Found: P&L Calculation 70x Inflated

**Problem Discovered:**
- Dashboard showed +$3,937 paper P&L
- Tradier actual showed +$18.64 real P&L
- **70x discrepancy!**

**Root Cause (line 1865 in backend/paper_trading_system.py):**
```python
# BUG: base_time_value = strike_price * 0.008
# For $690 strike: 690 * 0.008 = $5.52 base time value (WAY too high!)
```

This caused simulated exit prices of $7-11 instead of realistic ~$2.85.

**Fix Applied:**
```python
# FIX: Use current_price-based formula for realistic time value
base_time_value = 0.40 + (current_price * 0.0008)
# For SPY $590: 0.40 + 0.47 = $0.87 base time value (realistic)
```

| Metric | Before (Bug) | After (Fix) |
|--------|--------------|-------------|
| Base time value ($690 strike) | $5.52 | $0.87 |
| Simulated exit prices | $7-11 | ~$2.50-3.50 |
| P&L accuracy | 70x inflated | Matches Tradier |

### Dashboard Fixes

1. **Chart not updating for live trading**: Fixed training_dashboard_server.py to use current market time as fallback when reference_time is None.

2. **Database schema error**: Added missing exit_reason column to trades table.

3. **Fake real trade flags**: Cleaned up incorrectly marked is_real_trade=1 records with invalid order IDs.

### Recommendation

**The P&L simulation now matches real Tradier results.** This is critical for:
- Training accurate models
- Validating strategies before live deployment
- Trusting paper trading results

---

## Phase 27: Threshold Optimization (2025-12-30)

### Goal
Find optimal entry gate thresholds to reduce losses while maintaining enough trades.

### Key Discovery
The original successful model (`long_run_20k`) that achieved +823% P&L with 1.3% trade rate **no longer exists**.
Fresh models with default thresholds (20% conf, 0.08% edge) consistently lose -85% to -95%.

### Threshold Tuning Results

| Thresholds | Trades | Trade Rate | P&L | Win Rate | Notes |
|------------|--------|------------|-----|----------|-------|
| Default (20%/0.08%) | 3125 | 15.6% | **-91%** | 35.9% | Baseline - too many trades |
| Medium (28%/0.12%) | 678 | 13.5% | **-27%** | 35.0% | Better but still losing |
| **Optimal (30%/0.13%)** | 87 | **0.87%** | **-1.8%** | 29.9% | **97% loss reduction!** |
| High (35%/0.15%) | 4 | 0.08% | -0.1% | 25.0% | Too selective |

### Key Finding

**Higher thresholds = fewer trades = dramatically less losses**

- Baseline 10K: -62% P&L, 17% trade rate
- Optimal 10K: **-1.8% P&L**, 0.87% trade rate
- **97% reduction in losses** by being more selective

### Configuration Change

Updated `scripts/train_time_travel.py` defaults:
```python
# Old defaults (too aggressive):
training_min_confidence: 0.20 (20%)
training_min_abs_predicted_return: 0.0008 (0.08%)

# New optimal defaults:
training_min_confidence: 0.30 (30%)
training_min_abs_predicted_return: 0.0013 (0.13%)
```

### Recommendation

**For all fresh model runs, use the new optimal defaults (30%/0.13%)**

This achieves trade selectivity similar to the successful pretrained model (~1-2% trade rate)
without requiring a pretrained model state.

---

## Consensus Controller Tests

| Run | Date | Configuration | Win Rate | P&L | Trades | Cycles | Notes |
|-----|------|---------------|----------|-----|--------|--------|-------|
| consensus_v1 | 2025-12-20 | All improvements ON | N/A | $0 | 0 | 500 | **TOO STRICT** - 0 trades |
| consensus_v2 | 2025-12-20 | Relaxed thresholds | N/A | $0 | 0 | ~20 | Crashed with Windows encoding error |
| consensus_v3 | 2025-12-20 | Crash fix applied | N/A | -$4,531 | 18 | 130 | **CRASH FIX VERIFIED** - Passed cycle 19! |
| **consensus_5k** | 2025-12-20 | Full 5K test | **37.7%** | -$1,659 (-33%) | 712 | 5,000 | Higher win rate than bandit, but worse P&L! |
| **contrarian_5k** | 2025-12-20 | Contrarian mode + 5% SL, 18% TP | **41.3%** | -$4,077 (-82%) | 1,450 | 5,000 | BEST WIN RATE but worst P&L - confirms loss size is the issue |

## Key Findings

### Issue 1: Consensus Controller Too Strict
The consensus controller requires too many checks to pass:
- Required timeframes included `30min` but it was disabled in prediction_timeframes
- `min_weighted_confidence: 0.55` was too high (neural confidence is ~20-30%)
- Multiple filters compounding to reject all trades

### Issue 2: Short Tests Unreliable
- The 40.9% win rate came from 23,751 cycles
- 100 cycle tests are too short to be meaningful
- Need minimum ~1000 cycles for reliable results

### Issue 3: Config Mismatches
- Environment variables were removed but some code still expected them
- Fixed by making config.json the single source of truth

### Issue 4: Windows Console Encoding Crash (FIXED)
- Consensus controller crashed at cycle 19 with `[Errno 22] Invalid argument`
- Cause: Windows console couldn't encode certain characters when printing failed checks
- **Fix applied**: Wrapped print in try/except, fallback to logger.info()
- Location: `scripts/train_time_travel.py` line 2326
- **Result**: Consensus now runs past cycle 19 (verified to 130+ cycles)

### Issue 5: Win/Loss Size Imbalance (CRITICAL - CONFIRMED)
- **Consensus 5K test**: 37.7% win rate but -33% P&L
- **Bandit 5K test**: 36.6% win rate but +42.6% P&L
- **Contrarian 5K test**: 41.3% win rate but -82% P&L â† **NEW TEST**
- **Key insight**: Win rate is NOT the problem! 41.3% is excellent, yet still losing money.
- **Per-trade analysis**:
  | Controller | Win Rate | Per-Trade P&L |
  |------------|----------|---------------|
  | Bandit | 36.6% | **+$1.40** |
  | Consensus | 37.7% | -$2.33 |
  | Contrarian | 41.3% | -$2.81 |
- **Root cause CONFIRMED**: Average loss size > Average win size
  - Higher win rate makes P&L WORSE (more trades = more losses in absolute terms)
  - The problem is NOT entry selection, it's EXIT MANAGEMENT
- **Why bandit works better** (CODE ANALYSIS 2025-12-21):

  **Bandit Mode Entry Strategy (HMM-Only):**
  ```python
  # Only trade when HMM shows STRONG trend (ignore neural predictions)
  HMM_STRONG_BULLISH = 0.70  # Very strong bullish signal
  HMM_STRONG_BEARISH = 0.30  # Very strong bearish signal
  HMM_MIN_CONFIDENCE = 0.70  # HMM must be confident
  ```

  Key differences from RL/Consensus/Contrarian:
  1. **HMM-only entry**: Ignores neural network predictions entirely
  2. **Very strict thresholds**: Only trades when trend > 0.70 or < 0.30
  3. **High confidence requirement**: 70% HMM confidence (vs 55% for RL mode)
  4. **Volatility filter**: Avoids high vol (hmm_volatility < 0.7)
  5. **Catches EARLY moves**: Trades WITH established trend, not waiting for confirmation

  Why this works:
  - HMM is more robust than neural network for regime detection
  - Fewer but higher-quality trades
  - Enters early in trend before reversal
  - Neural predictions are unreliable (direction accuracy ~50%)

  **RL Mode Issues:**
  - Uses neural network which may not be well-trained
  - Lower confidence threshold (55%)
  - Temperature sampling adds randomness

  **Consensus/Contrarian Issues:**
  - Wait for too many signals to agree â†’ enter LATE
  - Late entries catch reversals â†’ bigger losses

- **Next steps**:
  1. ~~Investigate bandit's actual win/loss SIZE distribution~~ â†’ See analysis above
  2. ~~Consider making HMM-only the default strategy~~ â†’ Done (see Phase 6)
  3. ~~Train neural network better before using RL mode~~ â†’ Not needed
  4. ~~Or: Combine HMM threshold with neural confirmation (both must agree)~~ â†’ **IMPLEMENTED & BEST RESULT!**

---

## Phase 6: HMM+Neural Combined Entry Strategy (2025-12-21)

### Goal
Combine HMM's robust regime detection with neural network confirmation for even higher quality entries.

### Implementation

**Modified: `backend/unified_rl_policy.py`**

```python
# Entry requires BOTH signals to agree:
# 1. HMM trend > 0.70 (bullish) or < 0.30 (bearish)
# 2. Neural predicted_direction agrees (> 0.1 or < -0.1)
# Enable/disable via REQUIRE_NEURAL_CONFIRM env var (default: 1)
```

### Test Results

#### Initial 5K Test (Favorable Period)
| Strategy | Win Rate | P&L | Trades | Per-Trade P&L |
|----------|----------|-----|--------|---------------|
| **HMM+Neural** | **38.8%** | **+$35,774 (+715%)** | 1,084 | **+$33.00** |
| HMM-Only | 38.3% | +$19,485 (+390%) | 1,089 | +$17.90 |

#### 20K Validation Test (Extended Period)
| Strategy | Win Rate | P&L | Trades | Per-Trade P&L |
|----------|----------|-----|--------|---------------|
| **HMM+Neural** | **40.4%** | **-$4,675 (-93.5%)** | 3,254 | **-$1.44** |

### Key Findings

1. **VALIDATION FAILED**: The 5K +715% result was NOT reproducible
2. **Market period sensitivity**: The favorable 5K window (Sept-Oct timeframe) was anomalous
3. **20K test shows reality**: -93.5% P&L despite 40.4% win rate
4. **Per-trade P&L collapse**: +$33/trade in 5K â†’ -$1.44/trade in 20K
5. **Win rate is still NOT the issue**: 40.4% win rate yet losing 93% of capital

### Why Initial 5K Test Showed Good Results

1. **HMM filters for strong trends** (>0.70 or <0.30)
2. **Neural confirms direction** (must agree with HMM)
3. **Filters out contradictions** - avoids trades where HMM and neural disagree
4. **The Sept-Oct 2025 period** happened to have clear directional moves

### Why 20K Validation Failed

1. **Different market regimes**: Extended test included choppy/ranging periods
2. **HMM signals during consolidation**: Strong trend readings didn't translate to moves
3. **Balance floor hit**: Account dropped to ~10% of initial, limiting recovery potential
4. **Compounding losses**: Small losses accumulated faster than wins recovered

### Critical Lesson

**BACKTESTS ARE PERIOD-SENSITIVE**. A strategy that shows +715% in one window can show -93% in another. The 5K test was effectively curve-fitted to a favorable period.

### Configuration

```bash
# Default: HMM+Neural (enabled but NOT recommended for live trading)
REQUIRE_NEURAL_CONFIRM=1

# HMM-only mode (for comparison)
REQUIRE_NEURAL_CONFIRM=0
```

### Files Modified
- `backend/unified_rl_policy.py` - Added neural confirmation to bandit mode entry
- `config.json` - Restored max_cycles to reasonable default

## Configuration History

### v1: Bandit Baseline (BEST)
```json
{
  "entry_controller": { "type": "bandit" },
  "exit_policy": {
    "hard_stop_loss_pct": -8.0,
    "hard_take_profit_pct": 12.0,
    "hard_max_hold_minutes": 45
  }
}
```
**Result**: 40.9% win rate, +85% P&L (23,751 cycles)

### v2: Consensus (Too Strict)
```json
{
  "entry_controller": {
    "type": "consensus",
    "consensus": {
      "min_weighted_confidence": 0.55  // TOO HIGH - neural conf is ~20-30%
    }
  }
}
```
**Result**: 0 trades - all signals blocked

### v3: Consensus Relaxed
```json
{
  "entry_controller": {
    "type": "consensus"
  },
  "consensus": {
    "min_signals_to_trade": 3,
    "min_weighted_confidence": 0.15,  // Lowered
    "required_timeframes": ["15min", "1hour"]  // Fixed mismatch
  }
}
```
**Result**: 37.7% win rate, -33% P&L (712 trades)

### v4: Contrarian Mode (Current)
```json
{
  "entry_controller": {
    "type": "consensus"
  },
  "consensus": {
    "contrarian_mode": true,
    "contrarian_min_disagreement": 2,
    "contrarian_hmm_override": true
  },
  "exit_policy": {
    "hard_stop_loss_pct": -5.0,  // Tightened from 8%
    "hard_take_profit_pct": 18.0,  // Widened from 12%
    "hard_max_hold_minutes": 20  // Reduced from 45 (NOTE: wasn't used in test!)
  }
}
```
**Result**: **41.3% win rate** (best!), but -82% P&L (worst!). Confirms loss SIZE is the issue.

## Next Steps

### ~~Priority 1: Reproduce 40.9% Baseline~~ âœ… DONE
1. ~~Run bandit controller for ~5000+ cycles~~ - Done: 36.6% win rate at 5000 cycles
2. ~~Verify win rate is consistent~~ - Confirmed: 36-41% range is realistic
3. ~~Understand what makes it work~~ - Bandit mode + tight exits

### ~~Priority 2: Fix Consensus Controller~~ âœ… DONE
1. ~~Debug the crash at cycle 19~~ - Fixed Windows encoding issue
2. ~~Ensure consensus controller can actually make trades~~ - Verified: 18 trades in 130 cycles
3. ~~Compare win rate vs bandit~~ - Done: 37.7% vs 36.6% (consensus wins on rate, loses on P&L)

### ~~Priority 3: Full Consensus Test~~ âœ… DONE
1. ~~Run consensus controller for 5000 cycles~~ - Done: 37.7% win rate
2. ~~Compare win rate and P&L vs bandit baseline~~ - **Win rate higher but P&L worse!**
3. ~~If worse, tune thresholds further~~ - Need to fix win/loss size ratio

### ~~Priority 4: Fix Win/Loss Size Ratio~~ âœ… PARTIALLY DONE
**Phase 4 Fixes Applied (2025-12-20):**

1. **Stop Loss Min Hold Time**: Reduced from 5 minutes to 1 minute
   - Prevents catastrophic losses during early price gaps
   - Configurable via `STOP_LOSS_MIN_HOLD_MINUTES` env var

2. **Max Dollar Loss Cap**: Added $50 per trade hard cap
   - Exits immediately if position loses > $50 (regardless of %)
   - Configurable via `MAX_LOSS_PER_TRADE` env var

**Test Results (Combined Fixes):**
| Run | Config | Win Rate | P&L | Trades | Max Single Loss |
|-----|--------|----------|-----|--------|-----------------|
| test_combined | 1 min hold + $50 cap | **40.4%** | -$4,535 (-90.7%) | 1,012 | < $50 |

**Analysis:**
- Win rate improved from 36.6% to 40.4% âœ“
- No catastrophic single-trade losses (cap was never triggered) âœ“
- BUT: Still losing money overall because:
  - 4919 trades exit via FORCE_CLOSE (45 min time limit)
  - Stop loss rarely triggers (price doesn't hit SL before time exit)
  - Cumulative small losses exceed cumulative small wins

**Root Cause Confirmed:** The problem is NOT single-trade catastrophic losses. The problem is:
1. Entry timing leads to positions that drift sideways
2. Time exits dominate (45 min max hold)
3. Small losses accumulate faster than small wins

### ~~Priority 5: Dynamic Exit Evaluator~~ âŒ FAILED

**Goal:** Active position management - continuously re-evaluate positions instead of passive waiting

**Test Results:**
| Run | Config | Win Rate | P&L | Trades |
|-----|--------|----------|-----|--------|
| test_combined | Baseline (no dynamic exit) | 40.4% | -$4,535 (-90.7%) | 1,012 |
| test_dynamic_exit | Dynamic v1 (10 min flat) | 0.8% | -$4,502 (-90.0%) | 612 |
| test_dynamic_exit_v2 | Dynamic v2 (25 min flat) | 0.4% | -$4,505 (-90.0%) | 502 |

**Exit Reason Analysis (v2):**
- `theta_exceeds_expected`: 472 triggers (main culprit)
- `time_decay_exit`: 11 triggers

**Key Finding:** Dynamic exit HURTS performance dramatically (40% â†’ 0.4% win rate)
- Theta check too aggressive for short-term options
- Cuts positions before underlying has time to move
- Small repeated losses from bid-ask spread compound

**Conclusion:** Dynamic Exit Evaluator is **DISABLED BY DEFAULT** (set `DYNAMIC_EXIT_ENABLED=1` to enable)

**Next Steps (Revised):**
1. Focus on ENTRY quality rather than exit timing
2. Test with longer time horizons (45 min max hold is fine)
3. Investigate why bandit mode has positive per-trade P&L

### Priority 6: Tune for Higher Win Rate (After P5)
1. **VIX filtering** - Only trade when VIX is 15-25
2. **Time-of-day filter** - Avoid first/last 30 min
3. **Direction agreement** - All timeframes must agree

### Key Metrics
| Metric | Target | Bandit 5K | HMM+Neural 5K | HMM+Neural 20K |
|--------|--------|-----------|---------------|----------------|
| Win Rate | 60% | 36.6% | 38.8% | 40.4% |
| P&L | +100% | +42.6% | +715% | **-93.5%** |
| Trades | Quality > Quantity | 1,518 | 1,084 | 3,254 |
| Per-Trade P&L | > $0 | +$1.40 | +$33.00 | **-$1.44** |

**Conclusion**:
1. **Win rate is a red herring** - 40.4% win rate still lost 93% of capital
2. **Short backtests are dangerous** - 5K cycles can show +715%, 20K shows -93%
3. **Period sensitivity is extreme** - Strategy works in trending markets, fails in choppy markets
4. **No consistent edge found** - All strategies eventually lose money over longer periods

---

## Phase 7: Enhanced Features (2025-12-21)

### Goal
Address architectural gaps identified in code review:
1. GaussianKernelProcessor output was 96% wasted (only 1 of 25 features used)
2. No time-of-day features (markets behave differently at open/midday/close)
3. Options surface features existed but weren't fed to neural network

### Implementation

**Modified: `unified_options_trading_bot.py`**

```python
# Feature dimension increased: 50 â†’ 59
self.feature_dim = 59  # Enhanced: 50 base + 4 time + 5 gaussian pattern similarity

# NEW: Features 50-53: Time-of-day (cyclical encoding)
hour_sin = sin(2Ï€ * hour / 24)  # Cyclical hour
hour_cos = cos(2Ï€ * hour / 24)
dow_sin = sin(2Ï€ * day_of_week / 5)  # Cyclical day (Mon=0, Fri=4)
dow_cos = cos(2Ï€ * day_of_week / 5)

# NEW: Features 54-58: Gaussian pattern similarity
# Now uses 5 key features from the 25-feature GaussianKernelProcessor output:
# - similarity_mean (gamma=1.0): Average similarity to reference window
# - similarity_std (gamma=1.0): Variability in similarity
# - similarity_max (gamma=1.0): Best match to recent patterns
# - local_similarity (gamma=0.5): Tight local pattern matching
# - broad_similarity (gamma=2.0): Broad regime similarity
```

### Feature Layout (59 total)

| Range | Features | Count | Description |
|-------|----------|-------|-------------|
| 0-3 | Price & returns | 4 | Current price, 1/5/10-bar returns |
| 4-6 | Volatility | 3 | 5/10/20-bar volatility |
| 7-12 | Volume | 6 | Volume + velocity/acceleration/jerk |
| 13 | RSI | 1 | 14-period RSI |
| 14-15 | Bollinger | 2 | BB position and width |
| 16 | MACD | 1 | MACD signal |
| 17-18 | Range | 2 | High-low range features |
| 19-24 | Jerk | 6 | Price jerk (3rd derivative) |
| 25-28 | VIX | 4 | VIX level, BB, ROC, percentile |
| 29-38 | HMM | 10 | Multi-dimensional regime |
| 39-44 | Momentum | 6 | EMA crossover, trend strength |
| 45-49 | Short-term | 5 | 3/5-period momentum, acceleration |
| **50-53** | **Time (NEW)** | **4** | **Hour/DoW cyclical encoding** |
| **54-58** | **Gaussian (NEW)** | **5** | **Pattern similarity metrics** |

### Test Results (5000 cycles)

| Metric | Enhanced Features | Previous Baseline |
|--------|-------------------|-------------------|
| **Win Rate** | 39.3% | 40.4% |
| **P&L** | **-$4,882 (-97.6%)** | -$4,675 (-93.5%) |
| **Trades** | 1,017 | 3,254 |
| **Per-Trade P&L** | **-$4.80** | -$1.44 |

### Analysis

**The enhanced features did NOT improve performance**:

1. **Win rate unchanged** - Still around 40%
2. **P&L worse** - -97.6% vs -93.5% baseline
3. **Per-trade P&L worse** - -$4.80 vs -$1.44
4. **Fewer trades** - 1,017 vs 3,254 (may be due to feature mismatch during buffer warmup)

### Root Cause Analysis

The core issue is NOT feature quality. The architecture analysis revealed:

1. **Exit ratio problem persists**: -8% stop / +12% target = 1.25:1 ratio
   - With 40% win rate, need 1.5:1 ratio to break even
   - EV = (0.40 Ã— $500) - (0.60 Ã— $400) = -$40/trade

2. **Hold time exceeds prediction horizon**: 45 min hold vs 15 min prediction
   - After 15 min, position drifts randomly
   - Theta decay accumulates

3. **Features can't fix structural asymmetry**:
   - Better features might improve win rate slightly
   - But win rate isn't the problem - loss SIZE is
   - Average loss > average win regardless of entry quality

### Conclusion

Adding time-of-day and gaussian pattern features does not address the fundamental issue: the risk/reward ratio is structurally biased against profitability. The changes are kept in the codebase but **the core fixes needed are**:

1. **Tighten stop loss** to -5% (ratio becomes 2.4:1)
2. **Reduce max hold** to 15-20 min (align with prediction)
3. **Exit winners earlier** at +3-5% instead of waiting for +12%

---

## Phase 8: Architecture Comparison - output vs output3 (2025-12-21)

### Goal
Compare the architecture of `E:\gaussian\output` (original bot) with `E:\gaussian\output3` (current) to identify components that could be adapted.

### Key Findings

#### Exit Strategy Comparison

| Component | output | output3 | Analysis |
|-----------|--------|---------|----------|
| Stop Loss | -35% | -8% | output gives more room to recover |
| Take Profit | +40% | +12% | output captures larger wins |
| Exit Ratio | 1.14:1 | 1.5:1 | Similar math, different scale |
| **Max Hold** | **24 hours** | **45 minutes** | **MAJOR DIFFERENCE** |

**Key Insight**: output is designed for **longer-term options trading** (24h hold, 40% profit targets), while output3 is for **intraday scalping** (45m hold, 12% targets). These are fundamentally different strategies.

#### Adaptive Learning (output has, output3 lacks)

1. **RLThresholdLearner** (`backend/rl_threshold_learner.py`)
   - Learns optimal weights for trading factors (confidence, return, momentum, volume)
   - Instead of hardcoded thresholds, uses neural network to learn which factors matter
   - Self-adapts threshold based on win/loss score distributions
   - Tracks rejected signals to learn from missed opportunities

2. **AdaptiveTimeframeWeights** (`backend/adaptive_timeframe_weights.py`)
   - Learns which prediction timeframes (15m, 30m, 1h, 4h, etc.) are most accurate
   - Dynamically adjusts weights based on actual prediction outcomes
   - Better performing timeframes get higher weight
   - output3 has static weights (0.40, 0.35, 0.25)

#### Prediction Timeframes

| output | output3 |
|--------|---------|
| 7 timeframes (15m to 48h) | 3 timeframes (15m, 1h, 4h) |
| Adaptive weight learning | Fixed static weights |
| More market context | Limited context |

### Components to Port

| Component | File | Complexity | Expected Impact |
|-----------|------|------------|-----------------|
| RLThresholdLearner | `backend/rl_threshold_learner.py` | Medium | High - learns optimal entry factors |
| AdaptiveTimeframeWeights | `backend/adaptive_timeframe_weights.py` | Low | Medium - optimizes prediction weights |
| Wider Exit Bands | Config change | Low | High - structural fix |
| Longer Hold Time | Config change | Low | High - aligns with predictions |

### Recommendations

#### Priority 1: Fix Exit Strategy Mismatch
The core problem is structural:
- With 40% win rate and 8%/12% exits, we barely break even
- Transaction costs push us negative
- **Options**:
  - A. Widen stops to -20% / +30% (like output's proportions)
  - B. Extend hold time to 2-4 hours
  - C. Add volatility-adjusted exits

#### Priority 2: Add Adaptive Threshold Learning
Port `RLThresholdLearner` from output:
- Learns optimal weights for trading factors
- Adapts threshold based on performance
- Tracks missed opportunities

#### Priority 3: Add Adaptive Timeframe Weights
Port `AdaptiveTimeframeWeights` from output:
- Learns which prediction horizons are accurate
- Weights accurate timeframes higher

#### Priority 4: Align Prediction Horizon with Hold Time
Current mismatch:
- Predicting 15 minutes ahead
- Holding for 45 minutes
- Position often reverses after prediction horizon

### Documentation
Full comparison details: `docs/ARCHITECTURE_COMPARISON.md`

---

## Phase 9: Adaptive Learning Integration (2025-12-21)

### Goal
Integrate the two adaptive learning components identified in Phase 8:
1. **RLThresholdLearner** - Learns optimal weights for trading factors
2. **AdaptiveTimeframeWeights** - Learns which prediction timeframes are most accurate

### Changes Made

#### 1. Verified Both Components Already Exist in output3
Both components were already present and ENHANCED compared to output:

**RLThresholdLearner** (`backend/rl_threshold_learner.py`):
- 16 inputs vs 4 (expanded context: VIX, HMM, time, sector, etc.)
- Position sizing head (recommends 0.5x to 2x multiplier)
- Centralized threshold management (Issue 2 fix)
- Counterfactual learning from missed opportunities
- Already integrated in train_time_travel.py (but only as fallback)

**AdaptiveTimeframeWeights** (`backend/adaptive_timeframe_weights.py`):
- Supports 11 timeframes (5min to 2h)
- Already integrated in unified_options_trading_bot.py
- Loads/saves weights from models/adaptive_timeframe_weights.json

#### 2. Added Config Section for Adaptive Learning
New `config.json` section:
```json
"adaptive_learning": {
    "rl_threshold_learner": {
        "enabled": true,
        "learning_rate": 0.003,
        "base_threshold": 0.25,
        "threshold_floor": 0.15,
        "threshold_ceiling": 0.50,
        "rl_delta_max": 0.05,
        "use_as_filter": true
    },
    "adaptive_timeframe_weights": {
        "enabled": true,
        "min_predictions_for_update": 20,
        "weight_learning_rate": 0.05,
        "update_interval": 100
    }
}
```

#### 3. Integrated RLThresholdLearner as Quality Filter
Modified `scripts/train_time_travel.py`:
- RLThresholdLearner now initializes from config (not just as fallback)
- Acts as additional quality filter AFTER main entry controller decision
- Evaluates signals using 16 learned features
- Blocks trades that don't meet learned threshold
- Learns from trade outcomes (runs alongside unified RL)
- Tracks missed opportunities for counterfactual learning

#### 4. Added Emergency Circuit Breakers to Config
New `config.json` section:
```json
"emergency_circuit_breakers": {
    "catastrophic_loss_pct": -25.0,
    "massive_profit_pct": 100.0,
    "max_consecutive_losses": 5,
    "consecutive_loss_confidence_boost": 0.15,
    "max_daily_loss_pct": -20.0,
    "max_position_hold_hours": 2.0
}
```

### Architecture Flow (Updated)

```
Entry Signal
    â†“
Main Entry Controller (bandit/rl/consensus/q_scorer)
    â†“
RLThresholdLearner Filter (if enabled)
    â”œâ”€ Pass â†’ Execute Trade
    â””â”€ Block â†’ Record as missed opportunity
    â†“
Trade Execution
    â†“
Trade Closes
    â†“
Learning:
    â”œâ”€ Unified RL learns from outcome
    â”œâ”€ RLThresholdLearner learns from outcome
    â””â”€ Counterfactual learning from missed opportunities
```

### Expected Benefits

1. **Better Entry Quality**: RLThresholdLearner learns which factors (confidence, momentum, VIX, regime) actually predict winning trades

2. **Adaptive Thresholds**: Instead of fixed thresholds, the system learns optimal thresholds from data

3. **Timeframe Optimization**: AdaptiveTimeframeWeights will weight more accurate prediction horizons higher

4. **Counterfactual Learning**: System learns from trades it DIDN'T take, adjusting thresholds based on what would have happened

### Test Results (2025-12-21)

**Run: `models/adaptive_test_v2`**

| Metric | Value |
|--------|-------|
| Initial Balance | $5,000 |
| Final Balance | $38,314.96 |
| **P&L** | **+$33,314.96 (+666.30%)** |
| Total Trades | 197 |
| Win Rate | 39.3% (112 W / 173 L) |
| **Per-Trade P&L** | **+$169.11** |
| Total Signals | 4,967 |
| Cycles | 5,000 |

**Comparison to Previous Tests:**

| Phase | Strategy | P&L | Per-Trade P&L | Win Rate |
|-------|----------|-----|---------------|----------|
| Phase 9 | **Adaptive Learning** | **+666%** | **+$169.11** | 39.3% |
| Phase 6 | HMM+Neural (5K) | +715% | +$33.00 | 38.8% |
| Phase 5 | Bandit (HMM-only) | +42.6% | +$1.40 | 36.6% |
| Phase 7 | Enhanced Features | -97.6% | -$4.80 | 39.3% |
| Phase 6 | HMM+Neural (20K) | -93.5% | -$1.44 | 40.4% |

**Key Observations:**

1. **Excellent Per-Trade P&L**: +$169.11 vs previous best of +$33.00
2. **Consistent Win Rate**: 39.3% matches baseline
3. **Missed Play Analysis**:
   - Tracked 4,128 missed opportunities
   - 10.2% would have been winners (correctly avoided some)
   - 9.3% were losers we correctly avoided
4. **RL Threshold Filter working**: Blocked low-quality signals while passing good ones

**Important Note**: This is a single 5K cycle test. The HMM+Neural strategy that showed +715% on 5K failed at -93.5% on 20K validation. A 20K validation test is recommended to confirm these results hold up over a longer period.

### Validation Test (2025-12-21)

**Run: `models/adaptive_20k_validation`**

| Metric | Value |
|--------|-------|
| Initial Balance | $5,000 |
| Final Balance | $342.00 |
| **P&L** | **-$4,658.00 (-93.16%)** |
| Total Trades | 873 |
| Win Rate | 40.0% |
| Cycles | 5,000 (config limited) |

**CRITICAL FINDING: Strategy NOT Robust**

| Run | P&L | Trades | Per-Trade P&L |
|-----|-----|--------|---------------|
| adaptive_test_v2 | +666% | 197 | +$169.11 |
| adaptive_20k_validation | **-93%** | 873 | **-$5.34** |

The **same configuration** over the **same 5K cycles** produced wildly different results:
- First run: RLThresholdLearner blocked more trades (197 total)
- Second run: 4x more trades executed (873 total)
- Win rate nearly identical (39.3% vs 40.0%) but P&L opposite

**Conclusion**: The adaptive learning components do NOT provide consistent edge. Like previous strategies, results are highly period-sensitive and not reliable for live trading.

### Key Lessons Learned

1. **Win rate is not the bottleneck** - Both runs had ~40% win rate
2. **Trade quality varies wildly** - Per-trade P&L ranged from +$169 to -$5
3. **More trades != more profit** - Fewer, higher-quality trades outperformed
4. **5K tests are unreliable** - Same config can show +666% or -93%
5. **Adaptive learning doesn't fix structural issues** - Exit strategy asymmetry still dominates

### What Would Actually Help

Based on all experiments:
1. **Reduce trade frequency** - Fewer, higher-conviction trades
2. **Widen exit bands** - Current 8%/12% too tight for options volatility
3. **Align prediction horizon with hold time** - 15min prediction vs 45min hold is mismatch
4. **Focus on per-trade P&L, not win rate** - The math is in the size of wins vs losses

---

## Phase 10: Exit Strategy Experiments (2025-12-21)

### Goal
Test three specific improvements identified from previous analysis:
1. **Wider exit bands** - Address structural asymmetry
2. **Shorter hold time** - Align with prediction horizon
3. **Higher entry thresholds** - Reduce trade frequency

### Test Configuration

| Test | Stop Loss | Take Profit | Max Hold | Entry Gates |
|------|-----------|-------------|----------|-------------|
| Baseline (adaptive_test_v2) | -8% | +12% | 45 min | Default |
| **Test 1: Wider Exits** | **-15%** | **+25%** | 45 min | Default |
| **Test 2: Shorter Hold** | -8% | +12% | **20 min** | Default |
| **Test 3: Higher Thresholds** | -8% | +12% | 45 min | **min_conf=35%, min_abs_ret=0.10%** |

### Test Results (5000 cycles each)

| Test | P&L | Win Rate | Trades | Per-Trade P&L |
|------|-----|----------|--------|---------------|
| Baseline (adaptive_test_v2) | +$33,315 (+666%) | 39.3% | 197 | **+$169.11** |
| **Wider Exits (-15%/+25%)** | **+$22,855 (+457%)** | 37.4% | 895 | +$25.54 |
| **Shorter Hold (20 min)** | -$19 (-0.4%) | 25.0% | 12 | -$1.56 |
| **Higher Thresholds** | +$13,770 (+275%) | **40.7%** | 1,070 | +$12.87 |

### Analysis

#### Test 1: Wider Exit Bands (-15% stop / +25% TP)
**Result: Profitable but worse than baseline**

- **P&L**: +$22,855 (+457%) vs baseline +$33,315 (+666%)
- **Trades**: 895 (4.5x more than baseline's 197)
- **Per-Trade P&L**: +$25.54 vs baseline's +$169.11
- **Win Rate**: 37.4% (slightly lower than 39.3%)

**Finding**: Wider exits allowed more trades to complete but each trade was worth less. The additional room to move didn't improve quality - it just increased trade volume.

#### Test 2: Shorter Hold Time (20 min max)
**Result: FAILURE - Almost no trades**

- **Trades**: Only 12 trades in 5000 cycles
- **Win Rate**: 25.0% (3W/9L - too few trades to be meaningful)
- **P&L**: -$19 (-0.4%)

**Finding**: 20-minute hold time is too short. Positions are being force-closed before they can reach profit targets. This conflicts with the HMM entry strategy which trades on regime changes that take time to play out.

#### Test 3: Higher Entry Thresholds (min_conf=35%, min_abs_return=0.10%)
**Result: Profitable but fewer per-trade gains**

- **P&L**: +$13,770 (+275%) vs baseline +$33,315 (+666%)
- **Trades**: 1,070 (5.4x more than baseline)
- **Per-Trade P&L**: +$12.87 vs baseline's +$169.11
- **Win Rate**: 40.7% (highest of all tests!)

**Finding**: Higher thresholds improved win rate but still generated many more trades than baseline. The additional filters didn't reduce trade frequency as expected.

### Key Insight: RLThresholdLearner Is The Secret

**Why baseline (adaptive_test_v2) outperformed all three experiments:**

| Metric | Baseline | Wider Exits | Higher Thresh |
|--------|----------|-------------|---------------|
| Trades | 197 | 895 | 1,070 |
| Per-Trade P&L | +$169 | +$26 | +$13 |
| Trade Rejection Rate | **96%** | ~82% | ~79% |

The baseline used **RLThresholdLearner as a quality filter** which:
1. Blocked 96% of potential trades
2. Only allowed highest-quality signals through
3. Used 16 learned features to evaluate each opportunity

The experiments used different exit/entry parameters but **bypassed this learned filter** by generating more signals that passed the new thresholds.

### Conclusions

1. **Exit strategy parameters matter less than entry quality**
   - Wider stops didn't help - just allowed more mediocre trades
   - Tighter exits (shorter hold) actually broke the strategy

2. **The RLThresholdLearner is doing the heavy lifting**
   - Baseline blocked 96% of trades
   - The 4% that passed were high quality (+$169 each)
   - Changing exit parameters diluted this effect

3. **Trade frequency is inversely correlated with quality**
   - 197 trades â†’ +$169 per trade
   - 895 trades â†’ +$26 per trade
   - 1,070 trades â†’ +$13 per trade

4. **Short hold times don't work with HMM entry**
   - HMM detects regime changes
   - Regimes take time to play out (>20 min)
   - 45-minute hold is necessary for strategy

### Recommendations

1. **Keep 45-minute max hold** - Shorter breaks the strategy
2. **Focus on entry filtering** - RLThresholdLearner's quality gate is more important than exit parameters
3. **Default exit parameters are fine** - 8%/12% works when trade quality is high
4. **Validate over longer periods** - All these 5K results are period-sensitive

---

## Phase 11: Gate Analysis & Threshold Optimization (2025-12-21)

### Goal
1. Analyze which entry gates reject signals most often
2. Test relaxed thresholds to capture more of the 10.2% missed winners
3. Run 20K validation of current setup

### Gate Analysis

Added environment variable support for configurable thresholds:
- `HMM_STRONG_BULLISH` (default: 0.70)
- `HMM_STRONG_BEARISH` (default: 0.30)
- `HMM_MIN_CONFIDENCE` (default: 0.70)
- `HMM_MAX_VOLATILITY` (default: 0.70)
- `NEURAL_MIN_DIRECTION` (default: 0.1)

### RLThresholdLearner Feature Importance

Analysis of the trained model weights (L2 norm of first layer):

| Rank | Feature | Importance | Description |
|------|---------|------------|-------------|
| 1 | **predicted_return** | 1.44 | Neural network's predicted return |
| 2 | **confidence** | 1.37 | Signal confidence |
| 3 | **sector_strength** | 1.36 | Sector momentum |
| 4 | **hmm_trend** | 1.33 | HMM trend state |
| 5 | **recent_win_rate** | 1.29 | Recent trading performance |
| 6 | hmm_volatility | 1.28 | HMM volatility state |
| 7 | vix_level | 1.27 | VIX level |
| ... | ... | ... | ... |
| 16 | vix_bb_pos | 1.10 | (least important) |

**Key Insight**: The model weighs predicted_return and confidence highest, followed by sector strength and HMM trend.

### Test Results (5000 cycles each)

| Test | Thresholds | P&L | Trades | Win Rate | Per-Trade P&L |
|------|------------|-----|--------|----------|---------------|
| **BASELINE** | HMM: 0.70/0.30, Conf: 0.70 | +$3,431 (+69%) | 712 | **42.9%** | +$4.82 |
| **RELAXED** | HMM: 0.65/0.35, Conf: 0.60 | **+$10,308 (+206%)** | 243 | 34.8% | **+$42.42** |

### Analysis

#### RELAXED Thresholds Outperform Baseline by 3x!

Despite having:
- Lower win rate (34.8% vs 42.9%)
- Fewer trades (243 vs 712)

The RELAXED configuration achieved:
- **3x higher P&L** (+206% vs +69%)
- **9x higher per-trade P&L** (+$42 vs +$5)

#### Why Relaxed Thresholds Work Better

1. **Wider HMM band (0.65/0.35 vs 0.70/0.30)**
   - Catches trends earlier, before they reach extreme readings
   - Enters positions before the crowd
   - More trades during transition periods

2. **Lower confidence requirement (0.60 vs 0.70)**
   - Allows trades when HMM is directional but not extreme
   - Reduces requirement for perfect alignment
   - Captures more opportunities in trending markets

3. **Fewer but higher quality trades**
   - BASELINE: 712 trades = overtrading in marginal conditions
   - RELAXED: 243 trades = selective entry at better price points
   - Quality > Quantity confirmed again

### Missed Opportunity Analysis

| Test | Missed Winners | Avoided Losers | Neutral |
|------|----------------|----------------|---------|
| BASELINE | 52 (5.4%) | 48 (5.0%) | 89.7% |
| RELAXED | 3 (2.1%) | 0 (0.0%) | 97.9% |

**RELAXED has significantly fewer missed winners** (2.1% vs 5.4%)!

### 20K Validation Status

The 20K validation test is still running but showing only 1 trade after 5000 cycles. This suggests the extended period includes market conditions unfavorable for the strategy (choppy/ranging markets).

### Configuration Changes

**Updated `backend/unified_rl_policy.py`:**
```python
# Thresholds now configurable via environment variables
HMM_STRONG_BULLISH = float(os.environ.get('HMM_STRONG_BULLISH', '0.70'))
HMM_STRONG_BEARISH = float(os.environ.get('HMM_STRONG_BEARISH', '0.30'))
HMM_MIN_CONFIDENCE = float(os.environ.get('HMM_MIN_CONFIDENCE', '0.70'))
HMM_MAX_VOLATILITY = float(os.environ.get('HMM_MAX_VOLATILITY', '0.70'))
```

### Recommended New Defaults

Based on these results, consider updating defaults to:
```bash
HMM_STRONG_BULLISH=0.65
HMM_STRONG_BEARISH=0.35
HMM_MIN_CONFIDENCE=0.60
```

### Key Lessons

1. **Strict thresholds cause overtrading** - Waiting for "perfect" setups (HMM > 0.70) means entering late
2. **Earlier entry = better prices** - Catching trends at 0.65 instead of 0.70 means better entry points
3. **Fewer trades can mean more profit** - 243 trades at +$42 each beats 712 trades at +$5 each
4. **Win rate is still not the key metric** - Lower win rate (34.8%) produced 3x higher P&L

### Validation Test (New Defaults)

After updating defaults to relaxed thresholds, ran another 5K test:

| Test | Thresholds | P&L | Trades | Win Rate | Per-Trade |
|------|------------|-----|--------|----------|-----------|
| Earlier RELAXED | 0.65/0.35/0.60 | **+$10,308 (+206%)** | 243 | 34.8% | **+$42.42** |
| **New Defaults Test** | 0.65/0.35/0.60 | **-$4,768 (-95%)** | 1,020 | 40.2% | **-$4.67** |

### CRITICAL FINDING: Extreme Period Sensitivity

**The SAME configuration produced opposite results on different time periods:**
- Period A (earlier): +206% profit
- Period B (later): -95% loss

This confirms what we've seen throughout testing:
1. **5K backtests are unreliable** - Results vary wildly based on market conditions
2. **No consistent edge exists** - Every configuration eventually fails
3. **The strategy is not robust** - Cannot be deployed with confidence

### Why Results Differ

The two tests ran on different historical periods:
- **Earlier test**: Likely caught favorable trending conditions
- **Later test**: Likely hit choppy/ranging market conditions

The relaxed thresholds (0.65/0.35) generate more trades, which:
- In trending markets â†’ catches more winners â†’ profit
- In choppy markets â†’ catches more noise â†’ losses

### Conclusion

**The threshold values matter less than the market regime.** The strategy needs:
1. A robust market regime filter (only trade in favorable conditions)
2. Or: acceptance that it will have large drawdown periods
3. Or: a fundamentally different approach

The defaults have been updated to 0.65/0.35/0.60 but **users should be aware this does not guarantee better performance** - it depends entirely on market conditions during the trading period.

## Phase 12: Regime Filter Implementation (2025-12-22)

### Objective

Address the extreme period sensitivity discovered in Phase 11 by implementing a unified regime filter that gates entries based on market quality.

### Implementation

Created backend/regime_filter.py with three components:

1. **Regime Quality Score** (0-1, weighted composite):
   - Trend Clarity (30%): Strong trends > neutral
   - Volatility Sweet Spot (25%): Optimal is 0.3-0.5 HMM volatility
   - HMM Confidence (20%): Higher confidence = better
   - VIX Stability (15%): VIX 15-20 is ideal, extremes penalized
   - Liquidity (10%): Higher liquidity = better

2. **Regime Transition Detection**:
   - Tracks regime history over last 10 periods
   - Flags rapid_transition when change > threshold * 2

3. **VIX-HMM Reconciliation**:
   - Maps VIX levels to expected HMM volatility ranges
   - Flags divergence when HMM disagrees with VIX

### Integration

- TT_REGIME_FILTER=3 for time-travel training (scripts/train_time_travel.py)
- REGIME_FILTER_ENABLED=1 for live trading (backend/unified_rl_policy.py)

### Thresholds

- REGIME_MIN_QUALITY=0.35: Minimum quality to trade
- REGIME_FULL_SIZE_QUALITY=0.65: Quality for full position size

### Test Results (5K Cycles Comparison)

| Test | P&L | Trades | Win Rate | Per-Trade P&L |
|------|-----|--------|----------|---------------|
| **With Regime Filter (TT_REGIME_FILTER=3)** | **-$4,766 (-95.3%)** | 689 | 36.8% | -$6.92 |
| **Baseline (No Filter)** | **-$49 (-1.0%)** | 41 | 36.6% | -$1.19 |

### Filter Statistics

| Metric | Value |
|--------|-------|
| Signals Approved | 4,188 |
| Signals Blocked | 779 (15.7%) |
| Veto Reasons | ALL rapid_transition (stability=0.00) |
| low_quality vetoes | 0 |
| vix_hmm_divergence vetoes | 0 |

### Critical Finding: Regime Filter INCREASES Trade Count

The regime filter test made **17x more trades** (689 vs 41) than baseline!

**Why Baseline Outperformed:**
1. Baseline uses RLThresholdLearner which blocked 96%+ of signals
2. Regime filter only blocked 15.7% of signals
3. More trades = more exposure to losing positions
4. Per-trade P&L: -$1.19 (baseline) vs -$6.92 (with filter)

**Why Regime Filter Failed:**
1. Quality score (0.94-0.95) was too permissive - most regimes "looked good"
2. Only rapid_transition triggered vetoes, but these were minority
3. The filter allowed trades that RLThresholdLearner would have blocked
4. VIX-HMM reconciliation and quality gates rarely triggered

### Root Cause Analysis

The regime filter was designed to catch choppy/unfavorable market conditions, but:
1. **Most regimes pass the quality test** - 0.35 threshold too low
2. **Rapid transitions are rare** - only 15.7% of cycles showed instability
3. **The filter doesn't replace entry quality gates** - it's additive, not selective

The baseline's RLThresholdLearner provides **much stronger filtering** by:
- Evaluating 16 features per signal
- Learning from trade outcomes
- Blocking low-quality entries regardless of regime

### Conclusion

**The Regime Filter does NOT improve performance.**

The issue isn't detecting bad market regimes - it's detecting bad individual trade opportunities. The RLThresholdLearner does this better than regime-level filtering.

**Recommendations:**
1. Do NOT enable regime filter (TT_REGIME_FILTER=3) for live trading
2. Keep RLThresholdLearner as primary entry gate
3. Consider raising REGIME_MIN_QUALITY to 0.60+ if filter is used
4. Focus on per-signal quality, not regime quality

### Files Created/Modified

- NEW: backend/regime_filter.py
- MODIFIED: scripts/train_time_travel.py (mode 3)
- MODIFIED: backend/unified_rl_policy.py (live trading integration)

---

## Phase 13: PnL Calibration Gate (2025-12-22) âœ… BEST RESULT

### Goal
Use the CalibrationTracker's PnL-based calibration to gate entries. Instead of trusting raw confidence, use calibrated P(profit) to filter trades.

### Implementation

**Modified:** `scripts/train_time_travel.py`
- Added `PNL_CAL_GATE` environment variable
- CalibrationTracker records trade entries and outcomes
- Gates entries when `calibrate_pnl(confidence) < PNL_CAL_MIN_PROB`

### How It Works

1. **Learning Phase (first 30 trades):** Collects (confidence, was_profitable) pairs
2. **Gating Phase:** Uses Platt+Isotonic hybrid calibration to predict P(profit|confidence)
3. **Decision:** Only trade when `calibrated_pnl_prob >= 40%`

### Test Results (5K Cycles)

| Test | P&L | Trades | Win Rate | Per-Trade P&L |
|------|-----|--------|----------|---------------|
| **With PnL Cal Gate** | **-$100 (-2.0%)** | **233** | 34.3% | **-$0.43** |
| Regime Filter | -$4,766 (-95.3%) | 689 | 36.8% | -$6.92 |
| Baseline (No Filter) | -$49 (-1.0%) | 41 | 36.6% | -$1.19 |

### Analysis

**Why PnL Calibration Gate Works:**

1. **Signal-level filtering**: Unlike regime filter (market-level), this filters individual trade opportunities
2. **Learns from actual P&L outcomes**: Adapts to real win/loss patterns, not just direction
3. **Reduces trade count**: 233 trades vs 689 (66% fewer) - focuses on higher-quality entries
4. **Calibrated probabilities**: Uses Platt scaling + Isotonic regression for accurate P(profit) estimates

**Key Insight:**
The regime filter failed because it asked "Is this market regime good?" (answer: usually yes).
The PnL calibration gate asks "At this confidence level, what's the actual probability of profit?" (answer: varies, often <40%).

### Configuration

```bash
# Enable PnL Calibration Gate
PNL_CAL_GATE=1

# Minimum calibrated P(profit) to trade (default: 40%)
PNL_CAL_MIN_PROB=0.40

# Minimum trades before gating starts (default: 30)
PNL_CAL_MIN_SAMPLES=30
```

### Files Modified

- `scripts/train_time_travel.py` - Added PnL calibration gate integration
- `run_pnl_cal_test.py` - Test script

### Recommendation

**ENABLE PnL Calibration Gate** for live trading. Set:
```bash
PNL_CAL_GATE=1
PNL_CAL_MIN_PROB=0.40
PNL_CAL_MIN_SAMPLES=30
```

---

## Phase 14: Feature Attribution (2025-12-22)

### Goal
Add gradient-based feature attribution to RLThresholdLearner to identify which of the 16 features are most predictive of winning trades.

### Implementation

**Modified:** `backend/rl_threshold_learner.py`
- Added `FEATURE_NAMES` list for the 16 input features
- Added `compute_feature_attribution()` method using gradient saliency
- Added `attribution_by_outcome` tracking (winners vs losers)
- Added `get_feature_importance()` method for analysis
- Updated `store_experience()` to track attribution by outcome
- Updated `get_stats()` to include feature importance
- Updated save/load to persist attribution state

**Modified:** `scripts/train_time_travel.py`
- Pass `feature_attribution` to `store_experience()` when trades close
- Store `rl_filter_details` in signal for attribution tracking
- Added feature attribution output in summary section

### Features Tracked (16 total)
1. `confidence` - Signal confidence (0-1)
2. `predicted_return` - Predicted return magnitude
3. `momentum` - Price momentum
4. `volume_spike` - Volume spike multiplier
5. `vix_level` - VIX level (normalized)
6. `vix_bb_pos` - VIX Bollinger Band position
7. `vix_roc` - VIX rate of change
8. `vix_percentile` - VIX historical percentile
9. `hmm_trend` - HMM trend state
10. `hmm_vol` - HMM volatility state
11. `hmm_liq` - HMM liquidity state
12. `time_of_day` - Normalized time
13. `sector_strength` - Sector momentum
14. `recent_win_rate` - Recent win rate
15. `drawdown` - Current drawdown level
16. `price_jerk` - Rate of change of acceleration

### Test Results (5K Cycles, No PnL Cal Gate)

| Test | P&L | Trades | Win Rate | Notes |
|------|-----|--------|----------|-------|
| Feature Attribution (no PnL gate) | -$4,367 (-87.35%) | 1089 | 40.8% | Poor - confirms PnL gate is critical |
| PnL Cal Gate (Phase 13) | -$100 (-2.0%) | 233 | 34.3% | MUCH BETTER |

### Analysis

The feature attribution test performed poorly without the PnL calibration gate, confirming that:
1. PnL calibration gate is the key improvement
2. Feature attribution is a diagnostic tool, not a standalone improvement
3. The attribution system is in place but needs trades with proper outcome tracking to generate insights

### How to Use Feature Attribution

When trades are tracked with attribution, the summary shows:
```
[ATTRIBUTION] FEATURE IMPORTANCE (Phase 14):
   Samples: X total, Y winners, Z losers
   Top features (most predictive of winners):
      1. feature_name: +/- importance_score
      ...
```

Positive differential importance = feature predicts winners more than losers.

### Files Modified

- `backend/rl_threshold_learner.py` - Feature attribution implementation
- `scripts/train_time_travel.py` - Integration and output
- `run_feature_attr_test.py` - Test script

### Recommendation

Feature attribution is a **DIAGNOSTIC TOOL**. Use it to understand which features predict winners:
- Run training with RLThresholdLearner enabled
- Check `ranked_features` in summary or saved model
- Focus improvements on high-importance features

---

## Phase 15: Combined Test (2025-12-22) - BEST CONFIGURATION

### Goal
Test PnL Calibration Gate (Phase 13) + Feature Attribution (Phase 14) together.

### Configuration

```bash
# Enable PnL Calibration Gate
PNL_CAL_GATE=1
PNL_CAL_MIN_PROB=0.40
PNL_CAL_MIN_SAMPLES=30

# Feature Attribution is automatic via RLThresholdLearner (enabled in config.json)
```

### Test Results (5K Cycles)

| Test | P&L | Trades | Win Rate | Per-Trade P&L |
|------|-----|--------|----------|---------------|
| **Combined (BEST)** | **-$88 (-1.8%)** | **70** | 30.0% | -$1.26 |
| PnL Gate Only (Phase 13) | -$100 (-2.0%) | 233 | 34.3% | -$0.43 |
| Feature Attr Only (Phase 14) | -$4,367 (-87.35%) | 1089 | 40.8% | -$4.01 |
| Regime Filter (Phase 12) | -$4,766 (-95.3%) | 689 | 36.8% | -$6.92 |
| Baseline (No Filter) | -$49 (-1.0%) | 41 | 36.6% | -$1.19 |

### Feature Attribution Results

The gradient-based attribution identified which features predict winners vs losers:

```
Top features (most predictive of winners):
1. predicted_return: +1.4265  (MOST IMPORTANT - makes sense)
2. confidence: +0.7566        (SECOND - also makes sense)
3. volume_spike: -0.2030      (NEGATIVE - high volume spike HURTS)
4. vix_roc: -0.1981           (NEGATIVE - rapid VIX changes hurt)
5. hmm_trend: +0.1812         (POSITIVE - HMM trend agreement helps)
```

**Key Insights:**
- `predicted_return` and `confidence` are the strongest predictors (as expected)
- `volume_spike` being NEGATIVE is surprising - may indicate chasing momentum
- `vix_roc` being NEGATIVE confirms volatile VIX periods are bad for trading
- `hmm_trend` being positive confirms HMM regime alignment helps

### Recommendation - BEST CONFIGURATION

For live trading, use:

```bash
# REQUIRED: PnL Calibration Gate
PNL_CAL_GATE=1
PNL_CAL_MIN_PROB=0.40
PNL_CAL_MIN_SAMPLES=30

# OPTIONAL: Feature Attribution for diagnostics
# Enabled via config.json adaptive_learning.rl_threshold_learner.enabled = true
```

This configuration:
1. Reduces trades by 93% (70 vs ~1000)
2. Reduces P&L losses by 95% (-$88 vs -$4,367)
3. Provides feature importance diagnostics for future improvements

---

---

## Phase 16: Baseline + PnL Calibration Gate (2025-12-22) - NEW BEST

### Goal
Combine the proven profitable bandit baseline (+85% over 23K cycles) with the PnL Calibration Gate improvement.

### Hypothesis
The bandit baseline was the only verified profitable configuration. Adding PnL calibration gate should further filter out losing trades while preserving the profitable core strategy.

### Configuration

```bash
# Entry Controller: bandit (default HMM-only)
# This is the ONLY verified profitable configuration (+85% over 23K cycles)

# Enable PnL Calibration Gate
PNL_CAL_GATE=1
PNL_CAL_MIN_PROB=0.40  # 40% minimum P(profit)
PNL_CAL_MIN_SAMPLES=30  # Learn from first 30 trades

# RLThresholdLearner enabled via config.json
```

### Test Results (5K Cycles)

| Metric | Value |
|--------|-------|
| **P&L** | **+$19.66 (+0.39%)** |
| **Win Rate** | **46.7%** (HIGHEST EVER!) |
| **Trades** | 270 |
| **Per-Trade P&L** | **+$0.07** |
| **Wins** | 126 |
| **Losses** | 144 |

### Comparison to Previous Phases

| Test | P&L | Win Rate | Trades | Per-Trade P&L |
|------|-----|----------|--------|---------------|
| **Phase 16 (Baseline + PnL Gate)** | **+$19.66 (+0.39%)** | **46.7%** | 270 | **+$0.07** |
| Phase 15 (Combined) | -$88 (-1.8%) | 30.0% | 70 | -$1.26 |
| Phase 13 (PnL Gate only) | -$100 (-2.0%) | 34.3% | 233 | -$0.43 |
| Phase 14 (Feature Attr only) | -$4,367 (-87%) | 40.8% | 1089 | -$4.01 |
| Phase 12 (Regime Filter) | -$4,766 (-95%) | 36.8% | 689 | -$6.92 |

### Analysis

**Why This Configuration Works:**

1. **Bandit mode provides quality entries**: HMM-only entry with strict thresholds (>0.70 bullish, <0.30 bearish) catches trends early
2. **PnL calibration gate filters losers**: Uses Platt+Isotonic calibration to predict P(profit) and blocks low-probability trades
3. **RLThresholdLearner adds layer of quality**: 16-feature neural network evaluates signal quality
4. **Win rate jumped 6%**: From ~40% baseline to 46.7% - highest we've seen!

**Key Insight:** Previous phases tested improvements on unfavorable market periods (hence losses). By using the bandit baseline as the foundation, we started with a profitable core strategy.

### Missed Opportunity Analysis

| Metric | Value |
|--------|-------|
| Tracked | 152 |
| Missed Winners | 3 (2.0%) |
| Avoided Losers | 0 (0.0%) |
| Neutral | 149 (98.0%) |

Only 2% missed winners is excellent - the gate is not being too aggressive.

### Recommendation - NEW BEST CONFIGURATION

For live trading, use:

```bash
# Use default bandit entry controller (config.json)
# entry_controller.type: "bandit"

# Enable PnL Calibration Gate
PNL_CAL_GATE=1
PNL_CAL_MIN_PROB=0.40
PNL_CAL_MIN_SAMPLES=30
```

### 20K Validation Results (2025-12-22)

| Metric | 5K Test | 20K Validation |
|--------|---------|----------------|
| **P&L** | +$19.66 (+0.39%) | **-$216.88 (-4.34%)** |
| **Win Rate** | 46.7% | **29.8%** |
| **Trades** | 270 | **94** |
| **Per-Trade P&L** | +$0.07 | **-$2.31** |
| **Cycles** | 5,000 | 20,000 |

### Analysis - 20K Validation

**VALIDATION SHOWS MIXED RESULTS:**

1. **Losses are dramatically reduced**: -4.34% vs -93% to -95% in previous 20K tests
2. **Win rate dropped**: 46.7% â†’ 29.8% over extended period
3. **Very selective**: Only 94 trades in 20K cycles (gates blocking 99.5% of signals)
4. **Still period-sensitive**: First 5K favorable, extended period less so

### Key Insight

The PnL calibration gate + bandit combination is the **most stable configuration tested**:
- Previous 20K tests lost 93-95% of capital
- This configuration lost only 4.34%
- **20x improvement in drawdown control**

While not consistently profitable, this configuration:
- Prevents catastrophic losses
- Maintains capital preservation
- Could be profitable in trending market conditions

---

## Summary of All Phases

| Phase | Improvement | 5K Impact | 20K Impact | Recommendation |
|-------|-------------|-----------|------------|----------------|
| Phase 12 | Regime Filter | -95% P&L | N/A | **NOT RECOMMENDED** |
| Phase 13 | PnL Calibration Gate | -2% P&L | N/A | Partial improvement |
| Phase 14 | Feature Attribution | -87% P&L | N/A | Diagnostic only |
| Phase 15 | Combined | -1.8% P&L | N/A | Superseded by Phase 16 |
| **Phase 16** | **Baseline + PnL Gate** | **+0.39%** | **-4.34%** | **MOST STABLE - 20x better than other 20K tests** |

### Conclusion

**Phase 16 (Baseline + PnL Calibration Gate)** is the **best configuration**:
- Only -4.34% over 20K cycles vs -93% to -95% for other configurations
- **20x improvement in drawdown control**
- Very selective (94 trades in 20K cycles)
- Capital preservation focus

**For live trading, use:**
```bash
# Entry Controller: bandit (default in config.json)
PNL_CAL_GATE=1
PNL_CAL_MIN_PROB=0.40
PNL_CAL_MIN_SAMPLES=30
```

---

## Phase 17: Architecture Analysis & Improvement Options (2025-12-22)

### Critical Architectural Issues Identified

| Issue | Severity | Description | Impact |
|-------|----------|-------------|--------|
| **Horizon Misalignment** | MAJOR | Predict 15min, hold 45min | Position drifts after prediction "expires" |
| **Exit Ratio Asymmetry** | MAJOR | -8% stop / +12% TP needs 40% win rate | At 30% win rate, math guarantees losses |
| **Confidence Miscalibration** | MAJOR | Neural outputs 0.20-0.35, thresholds at 0.55+ | Good trades blocked |
| **Gate Proliferation** | MODERATE | 6+ independent gates filtering | Over-filtering, hard to debug |
| **HMM-Neural Conflict** | MODERATE | No hard veto on disagreement | Conflicting signals cause random trades |
| **Regime Filter Relaxed** | MINOR | Choppy filter disabled | Trades in unfavorable conditions |

### Improvement Options Ranked by Impact

| Priority | Fix | Change | Expected Impact | Effort |
|----------|-----|--------|-----------------|--------|
| **1** | Align Horizons | `max_hold: 45 â†’ 20 min` | +10-15% P&L | Low |
| **2** | Fix Exit Ratio | `stop: -8% â†’ -5%` | Break-even possible | Low |
| **3** | Calibrate Confidence | Add Platt scaling | +5% win rate | Medium |
| **4** | Consolidate Gates | Single entry filter | Fewer false blocks | High |
| **5** | HMM-Neural Veto | Hard disagree block | +3% win rate | Low |
| **6** | Enable Choppy Filter | `avoid_choppy: true` | +1-2% P&L | Low |

### The Core Problem

**Current State:**
```
Predict 15min ahead â†’ Hold 45min â†’ Exit by FORCE_CLOSE
          â†“                â†“              â†“
     Accurate        Drift randomly    Too late
```

**After 15 minutes**, the prediction is "expired" but we hold for another 30 minutes. The position movement after 15min is essentially random walk.

### Recommended Experiments

**Experiment A: Aligned Horizons**
```json
// config.json changes
"hard_max_hold_minutes": 20,  // Was 45 (3x prediction horizon)
"time_travel_training.max_hold_minutes": 20
```

**Experiment B: Tighter Risk/Reward**
```json
// config.json changes
"hard_stop_loss_pct": -5.0,    // Was -8.0
"hard_take_profit_pct": 15.0   // Was 12.0 (ratio now 3:1)
```

**Experiment C: Combined (A + B)**
Both horizon alignment AND tighter risk/reward together.

### Architecture Documentation

Full architecture analysis documented in: `docs/SYSTEM_ARCHITECTURE_V2.md`

Key files:
- `unified_options_trading_bot.py` - Main bot, signal generation
- `backend/unified_rl_policy.py` - Entry decisions (bandit mode)
- `backend/unified_exit_manager.py` - Exit decisions
- `scripts/train_time_travel.py` - Training loop
- `bot_modules/neural_networks.py` - Predictor architecture

---

## Phase 17: 5-Minute Bars + Aligned Horizons + Tighter Exits (2025-12-22)

### Configuration Changes

| Setting | Before | After | Rationale |
|---------|--------|-------|-----------|
| Data Interval | 1m | **5m** | Reduce noise |
| Max Hold | 45min | **20min** | Align with prediction horizon |
| Stop Loss | -8% | **-5%** | Tighter risk control |
| Take Profit | +12% | **+15%** | Better risk/reward (3:1) |
| Sequence Length | 30 | **12** | 12 5-min bars = 60min lookback |

### Test Results

| Metric | Phase 17 (5m) | Phase 16 (1m) |
|--------|---------------|---------------|
| **P&L** | -$300 (-6.01%) | -$217 (-4.34%) |
| **Win Rate** | **41.7%** (BEST!) | 29.8% |
| **Trades** | 336 | 94 |
| **Per-Trade P&L** | -$0.89 | -$2.31 |
| **Cycles** | 4,760 | 20,000 |

### Analysis

**What Worked:**
1. **Win rate jumped 12 percentage points** (29.8% â†’ 41.7%)
2. 5-minute bars reduce noise, improving prediction quality
3. Aligned horizons (20min hold vs 15min prediction) are better matched
4. Per-trade P&L improved (-$0.89 vs -$2.31)

**What Didn't Work:**
1. P&L still slightly negative (-6% vs -4.3%)
2. Many trades likely exit at max hold time (20min) before hitting TP/SL
3. With 41.7% win rate and 3:1 ratio, we SHOULD be profitable

### Root Cause Analysis

With 41.7% win rate and -5%/+15% exits:
- Expected win: 41.7% Ã— 15% = 6.26%
- Expected loss: 58.3% Ã— 5% = 2.92%
- Net expected: **+3.34% per trade**

But actual is -0.89$ per trade. This means:
1. Trades are exiting via FORCE_CLOSE (time) before hitting TP/SL
2. Average actual win < 15%, average actual loss > 5%
3. The 20-minute max hold is too short to reach targets

### Next Steps

**Option A: Increase max hold to 30min**
- Give trades more time to reach TP/SL
- Risk: more drift after prediction horizon

**Option B: Reduce TP to +10%**
- More achievable target within 20min
- Ratio becomes 2:1 (need 33% win rate)

**Option C: Use trailing stop more aggressively**
- Lock in smaller gains earlier
- Current: activate at +4%, trail by 2%
- Try: activate at +3%, trail by 1.5%

### Conclusion

Phase 17 achieved the **highest win rate ever (41.7%)** by:
1. Using 5-minute bars (less noise)
2. Aligning hold time with prediction horizon

The win rate improvement is significant, but exits need tuning. The 20-minute hold time may be too short to reach the +15% target regularly.

---

## Phase 18: Extended Macro Features + Transformer Architecture (2025-12-23)

### Goal
Expand the feature set with comprehensive macro proxy features using ETFs for sectors, credit, commodities, and mega-caps.

### Implementation

**Modified:** `features/macro.py` - MAJOR EXPANSION

Added 27 new ETF symbols across 6 categories:

| Category | Symbols | Features |
|----------|---------|----------|
| Index Proxies | IWM, SMH, RSP | 6 (relative strength) |
| Sector ETFs (10) | XLK, XLF, XLE, XLY, XLP, XLV, XLI, XLU, XLB, XLRE | 30 (rotation, dispersion) |
| Credit | HYG, LQD | 8 (spread, risk-on) |
| Commodities | USO, GLD | 8 (oil-gold spread) |
| Mega-Caps (6) | AAPL, MSFT, NVDA, AMZN, GOOGL, META | 6 (avg momentum, dispersion) |
| **Total** | **27 symbols** | **~115 new features** |

**New Feature Groups:**
1. `compute_relative_strength_ratios()` - X/SPY ratios for all symbols
2. `compute_credit_spread_features()` - HYG/LQD ratio, risk-on signal
3. `compute_sector_rotation_features()` - Leader, dispersion, risk-on/off
4. `compute_commodity_features()` - USO, GLD, oil-gold spread
5. `compute_megacap_features()` - Avg return, breadth, NVDA lead
6. `compute_index_proxy_features()` - IWM/SMH/RSP spreads

**Modified:** `features/pipeline.py`
- Added `enable_extended_macro: bool = True` to FeatureConfig
- Updated `get_required_symbols()` to include all 27 new symbols
- Feature dimension increased from ~50 to **500 features**

### Test Results

#### Phase 18a: Baseline Test with Extended Macro Features (5K Cycles)
| Metric | Value | Comparison |
|--------|-------|------------|
| **P&L** | **-$143.20 (-2.86%)** | Better than -4.34% (Phase 16 20K) |
| **Trades** | 82 | Very selective |
| **Features** | 500 | 10x increase |
| **Per-Trade P&L** | -$1.75 | Comparable to Phase 16 |
| **PnL Cal Gate** | Active | Blocking low P(profit) trades |

#### Phase 18b: Transformer Architecture Test (2K Cycles)
| Metric | TCN (baseline) | Transformer |
|--------|----------------|-------------|
| **P&L** | -0.2% | -1.9% |
| **Trades** | ~100 | 123 |

### Analysis

**Extended Macro Features:**
1. Successfully expanded feature pipeline from ~50 to 500 features
2. All 27 new ETF symbols fetching correctly
3. Neural network handles expanded features via RBF kernel expansion
4. PnL calibration gate remains effective at filtering low-quality trades

**Transformer vs TCN:**
- TCN (baseline) performs slightly better than transformer on this dataset
- Both show period sensitivity consistent with previous findings

### Configuration

```python
# features/pipeline.py - FeatureConfig
enable_extended_macro: bool = True  # Enable 27 new ETF symbols

# features/macro.py - New symbol groups
INDEX_PROXY_SYMBOLS = {'IWM': 'Russell 2000', 'SMH': 'Semis', 'RSP': 'Equal-weight'}
SECTOR_ETF_SYMBOLS = {'XLK': 'Tech', 'XLF': 'Financials', ...}  # 10 sectors
CREDIT_SYMBOLS = {'HYG': 'High Yield', 'LQD': 'Inv Grade'}
COMMODITY_SYMBOLS = {'USO': 'Oil', 'GLD': 'Gold'}
MEGACAP_SYMBOLS = {'AAPL', 'MSFT', 'NVDA', 'AMZN', 'GOOGL', 'META'}
```

### Key Findings

1. **Feature expansion successful**: 500 features vs 50 baseline
2. **No performance degradation**: -2.86% vs -4.34% (Phase 16 20K)
3. **PnL calibration gate essential**: Blocking trades with P(profit) < 40%
4. **TCN outperforms transformer**: For this architecture and dataset

### Files Modified

| File | Change |
|------|--------|
| `features/macro.py` | MAJOR: Added 27 symbols, 6 compute functions, ~115 features |
| `features/pipeline.py` | Added extended macro support, symbol lists |
| `bot_modules/neural_networks.py` | Added transformer components (swappable) |

### Conclusion

Phase 18 successfully expanded the feature pipeline with comprehensive macro proxies. The neural network handles the 10x feature increase well. Combined with Phase 16's PnL calibration gate, the system achieves better capital preservation (-2.86% vs -93% historical losses).

**Recommended Configuration:**
```bash
# Enable extended macro features (default: True)
# In features/pipeline.py: FeatureConfig.enable_extended_macro = True

# Enable PnL Calibration Gate (Phase 16)
PNL_CAL_GATE=1
PNL_CAL_MIN_PROB=0.40
```

---

## Phase 19: Attempt to Reproduce Profitable Run (2025-12-23)

### Goal
Analyze and reproduce the two profitable runs from December 20, 2025:
1. **run_20251220_073149**: +85% P&L over 23,751 cycles
2. **run_20251220_120723**: +42.6% P&L over 5,000 cycles (VERIFIED)

### Investigation

#### Profitable Run Analysis (run_20251220_120723)
| Metric | Value |
|--------|-------|
| P&L | +$2,128.68 (+42.57%) |
| Trades | 1,518 |
| Trade Rate | 30.4% (1518/5000) |
| Win Rate | 36.6% |
| Features | 50 |
| Date Range | Sept 15 - Dec 11, 2025 |
| Per-Trade P&L | +$1.40 |

#### Key Difference Discovered: Feature Dimension
- **Profitable run**: 50 features
- **Phase 18 runs**: 500 features (extended macro enabled)
- The extended macro features were causing weaker neural predictions

#### Key Difference Discovered: Trade Rate
- **Profitable run**: 30.4% of cycles resulted in trades
- **Recent runs**: Only 1.6% - 11% trade rate
- Gates (PnL Cal, Neural Confirmation) were blocking 95% of trades

### Reproduction Attempts

#### Test 1: Disable Gates + Extended Macro (500 features)
```bash
PNL_CAL_GATE=0 REQUIRE_NEURAL_CONFIRM=0 MODEL_RUN_DIR=models/reproduce_profitable
```
| Metric | Result |
|--------|--------|
| Trade Rate | 11.4% |
| P&L | -9.3% |
| Issue | Low confidence (~10-20%) due to 500 features |

#### Test 2: Disable Gates + Original Features (50 features)
```bash
# Changed feature_dim from 59 to 50 in unified_options_trading_bot.py
# Disabled enable_extended_macro in config.json
```
| Metric | Result |
|--------|--------|
| Trade Rate | 11.5% |
| P&L | -60% |
| Issue | Neural predictions still weak (0% edge) |

#### Test 3: HMM Pure Mode
```bash
HMM_PURE_MODE=1 PNL_CAL_GATE=0 REQUIRE_NEURAL_CONFIRM=0
```
| Metric | Result |
|--------|--------|
| Trade Rate | 20.2% |
| P&L | -94.5% at 5K cycles |
| Issue | Same time period, opposite result |

### Comparison Summary

| Config | Trade Rate | P&L | Status |
|--------|------------|-----|--------|
| Profitable (Dec 20) | 30.4% | +42.6% | âœ… Original |
| 500 features | 11.4% | -9.3% | âŒ Too few trades |
| 50 features | 11.5% | -60% | âŒ Still low trade rate |
| HMM Pure | 20.2% | -94.5% | âŒ Wrong direction |

### Root Cause Analysis

**Why we cannot reproduce:**

1. **Trade Rate Gap**: Profitable run had 30% rate, best reproduction got 20%
   - Missing 10% of high-quality trades

2. **Model Initialization**: Neural network starts fresh each run
   - Profitable run may have had favorable random initialization

3. **HMM State**: HMM regime detection is stochastic
   - Different runs detect regimes differently

4. **Code Changes**: Several modifications since Dec 20
   - Feature dimension changes (50 â†’ 59 â†’ 50)
   - Extended macro features (temporarily added/removed)

### Key Findings

1. **Feature dimension matters**: 50 features (original) vs 500 (extended) dramatically affects trade frequency

2. **Profitable config was**:
   - Pure bandit mode
   - 50-dimensional features
   - HMM-only entry (no neural confirmation)
   - No PnL calibration gate

3. **Period sensitivity confirmed**: Same config, same time period, opposite results
   - Random initialization plays a large role
   - No deterministic reproduction possible

4. **Trade quality vs quantity**: Lower trade rate doesn't necessarily mean better quality

### Configuration Changes Made

| File | Change |
|------|--------|
| `config.json` | Added `enable_extended_macro: false` |
| `unified_options_trading_bot.py` | Changed `feature_dim = 50` (was 59) |

### Conclusion

The profitable run from December 20, 2025 cannot be reliably reproduced. Key factors:
1. Random initialization of neural network and HMM
2. Stochastic nature of trading decisions
3. Code changes since the profitable run

**Recommendation**: Instead of chasing past results, focus on systematic improvements with proper statistical validation across multiple runs.


---

## Phase 20: Trade Selectivity Analysis (2025-12-23)

### Goal
Understand why `long_run_20k` achieved +823.87% P&L with such low trade rate (1.34%).

### Key Finding: Bandit Gate Selectivity

**long_run_20k Decision Analysis:**
| Metric | Value |
|--------|-------|
| Total Records | 20,000 |
| Trades Placed | 268 (1.34%) |
| HOLD Actions | 19,732 (98.7%) |
| BUY_CALLS | 266 (99.3% of trades) |
| BUY_PUTS | 2 (0.7% of trades) |

**Rejection Reason Breakdown:**
| Reason | Count | % of Total |
|--------|-------|------------|
| bandit_gate | 18,237 | 91.2% |
| max_positions | 1,407 | 7.0% |
| hold | 33 | 0.2% |
| trade_failed | 28 | 0.1% |

### Bandit Gate Thresholds

The bandit_gate requires BOTH:
1. **Confidence >= 20%** (`train_min_conf = 0.20`)
2. **|Predicted Return| >= 0.08%** (`train_min_abs_ret = 0.0008`)
3. **Edge consistent with direction** (positive for calls, negative for puts)

### Critical Discovery: Neural Network Training Matters

**Reproduction Test Comparison:**

| Test | Trade Rate | P&L | Neural Network State |
|------|------------|-----|---------------------|
| long_run_20k (original) | 1.34% | +823.87% | Well-trained (20K cycles) |
| Fresh start (same config) | 14.5% | -90%+ | Untrained/random |
| With loaded state | ~0.6% | In progress | Pre-trained |

**Why the difference?**
- Same bandit_gate thresholds (20% conf, 0.08% edge)
- Fresh neural network outputs higher confidences and edges
- Trained neural network is more conservative, outputs lower values
- Result: Trained NN passes fewer signals through the gate

### Per-Trade P&L Analysis

| Run | Trades | Total P&L | Per-Trade P&L |
|-----|--------|-----------|---------------|
| long_run_20k | 268 | +$41,193 | **+$153.70** |
| Fresh start | ~27 | -$4,890 | -$181.11 |

### Conclusion

**The secret to +823% P&L is extreme selectivity:**
1. The bandit_gate (20% conf + 0.08% edge) is a necessary filter
2. But the neural network's conservatism is what makes it work
3. A well-trained neural network outputs lower confidence values
4. This causes more signals to be rejected by the gate
5. Only the highest quality signals pass through
6. Result: 1.34% trade rate with +$153.70 per trade

**Recommendation:**
- Cannot simply replicate by setting thresholds
- Need to use trained model state from profitable run
- Or: Raise gate thresholds significantly (e.g., 35% conf, 0.15% edge)

### Files Modified
- No code changes in this phase (analysis only)
- Created reproduce_with_state directory with loaded model state

### Pre-trained State Reproduction Test (In Progress)

**Test: `models/reproduce_with_state`**

Using pre-trained model state from long_run_20k (+823.87% P&L).

| Cycle | Trades | Trade Rate | Balance | P&L |
|-------|--------|------------|---------|-----|
| 1015 | 18 | 1.77% | $11,793.60 | +136% |
| 1147 | 19 | 1.66% | $12,687.70 | +154% |
| 1346 | 19 | 1.41% | $17,651.92 | **+253%** |

**Per-Trade P&L at cycle 1346: +$665.89** (incredible!)

**Key Finding**: Pre-trained neural network state is the key differentiator:
- Same bandit_gate thresholds (20% conf, 0.08% edge)
- Same config.json settings
- But: Pre-trained NN is more conservative â†’ lower trade rate â†’ higher quality

### Final Results: Pre-trained State Reproduction Test

**Test: `models/reproduce_with_state`**
- Loaded pre-trained state from `long_run_20k`
- Config: Default (bandit mode, 20% conf, 0.08% edge)

| Metric | Value |
|--------|-------|
| **Final Balance** | **$55,811.30** |
| **P&L** | **+$50,811.30 (+1016%)** |
| **Total Trades** | 72 |
| **Trade Rate** | 1.43% |
| **Per-Trade P&L** | **+$705.71** |
| **Cycles** | 5,007 |
| **Win Rate** | ~36% (estimated) |

**Comparison to Original:**

| Run | P&L | Trades | Trade Rate | Per-Trade P&L |
|-----|-----|--------|------------|---------------|
| **reproduce_with_state (NEW)** | **+1016%** | 72 | 1.43% | **+$705.71** |
| long_run_20k (Original) | +824% | 268 | 1.34% | +$153.70 |

**KEY FINDING: Pre-trained state reproduction works AND outperforms original!**

The pre-trained neural network state from long_run_20k:
1. Maintains conservative output â†’ low trade rate (1.4%)
2. Only passes highest quality signals through bandit_gate
3. Achieves +$705/trade vs +$154/trade in original

---

## Scoreboard (Top Performing Runs)

| Rank | Run | P&L | Per-Trade P&L | Cycles | Date |
|------|-----|-----|---------------|--------|------|
| ðŸ¥‡ | **v3_20k_validation** | **+1277%** | +$12.84 | **20K** âœ… | 2025-12-30 |
| ðŸ¥ˆ | v3_10k_validation | +1327% | +$42.76 | 10K | 2025-12-30 |
| ðŸ¥‰ | v3_transformer_combined | +1326% | +$30.23 | 10K | 2025-12-30 |
| 4 | reproduce_with_state | +1016% | +$705.71 | 5K | 2025-12-24 |
| 5 | transformer_10k_validation | +801% | +$17.73 | 10K | 2025-12-30 |

**V3 Multi-Horizon is the FIRST strategy to maintain +1277% P&L at 20K cycles!**

---

## How to Reproduce the +1016% Result

### Method: Use Pre-trained Model State

1. **Copy state from profitable run:**
```bash
mkdir -p models/my_run/state
cp -r models/long_run_20k/state/* models/my_run/state/
```

2. **Run with LOAD_PRETRAINED flag:**
```bash
LOAD_PRETRAINED=1 MODEL_RUN_DIR=models/my_run TT_MAX_CYCLES=5000 PAPER_TRADING=True python scripts/train_time_travel.py
```

3. **Key insight:** The pre-trained neural network outputs conservative predictions, causing the bandit_gate (20% conf, 0.08% edge) to reject ~98.5% of signals. Only the highest quality 1.5% pass through.

### Why This Works

| Factor | Fresh Start | Pre-trained State |
|--------|-------------|-------------------|
| Trade Rate | 10-15% | **1.4%** |
| NN Confidence | Higher (20-40%) | Lower (10-25%) |
| Gate Rejections | ~85% | **~98.5%** |
| Per-Trade P&L | -$100 to +$50 | **+$700** |

The pre-trained neural network has learned to be conservative, outputting lower confidence values. This causes more signals to be rejected by the bandit_gate, leaving only the highest quality opportunities.

---

## âš ï¸ OVERFITTING WARNING (2025-12-24)

**The +1016% result is likely overfitted.**

### The Problem

| Factor | Value |
|--------|-------|
| Training data period | Sept 15 - Dec 11, 2025 |
| Test data period | Sept 15 - Dec 11, 2025 |
| **Same data?** | **YES - OVERFITTING** |

The `long_run_20k` neural network was trained on the **exact same historical window** we tested on. The model memorized patterns specific to that period.

### Evidence of Period Sensitivity

| Phase | Initial Result | Validation Result |
|-------|----------------|-------------------|
| Phase 6 | +715% | **-93.5%** |
| Phase 9 | +666% | **-93%** |
| Phase 11 | +206% | **-95%** |

### Proper Validation Plan

1. **Train**: Sept 15 - Nov 30, 2025 (months 1-3)
2. **Validate**: Dec 1 - Dec 24, 2025 (out-of-sample)
3. **Deploy**: Only if validation is profitable

---

## Scoreboard (Updated with Caveats)

| Rank | Run | P&L | Cycles | Status |
|------|-----|-----|--------|--------|
| ðŸ¥‡ | **v3_20k_validation** | **+1277%** | **20K** | âœ… **20K VALIDATED - STABLE!** |
| ðŸ¥ˆ | v3_10k_validation | +1327% | 10K | âœ… Fresh model, no pre-training |
| ðŸ¥‰ | v3_transformer_combined | +1326% | 10K | âœ… V3 + Transformer (no extra benefit) |
| 4th | transformer_10k_validation | +801% | 10K | âœ… Fresh model |
| 5th | reproduce_with_state | +1016% | 5K | âš ï¸ **OVERFITTED** - collapsed at 20K |

**Note**: V3 is the FIRST architecture to pass 20K validation without collapsing!

---

## Phase 21: Proper Walk-Forward Validation (2025-12-24)

### Plan

1. **Training Period**: Sept 15 - Nov 30, 2025 (~2.5 months)
2. **Validation Period**: Dec 1 - Dec 24, 2025 (~24 days, OUT-OF-SAMPLE)
3. **Live Deployment**: Only if validation shows positive P&L

### Expected Outcome

Based on previous validation failures, we expect:
- Training P&L: +500% to +1000% (overfitted)
- **Validation P&L: -50% to +50%** (realistic)

If validation is positive, we proceed to live trading.

### Actual Validation Results (2025-12-24)

**Run: dec_validation_v2** - Using pre-trained model state from `long_run_20k`

| Metric | Value |
|--------|-------|
| Cycles | 2,995 |
| Trades | 61 |
| **Trade Rate** | **2.0%** |
| Start Balance | $5,000 |
| Final Balance | $25,670 |
| **P&L** | **+413%** |
| **Win Rate** | **59.8%** |
| Per-Trade P&L | ~$339 |

**IMPORTANT CAVEAT**: This is NOT true out-of-sample validation because:
- Dec 2025 was part of the `long_run_20k` training period (Sept-Dec 2025)
- Database only has data through Dec 11, 2025
- True out-of-sample requires future data beyond training period

**Key Insight**: The pre-trained model state produces:
1. Very low trade rate (2%) - similar to profitable runs (1.3-1.4%)
2. High per-trade P&L (~$339)
3. Improved win rate (59.8% vs ~40% original)

**Decision**: Proceed to live trading with the pre-trained model state.

---

## Phase 23: Jerry's SPYOptionTrader Improvements Testing (2025-12-27)

### Goal
Systematically test Jerry's improvements from his SPYOptionTrader/Quantor-MTFuzz framework one at a time.

### Jerry Improvements Available
| Feature | Description | Config Key |
|---------|-------------|------------|
| event_halts | Block trading during CPI/FOMC/NFP | jerry.event_halts.enabled |
| kill_switches | Consecutive loss & drawdown halts | jerry.kill_switches.enabled |
| fuzzy_logic | Membership function trade quality | jerry.fuzzy_logic.enabled |
| position_sizing | Dynamic sizing based on fuzzy score | jerry.position_sizing.enabled |
| greek_limits | Portfolio Greek exposure limits | jerry.greek_limits.enabled |
| mtf_consensus | Multi-timeframe voting | jerry.mtf_consensus.enabled |

### Test Results (5K Cycles Each)

**CRITICAL**: Tests must use pre-trained model state from `long_run_20k` to be meaningful.
Fresh model tests show -85% to -95% losses regardless of config.

#### Tests WITHOUT Pre-trained State (INVALID - for reference only)
| Test | P&L | Trades | Balance | Notes |
|------|-----|--------|---------|-------|
| Fresh baseline | -87.5% | 974 | $624 | No pre-trained state |
| kill_switches (fresh) | -90.5% | 992 | $476 | Kill switches triggered but reset daily |
| fuzzy_logic (fresh) | -85.1% | ~1010 | $744 | No fuzzy vetoes logged |

#### Tests WITH Pre-trained State (VALID)
| Test | Jerry Feature | P&L | Trades | Trade Rate | Balance | Notes |
|------|---------------|-----|--------|------------|---------|-------|
| **Baseline** | None (event_halts only) | **-1.4%** | 81 | 1.57% | **$4,930** | âœ… Best result |
| **kill_switches** | kill_switches enabled | **-26.5%** | 90 | 1.77% | **$3,677** | âŒ Made it WORSE |

### Key Finding: Pre-trained State is CRITICAL

| Metric | Fresh Model | Pre-trained Model |
|--------|-------------|-------------------|
| Trade Rate | ~20% | ~1.5% |
| P&L (5K cycles) | -85% to -95% | -1.4% |
| Selectivity | Takes most signals | Rejects 98.5% of signals |

### Analysis

**kill_switches with pre-trained state (-26.5% vs -1.4% baseline):**
- Kill switches HURT performance when combined with pre-trained model
- The halt-and-resume pattern disrupts the neural network's learned patterns
- Consecutive loss tracking triggers during normal drawdown periods
- Net effect: More trades (90 vs 81) with worse outcomes

**Conclusion:** Jerry's improvements do NOT help the pre-trained model baseline.
The pre-trained neural network already achieves optimal selectivity.

### Recommendation

**BEST PERFORMING SETUP:**
```
- Pre-trained model state from long_run_20k
- event_halts: enabled (block CPI/FOMC/NFP)
- kill_switches: DISABLED
- fuzzy_logic: DISABLED
- All other Jerry features: DISABLED
```

**Result: -1.4% P&L, 1.57% trade rate, $4,930 balance**

### Next Steps
Focus on improving the pre-trained model baseline through:
1. Exit strategy tuning (stop loss, take profit, trailing)
2. Entry threshold adjustments (confidence, edge requirements)
3. Position sizing optimization
4. Multi-timeframe signal confirmation

---

## Phase 24: Exit Strategy Tuning (2025-12-28)

### Goal
Improve the best-performing baseline (pre-trained model with -1.4% P&L) through exit parameter tuning.

### Test Results (5K Cycles Each, Pre-trained State)

| Test | Stop Loss | Take Profit | Max Hold | P&L | Trades | Result |
|------|-----------|-------------|----------|-----|--------|--------|
| Baseline | -8% | +12% | 45 min | -1.4% | 81 | Baseline |
| Tight Stop | -5% | +12% | 45 min | -1.55% | 93 | âŒ Worse |
| Wide TP | -8% | +18% | 45 min | -0.72% | 56 | âœ… Better |
| **Short Hold** | -8% | +12% | **30 min** | **-0.58%** | 96 | âœ… **BEST** |
| Combined | -8% | +18% | 30 min | -11.2% | 91 | âŒ Much Worse |

### Key Findings

1. **Shorter max hold (30 min) is best**: Reduces theta decay exposure
2. **Improvements don't stack**: Wide TP + Short Hold combined = -11.2% (much worse)
3. **Tight stop loss hurts**: More trades but same or worse P&L
4. **Wide take profit helps individually**: But doesn't combine well with short hold

### Why Combined Config Failed

- Short hold (30 min) forces quicker exits
- Wide TP (+18%) needs more time to reach target
- Conflict: short time + high target = position exits on time before hitting TP
- Result: hits stop loss more often, misses take profit

### Recommendation

**BEST PERFORMING SETUP (Phase 24):**
```json
{
  "hard_stop_loss_pct": -8.0,
  "hard_take_profit_pct": 12.0,
  "hard_max_hold_minutes": 30
}
```

**Result: -0.58% P&L, 96 trades (improved from -1.4% baseline)**

---

## Phase 22: Live Trading Deployment (2025-12-24)

---

## Automated Optimization Results

### EXP-0174: Unknown (2026-01-05 13:58)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 43.9% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 40 |
| Run Dir | `models/EXP-0174_IDEA-272` |

**Source**: META_OPTIMIZER
**Category**: confidence_fix
**Hypothesis**: Confidence is frequently inverted - try entropy-based confidence
**Result**: ERROR

---

### EXP-0173: Unknown (2026-01-05 13:58)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 46.2% |
| P&L | -0.31% |
| Per-Trade P&L | $-0.30 |
| Trades | 52 |
| Run Dir | `models/EXP-0173_IDEA-273` |

**Source**: META_OPTIMIZER
**Category**: signal_filter
**Hypothesis**: Block consistently losing strategies: NEURAL_BEARISH,NEURAL_BULLISH,MOMENTUM_BEARISH
**Result**: FAIL

---


### EXP-0172: Unknown (2026-01-05 13:27)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 39.8% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 79 |
| Run Dir | `models/EXP-0172_IDEA-271` |

**Source**: PHASE51_MAMBA2
**Category**: architecture
**Hypothesis**: Mamba2 + signal filtering may combine architecture with best config
**Result**: ERROR

---

### EXP-0170: Unknown (2026-01-05 13:27)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 38.8% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 79 |
| Run Dir | `models/EXP-0170_IDEA-269` |

**Source**: PHASE51_MAMBA2
**Category**: architecture
**Hypothesis**: Mamba2 SSM may capture temporal patterns better than TCN for options trading
**Result**: ERROR

---

### EXP-0171: Unknown (2026-01-05 13:27)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 39.2% |
| P&L | -4.52% |
| Per-Trade P&L | $-2.86 |
| Trades | 79 |
| Run Dir | `models/EXP-0171_IDEA-270` |

**Source**: PHASE51_MAMBA2
**Category**: architecture
**Hypothesis**: Deeper Mamba2 (6 layers) may capture more complex patterns
**Result**: FAIL

---


### EXP-0169: Phase 50: Entropy V2 Only (no other changes) (2026-01-05 12:44)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 50.0% |
| P&L | -0.03% |
| Per-Trade P&L | $-0.07 |
| Trades | 20 |
| Run Dir | `models/EXP-0169_IDEA-268` |

**Source**: CODEX_REVIEW
**Category**: confidence_calibration
**Hypothesis**: Entropy confidence alone may significantly improve win rate correlation
**Result**: FAIL

---


### EXP-0167: Phase 50: All Codex Fixes Combined (2026-01-05 12:23)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 68.1% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 28 |
| Run Dir | `models/EXP-0167_IDEA-266` |

**Source**: CODEX_REVIEW
**Category**: confidence_calibration
**Hypothesis**: Combining all fixes will maximize confidence calibration improvement
**Result**: ERROR

---

### EXP-0166: Phase 50: Entropy Confidence V2 + Decoupled Uncertainty (2026-01-05 12:23)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 54.1% |
| P&L | -0.24% |
| Per-Trade P&L | $-0.32 |
| Trades | 37 |
| Run Dir | `models/EXP-0166_IDEA-265` |

**Source**: CODEX_REVIEW
**Category**: confidence_calibration
**Hypothesis**: Proper entropy confidence + decoupling uncertainty will fix inverted confidence
**Result**: FAIL

---

### EXP-0165: Phase 50: BCE Confidence Training (2026-01-05 12:23)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 51.1% |
| P&L | -0.7% |
| Per-Trade P&L | $-0.75 |
| Trades | 47 |
| Run Dir | `models/EXP-0165_IDEA-264` |

**Source**: CODEX_REVIEW
**Category**: confidence_calibration
**Hypothesis**: Training confidence with actual win/loss outcomes will make it predictive of win rate
**Result**: FAIL

---

### EXP-0168: Phase 50: Temperature Scaling Only (T=1.5) (2026-01-05 12:23)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 56.7% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 47 |
| Run Dir | `models/EXP-0168_IDEA-267` |

**Source**: CODEX_REVIEW
**Category**: confidence_calibration
**Hypothesis**: Temperature scaling alone may improve confidence calibration
**Result**: ERROR

---


### EXP-0164: TDA-BEST+: Tighter Trailing (8% activate, 4% trail) (2026-01-04 19:03)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 46.2% |
| P&L | -0.31% |
| Per-Trade P&L | $-0.30 |
| Trades | 52 |
| Run Dir | `models/EXP-0164_IDEA-221` |

**Source**: DATA_ANALYSIS
**Category**: entry
**Hypothesis**: Tighter trailing reduces drawdown from peak while keeping winners
**Result**: FAIL

---

### EXP-0163: TDA-BEST+: 10K Validation Run (2026-01-04 19:03)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 39.5% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 258 |
| Run Dir | `models/EXP-0163_IDEA-220` |

**Source**: DATA_ANALYSIS
**Category**: validation
**Hypothesis**: Longer test will confirm if +74% P&L is consistent
**Result**: ERROR

---


### EXP-0160: BEST+: Trailing + TDA regime filter (2026-01-04 18:08)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 49.2% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 52 |
| Run Dir | `models/EXP-0160_IDEA-213` |

**Source**: TDA_RESEARCH
**Category**: combo
**Hypothesis**: TDA can distinguish trending vs choppy regimes - only trade in trending
**Result**: ERROR

---

### EXP-0159: TDA: Topological features for regime detection (2026-01-04 18:08)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 48.3% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 52 |
| Run Dir | `models/EXP-0159_IDEA-212` |

**Source**: TDA_RESEARCH
**Category**: architecture
**Hypothesis**: TDA captures structural patterns (regime transitions, crash geometry) invisible to traditional indicators
**Result**: ERROR

---

### EXP-0162: ULTIMATE+: Trailing + TDA + Volume + Sentiment (2026-01-04 18:08)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 46.2% |
| P&L | -0.31% |
| Per-Trade P&L | $-0.30 |
| Trades | 52 |
| Run Dir | `models/EXP-0162_IDEA-215` |

**Source**: TDA_RESEARCH
**Category**: combo
**Hypothesis**: Multiple advanced signals = highest quality entries
**Result**: FAIL

---

### EXP-0161: TDA: Multi-scale windows (30m, 60m, 120m) (2026-01-04 18:08)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 46.2% |
| P&L | -0.31% |
| Per-Trade P&L | $-0.30 |
| Trades | 52 |
| Run Dir | `models/EXP-0161_IDEA-214` |

**Source**: TDA_RESEARCH
**Category**: architecture
**Hypothesis**: Multi-scale TDA captures patterns at different frequencies
**Result**: FAIL

---


### EXP-0158: BEST+: Trailing + Transformer encoder (2026-01-04 17:43)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 39.2% |
| P&L | -4.52% |
| Per-Trade P&L | $-2.86 |
| Trades | 79 |
| Run Dir | `models/EXP-0158_IDEA-211` |

**Source**: LEADERBOARD_OPTIMIZATION
**Category**: architecture
**Hypothesis**: Transformer attention = better regime detection = better entry timing
**Result**: FAIL

---

### EXP-0155: ULTIMATE BEST: Trailing + Volume + Low Conf + Sentiment (2026-01-04 17:43)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 51.9% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 22 |
| Run Dir | `models/EXP-0155_IDEA-208` |

**Source**: LEADERBOARD_OPTIMIZATION
**Category**: combo
**Hypothesis**: Multiple quality filters = fewer but much higher quality trades
**Result**: ERROR

---

### EXP-0157: BEST+: Trailing + V3 Multi-Horizon (2026-01-04 17:43)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 39.1% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 43 |
| Run Dir | `models/EXP-0157_IDEA-210` |

**Source**: LEADERBOARD_OPTIMIZATION
**Category**: architecture
**Hypothesis**: Better prediction horizon selection = better entry points for trailing
**Result**: ERROR

---

### EXP-0156: BEST+: Trailing + 11AM-1PM (best hours) (2026-01-04 17:43)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 47.2% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 52 |
| Run Dir | `models/EXP-0156_IDEA-209` |

**Source**: LEADERBOARD_OPTIMIZATION
**Category**: combo
**Hypothesis**: Morning momentum + trailing = catch the best moves
**Result**: ERROR

---


### EXP-0152: BEST+: Trailing + Sentiment (Fear & Greed < 40) (2026-01-04 17:20)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 46.2% |
| P&L | -0.31% |
| Per-Trade P&L | $-0.30 |
| Trades | 52 |
| Run Dir | `models/EXP-0152_IDEA-205` |

**Source**: LEADERBOARD_OPTIMIZATION
**Category**: combo
**Hypothesis**: Fear = best time to buy. Trailing lets winners run during recovery.
**Result**: FAIL

---

### EXP-0154: BEST+: Trailing + PCR > 1.1 (fear signal) (2026-01-04 17:20)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 46.2% |
| P&L | -0.31% |
| Per-Trade P&L | $-0.30 |
| Trades | 52 |
| Run Dir | `models/EXP-0154_IDEA-207` |

**Source**: LEADERBOARD_OPTIMIZATION
**Category**: combo
**Hypothesis**: High put buying = retail panic = time to buy with trailing stop
**Result**: FAIL

---

### EXP-0153: BEST+: Trailing + Low Confidence (< 0.25) (2026-01-04 17:20)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 50.0% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 22 |
| Run Dir | `models/EXP-0153_IDEA-206` |

**Source**: LEADERBOARD_OPTIMIZATION
**Category**: combo
**Hypothesis**: Low model confidence = market uncertainty = opportunity for trend followers
**Result**: ERROR

---

### EXP-0151: BEST+: Trailing + Volume > 1.3 (data-proven filter) (2026-01-04 17:20)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 46.2% |
| P&L | -0.31% |
| Per-Trade P&L | $-0.30 |
| Trades | 52 |
| Run Dir | `models/EXP-0151_IDEA-204` |

**Source**: LEADERBOARD_OPTIMIZATION
**Category**: combo
**Hypothesis**: Volume confirms institutional activity - high volume + trailing = best of both
**Result**: FAIL

---


### EXP-0150: ULTIMATE SENTIMENT: PCR + VIX + Trailing Stop (2026-01-04 15:50)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 46.2% |
| P&L | -0.31% |
| Per-Trade P&L | $-0.30 |
| Trades | 52 |
| Run Dir | `models/EXP-0150_IDEA-203` |

**Source**: USER_SUGGESTION
**Category**: combo
**Hypothesis**: Multiple sentiment signals aligning = higher conviction trades
**Result**: FAIL

---

### EXP-0149: SENTIMENT: VIX as Sentiment (extreme levels only) (2026-01-04 15:50)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 47.2% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 52 |
| Run Dir | `models/EXP-0149_IDEA-202` |

**Source**: USER_SUGGESTION
**Category**: features
**Hypothesis**: VIX extremes are reliable contrarian signals - high VIX = oversold, low VIX = overbought
**Result**: ERROR

---


### EXP-0148: COMBO: Trailing Stop + PCR Sentiment Filter (2026-01-04 15:28)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 46.2% |
| P&L | -0.31% |
| Per-Trade P&L | $-0.30 |
| Trades | 52 |
| Run Dir | `models/EXP-0148_IDEA-201` |

**Source**: USER_SUGGESTION
**Category**: combo
**Hypothesis**: PCR filter will cut bad trades while trailing stop lets winners run
**Result**: FAIL

---

### EXP-0146: SENTIMENT: Fear & Greed Index (CNN) (2026-01-04 15:28)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 46.2% |
| P&L | -0.31% |
| Per-Trade P&L | $-0.30 |
| Trades | 52 |
| Run Dir | `models/EXP-0146_IDEA-199` |

**Source**: USER_SUGGESTION
**Category**: features
**Hypothesis**: Extreme sentiment = reversal opportunities. Fear = buy, Greed = sell
**Result**: FAIL

---

### EXP-0145: SENTIMENT: Alpha Vantage News Sentiment API (2026-01-04 15:28)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 49.1% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 52 |
| Run Dir | `models/EXP-0145_IDEA-198` |

**Source**: USER_SUGGESTION
**Category**: features
**Hypothesis**: News sentiment provides leading indicator - positive news + bullish HMM = higher win rate
**Result**: ERROR

---

### EXP-0147: SENTIMENT: Enhanced Put/Call Ratio (already have data) (2026-01-04 15:28)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 46.2% |
| P&L | -0.31% |
| Per-Trade P&L | $-0.30 |
| Trades | 52 |
| Run Dir | `models/EXP-0147_IDEA-200` |

**Source**: USER_SUGGESTION
**Category**: features
**Hypothesis**: Extreme PCR is a reliable contrarian indicator - already have this data, just need to use it better
**Result**: FAIL

---


### EXP-0142: DATA-DRIVEN: Low confidence filter (< 0.25) (2026-01-04 15:06)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 40.2% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 79 |
| Run Dir | `models/EXP-0142_IDEA-195` |

**Source**: DATA_ANALYSIS
**Category**: entry
**Hypothesis**: High confidence = overfit prediction = worse outcome
**Result**: ERROR

---

### EXP-0143: ULTIMATE DATA-DRIVEN: All filters combined (2026-01-04 15:06)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 38.8% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 79 |
| Run Dir | `models/EXP-0143_IDEA-196` |

**Source**: DATA_ANALYSIS
**Category**: combined
**Hypothesis**: Maximum filtering based on actual data patterns
**Result**: ERROR

---

### EXP-0141: COMBO: 11AM-1PM + Volume > 1.3 + Trailing (2026-01-04 15:06)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 39.0% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 79 |
| Run Dir | `models/EXP-0141_IDEA-194` |

**Source**: DATA_ANALYSIS
**Category**: combined
**Hypothesis**: Stack all data-driven filters for maximum edge
**Result**: ERROR

---

### EXP-0144: Favor PUTS over CALLS (4.8% vs 4.0% WR) (2026-01-04 15:06)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 39.2% |
| P&L | -4.52% |
| Per-Trade P&L | $-2.86 |
| Trades | 79 |
| Run Dir | `models/EXP-0144_IDEA-197` |

**Source**: DATA_ANALYSIS
**Category**: entry
**Hypothesis**: Market has slight downward bias or puts are better priced
**Result**: FAIL

---


### EXP-0140: DATA-DRIVEN: Skip 1PM-3PM entirely (0.3-0.7% WR) (2026-01-04 14:44)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 39.5% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 79 |
| Run Dir | `models/EXP-0140_IDEA-193` |

**Source**: DATA_ANALYSIS
**Category**: entry
**Hypothesis**: Afternoon reversals kill trades - just avoid them
**Result**: ERROR

---

### EXP-0138: DATA-DRIVEN: Only trade 11AM-1PM (9.3% WR window) (2026-01-04 14:44)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 40.5% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 79 |
| Run Dir | `models/EXP-0138_IDEA-191` |

**Source**: DATA_ANALYSIS
**Category**: entry
**Hypothesis**: Midday has cleaner trends, afternoon is choppy reversals
**Result**: ERROR

---

### EXP-0137: ULTIMATE TRAILING: All optimizations combined (2026-01-04 14:44)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 20.0% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 56 |
| Run Dir | `models/EXP-0137_IDEA-190` |

**Source**: TRAILING_OPTIMIZATION
**Category**: combined
**Hypothesis**: Stack all winning elements with trailing stop
**Result**: ERROR

---

### EXP-0139: DATA-DRIVEN: Volume spike > 1.3 filter (2026-01-04 14:44)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 39.2% |
| P&L | -4.52% |
| Per-Trade P&L | $-2.86 |
| Trades | 79 |
| Run Dir | `models/EXP-0139_IDEA-192` |

**Source**: DATA_ANALYSIS
**Category**: entry
**Hypothesis**: High volume confirms real moves, low volume = fake breakouts
**Result**: FAIL

---


### EXP-0133: Trailing + Tighter stop -5% (cut losers faster) (2026-01-04 14:21)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 41.7% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 225 |
| Run Dir | `models/EXP-0133_IDEA-186` |

**Source**: TRAILING_OPTIMIZATION
**Category**: exit
**Hypothesis**: Cut losers fast + let winners run = asymmetric edge
**Result**: ERROR

---

### EXP-0136: Trailing + Stricter HMM 0.75/0.25 (2026-01-04 14:21)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 41.3% |
| P&L | -29.79% |
| Per-Trade P&L | $-6.62 |
| Trades | 225 |
| Run Dir | `models/EXP-0136_IDEA-189` |

**Source**: TRAILING_OPTIMIZATION
**Category**: combined
**Hypothesis**: Higher quality entries + trailing stop = fewer but bigger winners
**Result**: FAIL

---

### EXP-0135: Trailing + Time filter 10AM-2PM (2026-01-04 14:21)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 40.0% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 234 |
| Run Dir | `models/EXP-0135_IDEA-188` |

**Source**: TRAILING_OPTIMIZATION
**Category**: combined
**Hypothesis**: Best exit strategy + best time = compounded edge
**Result**: ERROR

---

### EXP-0134: Trailing + V3 + Transformer (architecture combo) (2026-01-04 14:21)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 29.1% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 97 |
| Run Dir | `models/EXP-0134_IDEA-187` |

**Source**: TRAILING_OPTIMIZATION
**Category**: combined
**Hypothesis**: Better predictions + trailing stop = more winners that run
**Result**: ERROR

---


### EXP-0129: OOS: Trailing stop on December (BEST +250%) (2026-01-04 13:59)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 37.0% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 183 |
| Run Dir | `models/EXP-0129_IDEA-182` |

**Source**: OOS_VALIDATION
**Category**: validation
**Hypothesis**: Trailing stop strategy generalizes to unseen data
**Result**: ERROR

---

### EXP-0132: Trailing: Later activation at +15% (2026-01-04 13:59)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 34.8% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 45 |
| Run Dir | `models/EXP-0132_IDEA-185` |

**Source**: TRAILING_OPTIMIZATION
**Category**: exit
**Hypothesis**: Later activation lets trends develop more
**Result**: ERROR

---

### EXP-0130: Trailing: Tighter trail 3% (lock more profit) (2026-01-04 13:59)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 33.3% |
| P&L | -0.56% |
| Per-Trade P&L | $-0.62 |
| Trades | 45 |
| Run Dir | `models/EXP-0130_IDEA-183` |

**Source**: TRAILING_OPTIMIZATION
**Category**: exit
**Hypothesis**: Tighter trail locks in more profit on reversals
**Result**: FAIL

---

### EXP-0131: Trailing: Earlier activation at +5% (2026-01-04 13:59)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 34.8% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 45 |
| Run Dir | `models/EXP-0131_IDEA-184` |

**Source**: TRAILING_OPTIMIZATION
**Category**: exit
**Hypothesis**: Earlier activation protects gains sooner
**Result**: ERROR

---


### EXP-0127: Momentum confirmation filter (2026-01-04 13:38)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 36.2% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 45 |
| Run Dir | `models/EXP-0127_IDEA-180` |

**Source**: CLAUDE_BRAINSTORM
**Category**: entry
**Hypothesis**: Trading with momentum improves win rate
**Result**: ERROR

---

### EXP-0128: ULTIMATE: All winning features combined (2026-01-04 13:38)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 33.3% |
| P&L | -0.56% |
| Per-Trade P&L | $-0.62 |
| Trades | 45 |
| Run Dir | `models/EXP-0128_IDEA-181` |

**Source**: CLAUDE_BRAINSTORM
**Category**: combined
**Hypothesis**: Stack all improvements for maximum edge
**Result**: FAIL

---


### EXP-0123: Only trade 10AM-2PM (optimal hours) (2026-01-04 13:17)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 34.8% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 45 |
| Run Dir | `models/EXP-0123_IDEA-176` |

**Source**: CLAUDE_BRAINSTORM
**Category**: entry
**Hypothesis**: Mid-day is more predictable, trends develop better
**Result**: ERROR

---

### EXP-0124: Entropy-based position sizing (2026-01-04 13:17)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 36.2% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 45 |
| Run Dir | `models/EXP-0124_IDEA-177` |

**Source**: CLAUDE_BRAINSTORM
**Category**: risk
**Hypothesis**: Bet more when model is confident, less when uncertain
**Result**: ERROR

---

### EXP-0125: Tighter stop -5% with wide TP +25% (2026-01-04 13:17)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 33.3% |
| P&L | -0.56% |
| Per-Trade P&L | $-0.62 |
| Trades | 45 |
| Run Dir | `models/EXP-0125_IDEA-178` |

**Source**: CLAUDE_BRAINSTORM
**Category**: exit
**Hypothesis**: Asymmetric risk/reward in our favor
**Result**: FAIL

---

### EXP-0126: Volume spike filter (only high volume) (2026-01-04 13:17)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 33.3% |
| P&L | -0.56% |
| Per-Trade P&L | $-0.62 |
| Trades | 45 |
| Run Dir | `models/EXP-0126_IDEA-179` |

**Source**: CLAUDE_BRAINSTORM
**Category**: entry
**Hypothesis**: High volume confirms direction, low volume = fake moves
**Result**: FAIL

---


### EXP-0120: Trailing stop instead of fixed TP (2026-01-04 12:57)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 38.1% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 189 |
| Run Dir | `models/EXP-0120_IDEA-173` |

**Source**: CLAUDE_BRAINSTORM
**Category**: exit
**Hypothesis**: Trailing stops capture more upside than fixed TP
**Result**: ERROR

---

### EXP-0122: Time-of-day filter (avoid first 30 min) (2026-01-04 12:57)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 38.5% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 216 |
| Run Dir | `models/EXP-0122_IDEA-175` |

**Source**: CLAUDE_BRAINSTORM
**Category**: entry
**Hypothesis**: Opening volatility causes whipsaws - skip it
**Result**: ERROR

---

### EXP-0119: Even wider TP +30% (push the limit) (2026-01-04 12:57)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 36.2% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 182 |
| Run Dir | `models/EXP-0119_IDEA-172` |

**Source**: CLAUDE_BRAINSTORM
**Category**: exit
**Hypothesis**: If wider TP helps, even wider might help more
**Result**: ERROR

---

### EXP-0121: VIX-adaptive exits (wider in low VIX) (2026-01-04 12:57)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 37.0% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 187 |
| Run Dir | `models/EXP-0121_IDEA-174` |

**Source**: CLAUDE_BRAINSTORM
**Category**: exit
**Hypothesis**: Low VIX = trending markets = let winners run longer
**Result**: ERROR

---


### EXP-0117: COMBO: TP +25% + Entropy Confidence (best P&L + best WR) (2026-01-04 12:00)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 38.0% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 276 |
| Run Dir | `models/EXP-0117_IDEA-170` |

**Source**: COMBO_TEST
**Category**: combined
**Hypothesis**: Wide TP for big winners + entropy confidence for better entry selection = best of both
**Result**: ERROR

---

### EXP-0118: COMBO: TP +25% + Entropy + V3 Transformer (2026-01-04 12:00)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 39.3% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 328 |
| Run Dir | `models/EXP-0118_IDEA-171` |

**Source**: COMBO_TEST
**Category**: combined
**Hypothesis**: Best architecture + best encoder + best exits + best entry filter
**Result**: ERROR

---


### EXP-0116: OOS: TP +25% on December (IDEA-153 BEST +91.44%) (2026-01-04 04:47)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 40.3% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 181 |
| Run Dir | `models/EXP-0116_IDEA-169` |

**Source**: OOS_VALIDATION
**Category**: validation
**Hypothesis**: Widest TP showed best P&L in training, validate on unseen data
**Result**: ERROR

---

### EXP-0115: OOS: Symmetric exits on December (IDEA-145) (2026-01-04 04:47)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 38.9% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 183 |
| Run Dir | `models/EXP-0115_IDEA-168` |

**Source**: OOS_VALIDATION
**Category**: validation
**Hypothesis**: Symmetric exits showed solid P&L, validate on unseen data
**Result**: ERROR

---


### EXP-0114: OOS: Wider TP (+20%) on December (IDEA-146 winner) (2026-01-04 04:32)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 36.6% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 183 |
| Run Dir | `models/EXP-0114_IDEA-167` |

**Source**: OOS_VALIDATION
**Category**: validation
**Hypothesis**: Wider TP showed best P&L in training, validate on unseen data
**Result**: ERROR

---

### EXP-0113: OOS: V3+Transformer on December (IDEA-144 winner) (2026-01-04 04:32)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 42.6% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 348 |
| Run Dir | `models/EXP-0113_IDEA-166` |

**Source**: OOS_VALIDATION
**Category**: validation
**Hypothesis**: V3+Transformer showed best WR in training, validate on unseen data
**Result**: ERROR

---

### EXP-0112: BEST BET: Trans+StrictHMM+TightExits (2026-01-04 04:32)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 38.0% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 49 |
| Run Dir | `models/EXP-0112_IDEA-165` |

**Source**: GRID_SEARCH
**Category**: combined
**Hypothesis**: Quality over quantity with fast exits
**Result**: ERROR

---

### EXP-0111: BEST BET: V3+Trans+Sym exits+20min hold (2026-01-04 04:32)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 35.8% |
| P&L | -3.65% |
| Per-Trade P&L | $-0.60 |
| Trades | 302 |
| Run Dir | `models/EXP-0111_IDEA-164` |

**Source**: GRID_SEARCH
**Category**: combined
**Hypothesis**: Combine all OOS-friendly settings
**Result**: FAIL

---


### EXP-0110: Transformer with dropout 0.2 (2026-01-04 04:07)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 37.7% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 45 |
| Run Dir | `models/EXP-0110_IDEA-163` |

**Source**: GRID_SEARCH
**Category**: training
**Hypothesis**: More dropout = less overfitting
**Result**: ERROR

---

### EXP-0108: V3 + Transformer + 30min horizon (2026-01-04 04:07)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 40.3% |
| P&L | -1.82% |
| Per-Trade P&L | $-1.26 |
| Trades | 72 |
| Run Dir | `models/EXP-0108_IDEA-161` |

**Source**: GRID_SEARCH
**Category**: architecture
**Hypothesis**: Longer horizon for bigger moves
**Result**: FAIL

---

### EXP-0107: V3 + Transformer + 15min horizon (2026-01-04 04:07)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 48.1% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 76 |
| Run Dir | `models/EXP-0107_IDEA-160` |

**Source**: GRID_SEARCH
**Category**: architecture
**Hypothesis**: Match prediction to hold time
**Result**: ERROR

---

### EXP-0109: Transformer 15K cycles (2026-01-04 04:07)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 34.7% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 114 |
| Run Dir | `models/EXP-0109_IDEA-162` |

**Source**: GRID_SEARCH
**Category**: training
**Hypothesis**: Optimal training length between 10K and 20K
**Result**: ERROR

---


### EXP-0103: Aggressive: -5%/+8%/20min with Transformer (2026-01-04 03:06)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 38.8% |
| P&L | -0.52% |
| Per-Trade P&L | $-0.54 |
| Trades | 49 |
| Run Dir | `models/EXP-0103_IDEA-156` |

**Source**: GRID_SEARCH
**Category**: exit
**Hypothesis**: Quick trades with tight risk control
**Result**: FAIL

---

### EXP-0104: Patient: -12%/+20%/60min with Transformer (2026-01-04 03:06)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 43.5% |
| P&L | -1.35% |
| Per-Trade P&L | $-1.46 |
| Trades | 46 |
| Run Dir | `models/EXP-0104_IDEA-157` |

**Source**: GRID_SEARCH
**Category**: exit
**Hypothesis**: Let trades develop fully
**Result**: FAIL

---

### EXP-0105: Relaxed HMM 0.60/0.40 with Transformer (2026-01-04 03:06)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 44.4% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 45 |
| Run Dir | `models/EXP-0105_IDEA-158` |

**Source**: GRID_SEARCH
**Category**: entry
**Hypothesis**: More trades might improve total P&L
**Result**: ERROR

---

### EXP-0106: Very strict HMM 0.80/0.20 with Transformer (2026-01-04 03:06)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 40.0% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 45 |
| Run Dir | `models/EXP-0106_IDEA-159` |

**Source**: GRID_SEARCH
**Category**: entry
**Hypothesis**: Only strongest trends = highest quality
**Result**: ERROR

---


### EXP-0099: TP +15% with Transformer (2026-01-04 02:45)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 40.4% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 45 |
| Run Dir | `models/EXP-0099_IDEA-152` |

**Source**: GRID_SEARCH
**Category**: exit
**Hypothesis**: Medium-wide TP balances profit capture
**Result**: ERROR

---

### EXP-0101: Max hold 30min with Transformer (2026-01-04 02:45)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 36.5% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 45 |
| Run Dir | `models/EXP-0101_IDEA-154` |

**Source**: GRID_SEARCH
**Category**: exit
**Hypothesis**: 30 min closer to 15 min prediction horizon
**Result**: ERROR

---

### EXP-0100: TP +25% with Transformer (2026-01-04 02:45)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 38.9% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 45 |
| Run Dir | `models/EXP-0100_IDEA-153` |

**Source**: GRID_SEARCH
**Category**: exit
**Hypothesis**: Very wide TP lets big winners run
**Result**: ERROR

---

### EXP-0102: Max hold 60min with Transformer (2026-01-04 02:45)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 43.5% |
| P&L | -1.35% |
| Per-Trade P&L | $-1.46 |
| Trades | 46 |
| Run Dir | `models/EXP-0102_IDEA-155` |

**Source**: GRID_SEARCH
**Category**: exit
**Hypothesis**: Longer hold for bigger moves
**Result**: FAIL

---


### EXP-0097: Wider TP (-8%/+20%) with Transformer (2026-01-04 02:01)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 36.5% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 45 |
| Run Dir | `models/EXP-0097_IDEA-146` |

**Source**: PHASE35_CLAUDE
**Category**: exit
**Hypothesis**: Wider TP lets trending moves develop fully
**Result**: ERROR

---

### EXP-0096: Symmetric exits (-10%/+10%) with Transformer (2026-01-04 02:01)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 36.2% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 45 |
| Run Dir | `models/EXP-0096_IDEA-145` |

**Source**: PHASE35_CLAUDE
**Category**: exit
**Hypothesis**: Symmetric exits reduce breakeven threshold, improving edge capture
**Result**: ERROR

---

### EXP-0095: V3 Multi-Horizon + Transformer encoder (2026-01-04 02:01)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 48.1% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 76 |
| Run Dir | `models/EXP-0095_IDEA-144` |

**Source**: PHASE35_CLAUDE
**Category**: architecture
**Hypothesis**: V3 architecture + Transformer encoder = best of both worlds for OOS
**Result**: ERROR

---

### EXP-0098: Shorter max hold (20 min) with Transformer (2026-01-04 02:01)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 38.8% |
| P&L | -0.52% |
| Per-Trade P&L | $-0.54 |
| Trades | 49 |
| Run Dir | `models/EXP-0098_IDEA-147` |

**Source**: PHASE35_CLAUDE
**Category**: exit
**Hypothesis**: Holding beyond prediction horizon causes reversals
**Result**: FAIL

---


### EXP-0094: Phase 45: Low conf + High volume (data-driven) (2026-01-03 17:42)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 41.5% |
| P&L | -0.2% |
| Per-Trade P&L | $-0.19 |
| Trades | 53 |
| Run Dir | `models/EXP-0094_IDEA-143` |

**Source**: PHASE45_ANALYSIS
**Category**: entry
**Hypothesis**: Low confidence + high volume = model uncertain but market active = best entries
**Result**: FAIL

---


### EXP-0093: HMM pure mode with strict thresholds (2026-01-02 17:01)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 0.0% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 0 |
| Run Dir | `models/EXP-0093_IDEA-112` |

**Source**: CLAUDE
**Category**: entry
**Hypothesis**: HMM was profitable in bandit mode - test pure HMM
**Result**: ERROR

---

### EXP-0091: Minimum edge threshold 0.5% (2026-01-02 17:01)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 34.4% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 1035 |
| Run Dir | `models/EXP-0091_IDEA-126` |

**Source**: CLAUDE
**Category**: entry
**Hypothesis**: Higher edge requirement = fewer but better trades
**Result**: ERROR

---

### EXP-0092: V3 + Transformer + Calibration gate (2026-01-02 17:01)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 34.7% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 1237 |
| Run Dir | `models/EXP-0092_IDEA-111` |

**Source**: CLAUDE
**Category**: architecture
**Hypothesis**: Best architecture + best filtering = best results
**Result**: ERROR

---


### EXP-0087: PRIORITY: 70% calibrated confidence gate (2026-01-02 16:37)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 43.0% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 76 |
| Run Dir | `models/EXP-0087_IDEA-122` |

**Source**: CLAUDE
**Category**: entry
**Hypothesis**: Extreme selectivity via calibration = 60%+ win rate
**Result**: ERROR

---

### EXP-0089: Ultra-strict: HMM 0.85 + Calibration 65% (2026-01-02 16:37)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 50.0% |
| P&L | -0.22% |
| Per-Trade P&L | $-0.24 |
| Trades | 44 |
| Run Dir | `models/EXP-0089_IDEA-124` |

**Source**: CLAUDE
**Category**: entry
**Hypothesis**: Double extreme filtering = highest quality trades only
**Result**: FAIL

---

### EXP-0088: PRIORITY: Load dec_validation_v2 RL weights (2026-01-02 16:37)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 36.5% |
| P&L | -3.29% |
| Per-Trade P&L | $-0.79 |
| Trades | 208 |
| Run Dir | `models/EXP-0088_IDEA-123` |

**Source**: CLAUDE
**Category**: entry
**Hypothesis**: RL weights + calibration = replicate 60% behavior
**Result**: FAIL

---

### EXP-0090: 30K training on Sept-Dec data (2026-01-02 16:37)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | N/A% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | N/A |
| Run Dir | `models/EXP-0090_IDEA-125` |

**Source**: CLAUDE
**Category**: architecture
**Hypothesis**: More training data + longer training = better generalization
**Result**: ERROR

---


### EXP-0083: DATA: Strict 30-minute max hold (not 31+) (2026-01-02 12:35)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 22.5% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 75 |
| Run Dir | `models/EXP-0083_IDEA-133` |

**Source**: DECISION_ANALYSIS
**Category**: exit
**Hypothesis**: Extra minutes after 30 hurt performance significantly
**Result**: ERROR

---

### EXP-0085: DATA: Disable confidence gate entirely (2026-01-02 12:35)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 38.2% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 87 |
| Run Dir | `models/EXP-0085_IDEA-135` |

**Source**: DECISION_ANALYSIS
**Category**: entry
**Hypothesis**: Confidence filter is counterproductive - removing it may help
**Result**: ERROR

---

### EXP-0084: DATA: Combined - Inverted conf + High consensus (2026-01-02 12:35)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 18.6% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 22 |
| Run Dir | `models/EXP-0084_IDEA-134` |

**Source**: DECISION_ANALYSIS
**Category**: entry
**Hypothesis**: Uncertain model + strong consensus = highest quality trades
**Result**: ERROR

---

### EXP-0086: BEST: V3 Multi-Horizon + Calibration Gate (2026-01-02 12:35)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 21.6% |
| P&L | -2.86% |
| Per-Trade P&L | $-1.63 |
| Trades | 88 |
| Run Dir | `models/EXP-0086_IDEA-127` |

**Source**: CLAUDE
**Category**: architecture
**Hypothesis**: V3 architecture + calibrated confidence = best of both worlds
**Result**: FAIL

---


### EXP-0082: DATA: High consensus strength filter (>=0.28) (2026-01-02 12:13)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 37.9% |
| P&L | -0.25% |
| Per-Trade P&L | $-0.44 |
| Trades | 29 |
| Run Dir | `models/EXP-0082_IDEA-132` |

**Source**: DECISION_ANALYSIS
**Category**: entry
**Hypothesis**: Multi-timeframe agreement strength is a strong win predictor
**Result**: FAIL

---

### EXP-0080: ARCH: Freeze NN weights (stable calibration) (2026-01-02 12:13)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 21.6% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 67 |
| Run Dir | `models/EXP-0080_IDEA-141` |

**Source**: ARCHITECTURE_REVIEW
**Category**: training
**Hypothesis**: Frequent retraining destabilizes calibration - freeze for stability
**Result**: ERROR

---

### EXP-0081: DATA: Inverted confidence (40-50% sweet spot) (2026-01-02 12:13)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 37.2% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 71 |
| Run Dir | `models/EXP-0081_IDEA-131` |

**Source**: DECISION_ANALYSIS
**Category**: entry
**Hypothesis**: Model overconfidence predicts LOSING trades. Lower confidence = better.
**Result**: ERROR

---

### EXP-0079: ARCH: Greeks-aware stops (vol-adjusted) (2026-01-02 12:13)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 34.2% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 71 |
| Run Dir | `models/EXP-0079_IDEA-140` |

**Source**: ARCHITECTURE_REVIEW
**Category**: exit
**Hypothesis**: Vol-adjusted stops reduce premature exits in high-gamma regimes
**Result**: ERROR

---


### EXP-0075: ARCH: EV Gate (expected value after costs) (2026-01-02 11:51)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 0.0% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 0 |
| Run Dir | `models/EXP-0075_IDEA-136` |

**Source**: ARCHITECTURE_REVIEW
**Category**: architecture
**Hypothesis**: High confidence doesn't mean positive EV when costs dominate
**Result**: ERROR

---

### EXP-0078: ARCH: Combined - EV Gate + Regime Attribution (2026-01-02 11:51)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 0.0% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 0 |
| Run Dir | `models/EXP-0078_IDEA-139` |

**Source**: ARCHITECTURE_REVIEW
**Category**: architecture
**Hypothesis**: Multiple filters working together = highest quality trades
**Result**: ERROR

---

### EXP-0077: ARCH: Auto-disable underperforming regimes (2026-01-02 11:51)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 29.1% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 235 |
| Run Dir | `models/EXP-0077_IDEA-138` |

**Source**: ARCHITECTURE_REVIEW
**Category**: risk
**Hypothesis**: Some regimes consistently lose - stop trading them
**Result**: ERROR

---

### EXP-0076: ARCH: Per-regime calibration (2026-01-02 11:51)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 36.1% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 165 |
| Run Dir | `models/EXP-0076_IDEA-137` |

**Source**: ARCHITECTURE_REVIEW
**Category**: architecture
**Hypothesis**: Regime-specific calibration improves ECE and confidence usefulness
**Result**: ERROR

---


### EXP-0072: Ultra-selective: 90% calibrated confidence gate (2026-01-02 11:28)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 37.8% |
| P&L | -0.42% |
| Per-Trade P&L | $-0.57 |
| Trades | 37 |
| Run Dir | `models/EXP-0072_IDEA-108` |

**Source**: CLAUDE
**Category**: entry
**Hypothesis**: Extreme selectivity should dramatically improve win rate
**Result**: FAIL

---

### EXP-0074: Asymmetric exits: -4% stop, +20% take profit (2026-01-02 11:28)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 38.9% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 175 |
| Run Dir | `models/EXP-0074_IDEA-110` |

**Source**: CLAUDE
**Category**: exit
**Hypothesis**: Even with lower win rate, 5:1 R:R should be profitable
**Result**: ERROR

---

### EXP-0073: Combined: Calibration 60% + RSI/MACD filter (2026-01-02 11:28)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 36.2% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 499 |
| Run Dir | `models/EXP-0073_IDEA-109` |

**Source**: CLAUDE
**Category**: entry
**Hypothesis**: Double filtering should catch only best trades
**Result**: ERROR

---

### EXP-0071: Long pretrain (50K cycles) for conservative outputs (2026-01-02 11:28)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | N/A% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | N/A |
| Run Dir | `models/EXP-0071_IDEA-107` |

**Source**: CLAUDE
**Category**: architecture
**Hypothesis**: Longer training leads to more conservative predictions, higher selectivity, better win rate
**Result**: ERROR

---


### EXP-0070: Bayesian uncertainty threshold (2026-01-02 09:27)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 26.1% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 61 |
| Run Dir | `models/EXP-0070_IDEA-120` |

**Source**: CLAUDE
**Category**: architecture
**Hypothesis**: Low uncertainty predictions should be more accurate
**Result**: ERROR

---

### EXP-0069: Triple confirmation: HMM + Neural + Calibration (2026-01-02 09:27)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 42.3% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 291 |
| Run Dir | `models/EXP-0069_IDEA-119` |

**Source**: CLAUDE
**Category**: entry
**Hypothesis**: Triple confirmation = highest quality trades only
**Result**: ERROR

---

### EXP-0068: Ensemble: TCN + Transformer + LSTM vote (2026-01-02 09:27)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 35.4% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 931 |
| Run Dir | `models/EXP-0068_IDEA-118` |

**Source**: CLAUDE
**Category**: architecture
**Hypothesis**: Ensemble reduces variance and improves reliability
**Result**: ERROR

---

### EXP-0067: RMSNorm + SwiGLU (LLaMA-style) (2026-01-02 09:27)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 33.3% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 965 |
| Run Dir | `models/EXP-0067_IDEA-117` |

**Source**: CLAUDE
**Category**: architecture
**Hypothesis**: Modern architecture components improve gradient flow
**Result**: ERROR

---


### EXP-0065: Deeper TCN (6 layers instead of 4) (2026-01-02 09:02)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 35.1% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 383 |
| Run Dir | `models/EXP-0065_IDEA-115` |

**Source**: CLAUDE
**Category**: architecture
**Hypothesis**: Deeper TCN captures more complex temporal patterns
**Result**: ERROR

---

### EXP-0064: Larger hidden dim (128 -> 256) (2026-01-02 09:02)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 39.3% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 363 |
| Run Dir | `models/EXP-0064_IDEA-114` |

**Source**: CLAUDE
**Category**: architecture
**Hypothesis**: More capacity = better feature learning = better predictions
**Result**: ERROR

---

### EXP-0066: Attention pooling + calibration (2026-01-02 09:02)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 42.1% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 117 |
| Run Dir | `models/EXP-0066_IDEA-116` |

**Source**: CLAUDE
**Category**: architecture
**Hypothesis**: Attention focuses on most relevant features for prediction
**Result**: ERROR

---

### EXP-0063: Pretrain 3 months (Sept-Nov) then fine-tune (2026-01-02 09:02)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | N/A% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | N/A |
| Run Dir | `models/EXP-0063_IDEA-113` |

**Source**: CLAUDE
**Category**: architecture
**Hypothesis**: Longer pretraining creates conservative, selective neural network outputs
**Result**: ERROR

---


### EXP-0062: Balanced 1:1 risk/reward (-8%/+8%) (2026-01-02 01:55)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 40.3% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 300 |
| Run Dir | `models/EXP-0062_IDEA-105` |

**Source**: TUNING_ANALYZER
**Category**: exit
**Hypothesis**: If win rate > 50%, symmetric R:R is profitable
**Result**: ERROR

---

### EXP-0061: Only trade in low volatility (VIX < 20) (2026-01-02 01:55)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 37.8% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 325 |
| Run Dir | `models/EXP-0061_IDEA-104` |

**Source**: TUNING_ANALYZER
**Category**: entry
**Hypothesis**: High VIX = unpredictable markets = random outcomes
**Result**: ERROR

---


### EXP-0058: Trailing stop activation at 5% gain (2026-01-02 01:32)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 47.1% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 91 |
| Run Dir | `models/EXP-0058_IDEA-101` |

**Source**: TUNING_ANALYZER
**Category**: exit
**Hypothesis**: Earlier profit protection prevents winners from becoming losers
**Result**: ERROR

---

### EXP-0057: Momentum filter + high confidence (2026-01-02 01:32)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 41.7% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 55 |
| Run Dir | `models/EXP-0057_IDEA-100` |

**Source**: TUNING_ANALYZER
**Category**: entry
**Hypothesis**: Active momentum + high confidence should catch real moves
**Result**: ERROR

---

### EXP-0060: V3 + short hold (20 min) (2026-01-02 01:32)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 38.1% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 381 |
| Run Dir | `models/EXP-0060_IDEA-103` |

**Source**: TUNING_ANALYZER
**Category**: architecture
**Hypothesis**: V3's 5m/15m predictions are most accurate; match hold time to horizon
**Result**: ERROR

---

### EXP-0059: V3 predictor + 75% confidence (2026-01-02 01:32)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 29.3% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 565 |
| Run Dir | `models/EXP-0059_IDEA-102` |

**Source**: TUNING_ANALYZER
**Category**: architecture
**Hypothesis**: V3's multi-horizon prediction + high confidence should find best entries
**Result**: ERROR

---


### EXP-0054: Tight stop with quick take-profit (-5%/+10%) (2026-01-02 01:07)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 17.6% |
| P&L | -2.56% |
| Per-Trade P&L | $-1.41 |
| Trades | 91 |
| Run Dir | `models/EXP-0054_IDEA-097` |

**Source**: TUNING_ANALYZER
**Category**: exit
**Hypothesis**: Smaller, more frequent wins beat larger, rarer wins
**Result**: FAIL

---

### EXP-0055: Very tight stop with moderate TP (-3%/+15%) (2026-01-02 01:07)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 22.2% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 83 |
| Run Dir | `models/EXP-0055_IDEA-098` |

**Source**: TUNING_ANALYZER
**Category**: exit
**Hypothesis**: High R:R ratio should be profitable even with low win rate
**Result**: ERROR

---

### EXP-0056: Combined: High conf + strict HMM (2026-01-02 01:07)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 37.1% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 80 |
| Run Dir | `models/EXP-0056_IDEA-099` |

**Source**: TUNING_ANALYZER
**Category**: entry
**Hypothesis**: Double confirmation should filter out noise trades
**Result**: ERROR

---

### EXP-0053: Very short max hold (10 min) (2026-01-02 01:07)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 38.3% |
| P&L | -1.57% |
| Per-Trade P&L | $-0.35 |
| Trades | 222 |
| Run Dir | `models/EXP-0053_IDEA-096` |

**Source**: TUNING_ANALYZER
**Category**: exit
**Hypothesis**: Ultra-short trades are scalping momentum which should be more predictable
**Result**: FAIL

---


### EXP-0052: Short max hold (15 min) (2026-01-02 00:48)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 40.5% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 240 |
| Run Dir | `models/EXP-0052_IDEA-095` |

**Source**: TUNING_ANALYZER
**Category**: exit
**Hypothesis**: Short-duration trades have better risk/reward as theta decay is minimal
**Result**: ERROR

---

### EXP-0050: Very high confidence threshold (80%) (2026-01-02 00:48)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 47.3% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 104 |
| Run Dir | `models/EXP-0050_IDEA-093` |

**Source**: TUNING_ANALYZER
**Category**: entry
**Hypothesis**: Top 20% confidence predictions should have significantly better win rates
**Result**: ERROR

---

### EXP-0051: Strict HMM regime filter (0.75/0.25) (2026-01-02 00:48)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 40.4% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 123 |
| Run Dir | `models/EXP-0051_IDEA-094` |

**Source**: TUNING_ANALYZER
**Category**: entry
**Hypothesis**: Trades aligned with strong HMM trends should perform better
**Result**: ERROR

---

### EXP-0049: High confidence threshold (75%) (2026-01-02 00:48)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 43.3% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 263 |
| Run Dir | `models/EXP-0049_IDEA-092` |

**Source**: TUNING_ANALYZER
**Category**: entry
**Hypothesis**: Higher confidence trades should have better outcomes
**Result**: ERROR

---


### EXP-0047: V3 + Jerry Features + Filter (best combo) (2026-01-01 16:53)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 34.9% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 1401 |
| Run Dir | `models/EXP-0047_IDEA-088` |

**Source**: CLAUDE
**Category**: architecture
**Hypothesis**: V3 (+1506%) + Features+Filter (+3.2% WR) = best combination
**Result**: ERROR

---

### EXP-0048: Enable options flow signal (2026-01-01 16:53)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 36.4% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 1435 |
| Run Dir | `models/EXP-0048_IDEA-089` |

**Source**: CLAUDE
**Category**: feature
**Hypothesis**: Put/call ratio provides additional directional confirmation
**Result**: ERROR

---


### EXP-0043: 5K: -6%/+35% wider TP from best config (2025-12-29 12:12)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 37.4% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 1153 |
| Run Dir | `models/EXP-0043_IDEA-83` |

**Source**: CLAUDE
**Category**: exit_strategy
**Hypothesis**: Wider TP may push to profitability
**Result**: ERROR

---

### EXP-0044: 5K: -7%/+30% looser stop from best config (2025-12-29 12:12)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 36.9% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 1703 |
| Run Dir | `models/EXP-0044_IDEA-84` |

**Source**: CLAUDE
**Category**: exit_strategy
**Hypothesis**: May reduce premature stop-outs while keeping good R:R
**Result**: ERROR

---

### EXP-0046: 5K: -5.5%/+30% split difference stop (2025-12-29 12:12)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 34.8% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 1245 |
| Run Dir | `models/EXP-0046_IDEA-86` |

**Source**: CLAUDE
**Category**: exit_strategy
**Hypothesis**: Fine-tune the stop loss level
**Result**: ERROR

---

### EXP-0045: 5K: -6%/+28% tighter TP from best (2025-12-29 12:12)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 41.0% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 1293 |
| Run Dir | `models/EXP-0045_IDEA-85` |

**Source**: CLAUDE
**Category**: exit_strategy
**Hypothesis**: Smaller target may increase win rate enough
**Result**: ERROR

---


### EXP-0039: 5K: very tight stop (-4%/+32%) = 8:1 (2025-12-29 11:46)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 52.0% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 388 |
| Run Dir | `models/EXP-0039_IDEA-075` |

**Source**: CLAUDE
**Category**: exit_strategy
**Hypothesis**: Extreme R:R may compensate for lower win rate
**Result**: ERROR

---

### EXP-0041: 5K: -5%/+25% = 5:1 R:R tighter (2025-12-29 11:46)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 44.1% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 272 |
| Run Dir | `models/EXP-0041_IDEA-077` |

**Source**: CLAUDE
**Category**: exit_strategy
**Hypothesis**: May have higher win rate with smaller swings
**Result**: ERROR

---

### EXP-0040: 20K validation: -6%/+30% best config (2025-12-29 11:46)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 38.4% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 4129 |
| Run Dir | `models/EXP-0040_IDEA-076` |

**Source**: CLAUDE
**Category**: validation
**Hypothesis**: 46.9% WR with 5:1 R:R should remain favorable
**Result**: ERROR

---

### EXP-0042: 20K validation: -5%/+30% best config (2025-12-29 11:46)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 45.5% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 3077 |
| Run Dir | `models/EXP-0042_IDEA-080` |

**Source**: CLAUDE
**Category**: validation
**Hypothesis**: 43.6% WR with 6:1 R:R at -$0.23/trade
**Result**: ERROR

---


### EXP-0038: 5K: -7%/+35% = 5:1 R:R wider (2025-12-29 10:15)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 36.1% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 1246 |
| Run Dir | `models/EXP-0038_IDEA-074` |

**Source**: CLAUDE
**Category**: exit_strategy
**Hypothesis**: May improve win rate while maintaining R:R
**Result**: ERROR

---

### EXP-0035: 5K test: ultra-wide TP (+50%) (2025-12-29 10:15)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 37.5% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 1120 |
| Run Dir | `models/EXP-0035_IDEA-071` |

**Source**: CLAUDE
**Category**: exit_strategy
**Hypothesis**: Very wide TP may capture larger moves
**Result**: ERROR

---

### EXP-0036: 5K test: moderate TP + loose stop (-12%/+20%) (2025-12-29 10:15)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 38.1% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 1203 |
| Run Dir | `models/EXP-0036_IDEA-072` |

**Source**: CLAUDE
**Category**: exit_strategy
**Hypothesis**: May reduce premature stop-outs
**Result**: ERROR

---

### EXP-0037: 5K: tighter stop (-5%/+30%) = 6:1 R:R (2025-12-29 10:15)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 35.6% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 1227 |
| Run Dir | `models/EXP-0037_IDEA-073` |

**Source**: CLAUDE
**Category**: exit_strategy
**Hypothesis**: Smaller losses with 46.9% win rate may turn profitable
**Result**: ERROR

---


### EXP-0034: 20K validation: -4%/+30% PROFITABLE CONFIG (2025-12-29 00:06)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 41.6% |
| P&L | -3.03% |
| Per-Trade P&L | $-1.70 |
| Trades | 89 |
| Run Dir | `models/EXP-0034_IDEA-082` |

**Source**: CLAUDE
**Category**: validation
**Hypothesis**: IDEA-078 showed +$0.27/trade profit at 5K - validate at scale
**Result**: FAIL

---


### EXP-0033: 5K: -4%/+25% = 6.25:1 R:R (2025-12-29 00:38)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 35.5% |
| P&L | -18.83% |
| Per-Trade P&L | $-1.04 |
| Trades | 903 |
| Run Dir | `models/EXP-0033_IDEA-081` |

**Source**: CLAUDE
**Category**: exit_strategy
**Hypothesis**: May have higher hit rate with smaller targets
**Result**: FAIL

---


### EXP-0032: 5K: extreme tight stop (-3%/+30%) = 10:1 (2025-12-28 20:57)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 46.8% |
| P&L | -9.61% |
| Per-Trade P&L | $-10.01 |
| Trades | 48 |
| Run Dir | `models/EXP-0032_IDEA-079` |

**Source**: CLAUDE
**Category**: exit_strategy
**Hypothesis**: High R:R with very tight stops
**Result**: FAIL

---


### EXP-0031: 5K: ultra-tight stop (-4%/+30%) = 7.5:1 (2025-12-28 20:31)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 44.1% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 34 |
| Run Dir | `models/EXP-0031_IDEA-078` |

**Source**: CLAUDE
**Category**: exit_strategy
**Hypothesis**: Trend: -6%:-$0.63, -5%:-$0.23, -4%:profit?
**Result**: ERROR

---


### EXP-0030: 5K test: wide TP + tighter stop (-6%/+30%) (2025-12-28 19:04)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 46.9% |
| P&L | -0.4% |
| Per-Trade P&L | $-0.63 |
| Trades | 32 |
| Run Dir | `models/EXP-0030_IDEA-069` |

**Source**: CLAUDE
**Category**: exit_strategy
**Hypothesis**: May improve per-trade P&L with better R:R
**Result**: FAIL

---


### EXP-0029: 5K test: very wide TP (+40%) (2025-12-28 18:39)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 11.1% |
| P&L | -0.93% |
| Per-Trade P&L | $-2.57 |
| Trades | 18 |
| Run Dir | `models/EXP-0029_IDEA-068` |

**Source**: CLAUDE
**Category**: exit_strategy
**Hypothesis**: Trend shows wider TP = better per-trade P&L
**Result**: FAIL

---


### EXP-0028: Protected pretrained + tighter stops (-5%/+15%) (2025-12-28 18:18)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 34.3% |
| P&L | -42.4% |
| Per-Trade P&L | $-2.52 |
| Trades | 842 |
| Run Dir | `models/EXP-0028_IDEA-053` |

**Source**: CLAUDE
**Category**: exit_strategy
**Hypothesis**: Quality-filtered trades with tighter stops improve per-trade P&L
**Result**: FAIL

---


### EXP-0027: v7 correct weights + tighter stops (-5%/+15%) (2025-12-28 17:46)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 33.9% |
| P&L | -72.34% |
| Per-Trade P&L | $-3.80 |
| Trades | 951 |
| Run Dir | `models/EXP-0027_IDEA-051` |

**Source**: CLAUDE
**Category**: exit_strategy
**Hypothesis**: Quality-filtered trades with tighter stops improve per-trade P&L
**Result**: FAIL

---


### EXP-0026: v6 fix + tighter stops (-5%/+15%) (2025-12-28 17:15)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 35.0% |
| P&L | -86.2% |
| Per-Trade P&L | $-3.67 |
| Trades | 1175 |
| Run Dir | `models/EXP-0026_IDEA-041` |

**Source**: CLAUDE
**Category**: exit_strategy
**Hypothesis**: Quality-filtered trades with tighter stops improve per-trade P&L
**Result**: FAIL

---


### EXP-0025: v5 fix + wider take profit (+20%) (2025-12-28 16:48)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 36.3% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 1224 |
| Run Dir | `models/EXP-0025_IDEA-033` |

**Source**: CLAUDE
**Category**: exit_strategy
**Hypothesis**: Quality trades may run further, capture more upside
**Result**: ERROR

---

### EXP-0024: v5 fix + tighter stops (-5%/+15%) (2025-12-28 16:48)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 37.7% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 1319 |
| Run Dir | `models/EXP-0024_IDEA-032` |

**Source**: CLAUDE
**Category**: exit_strategy
**Hypothesis**: Quality-filtered trades with tighter stops improve per-trade P&L
**Result**: ERROR

---

### EXP-0023: v3 fix + wider take profit (+20%) (2025-12-28 16:10)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 36.3% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 1266 |
| Run Dir | `models/EXP-0023_IDEA-027` |

**Source**: CLAUDE
**Category**: exit_strategy
**Hypothesis**: Quality trades may run further, capture more upside
**Result**: ERROR

---

### EXP-0022a: v3 fix + tighter stops (-5%/+15%) (2025-12-28 16:10)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 37.8% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 1458 |
| Run Dir | `models/EXP-0022_IDEA-026` |

**Source**: CLAUDE
**Category**: exit_strategy
**Hypothesis**: Quality-filtered trades with tighter stops improve per-trade P&L
**Result**: ERROR

---

### EXP-0022b: RL threshold loading fix v3 (2025-12-28 13:11)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 39.7% |
| P&L | -97.26% |
| Per-Trade P&L | $-7.62 |
| Trades | 638 |
| Run Dir | `models/EXP-0022_IDEA-025` |

**Source**: CLAUDE
**Category**: baseline
**Hypothesis**: With rl_threshold.pth actually LOADED, trade rate drops to 1-2%
**Result**: FAIL

---


### EXP-0019: Use long_run_20k pretrained state only (2025-12-28 15:05)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 39.6% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 989 |
| Run Dir | `models/EXP-0019_IDEA-012` |

**Source**: CLAUDE
**Category**: training
**Hypothesis**: The trained state has learned good features
**Result**: ERROR

---

### EXP-0020: Momentum-only entry (no HMM) (2025-12-28 15:05)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 34.5% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 1355 |
| Run Dir | `models/EXP-0020_IDEA-013` |

**Source**: CLAUDE
**Category**: entry_strategy
**Hypothesis**: HMM may be adding noise, pure momentum cleaner
**Result**: ERROR

---

### EXP-0021: Very tight stops (-3%) with medium TP (+8%) (2025-12-28 15:05)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 38.0% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 1354 |
| Run Dir | `models/EXP-0021_IDEA-014` |

**Source**: CLAUDE
**Category**: exit_strategy
**Hypothesis**: Tighter risk management may improve consistency
**Result**: ERROR

---

### EXP-0018: HMM + Neural + RLThreshold triple filter (2025-12-28 15:05)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 39.1% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | 1123 |
| Run Dir | `models/EXP-0018_IDEA-011` |

**Source**: CLAUDE
**Category**: entry_strategy
**Hypothesis**: Triple confirmation = highest quality trades
**Result**: ERROR

---


### EXP-0017: Tighter stops (-5%) with wider TP (+15%) (2025-12-28 11:39)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 39.9% |
| P&L | -69.49% |
| Per-Trade P&L | $-4.77 |
| Trades | 728 |
| Run Dir | `models/EXP-0017_IDEA-010` |

**Source**: CLAUDE
**Category**: exit_strategy
**Hypothesis**: Asymmetric in favor of winners should improve per-trade P&L
**Result**: FAIL

---


### EXP-0016: Stricter RLThresholdLearner base threshold (0.35) (2025-12-28 11:10)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | 39.5% |
| P&L | -73.6% |
| Per-Trade P&L | $-4.80 |
| Trades | 766 |
| Run Dir | `models/EXP-0016_IDEA-009` |

**Source**: CLAUDE
**Category**: entry_strategy
**Hypothesis**: Higher threshold = fewer trades = higher quality
**Result**: FAIL

---


### EXP-0015: VVIX (volatility of volatility) (2025-12-28 13:15)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | N/A% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | N/A |
| Run Dir | `models/EXP-0015_IDEA-008` |

**Source**: CLAUDE
**Category**: features
**Hypothesis**: VVIX spikes signal regime changes before VIX does
**Result**: ERROR

---

### EXP-0013: Fresh 3-month pretrained model (2025-12-28 13:15)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | N/A% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | N/A |
| Run Dir | `models/EXP-0013_IDEA-006` |

**Source**: CLAUDE
**Category**: training
**Hypothesis**: Pre-trained model on recent data performed best in previous tests
**Result**: ERROR

---

### EXP-0014: RMSNorm + GeGLU activations (2025-12-28 13:15)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | N/A% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | N/A |
| Run Dir | `models/EXP-0014_IDEA-007` |

**Source**: CLAUDE
**Category**: architecture
**Hypothesis**: Modern normalization and gated activations may improve prediction stability
**Result**: ERROR

---


### EXP-0012: Stricter HMM thresholds (0.75/0.25) (2025-12-28 13:13)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | N/A% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | N/A |
| Run Dir | `models/EXP-0012_IDEA-005` |

**Source**: CLAUDE
**Category**: entry_strategy
**Hypothesis**: Current 0.70/0.30 may be letting through marginal signals
**Result**: ERROR

---

### EXP-0010: Transformer temporal encoder (2025-12-28 13:13)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | N/A% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | N/A |
| Run Dir | `models/EXP-0010_IDEA-003` |

**Source**: CLAUDE
**Category**: architecture
**Hypothesis**: Attention mechanism may better capture important price patterns
**Result**: ERROR

---

### EXP-0009: Wider exits (-15%/+25%) (2025-12-28 13:13)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | N/A% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | N/A |
| Run Dir | `models/EXP-0009_IDEA-002` |

**Source**: CLAUDE
**Category**: exit_strategy
**Hypothesis**: Wider exits may catch bigger moves and reduce whipsaw exits
**Result**: ERROR

---

### EXP-0011: Shorter max hold (20 min) (2025-12-28 13:13)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | N/A% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | N/A |
| Run Dir | `models/EXP-0011_IDEA-004` |

**Source**: CLAUDE
**Category**: exit_strategy
**Hypothesis**: Predictions are for 15 min, holding 45 min causes drift. Shorter hold may align better.
**Result**: ERROR

---


### EXP-0006: Wider exits (-15%/+25%) (2025-12-28 12:04)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | N/A% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | N/A |
| Run Dir | `models/EXP-0006_IDEA-002` |

**Source**: CLAUDE
**Category**: exit_strategy
**Hypothesis**: Wider exits may catch bigger moves and reduce whipsaw exits
**Result**: ERROR

---

### EXP-0005: Symmetric exit ratios (-10%/+10%) (2025-12-28 12:04)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | N/A% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | N/A |
| Run Dir | `models/EXP-0005_IDEA-001` |

**Source**: CLAUDE
**Category**: exit_strategy
**Hypothesis**: Symmetric exits will improve risk/reward math and require lower win rate to profit
**Result**: ERROR

---

### EXP-0007: Transformer temporal encoder (2025-12-28 12:04)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | N/A% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | N/A |
| Run Dir | `models/EXP-0007_IDEA-003` |

**Source**: CLAUDE
**Category**: architecture
**Hypothesis**: Attention mechanism may better capture important price patterns
**Result**: ERROR

---

### EXP-0008: Shorter max hold (20 min) (2025-12-28 12:04)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | N/A% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | N/A |
| Run Dir | `models/EXP-0008_IDEA-004` |

**Source**: CLAUDE
**Category**: exit_strategy
**Hypothesis**: Predictions are for 15 min, holding 45 min causes drift. Shorter hold may align better.
**Result**: ERROR

---


### EXP-0002: Fresh 3-month pretrained model (2025-12-28 11:54)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | N/A% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | N/A |
| Run Dir | `models/EXP-0002_IDEA-006` |

**Source**: CLAUDE
**Category**: training
**Hypothesis**: Pre-trained model on recent data performed best in previous tests
**Result**: ERROR

---

### EXP-0001: Stricter HMM thresholds (0.75/0.25) (2025-12-28 11:54)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | N/A% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | N/A |
| Run Dir | `models/EXP-0001_IDEA-005` |

**Source**: CLAUDE
**Category**: entry_strategy
**Hypothesis**: Current 0.70/0.30 may be letting through marginal signals
**Result**: ERROR

---

### EXP-0003: RMSNorm + GeGLU activations (2025-12-28 11:54)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | N/A% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | N/A |
| Run Dir | `models/EXP-0003_IDEA-007` |

**Source**: CLAUDE
**Category**: architecture
**Hypothesis**: Modern normalization and gated activations may improve prediction stability
**Result**: ERROR

---

### EXP-0004: VVIX (volatility of volatility) (2025-12-28 11:54)

| Metric | Quick Test (5K) |
|--------|------------|
| Win Rate | N/A% |
| P&L | N/A% |
| Per-Trade P&L | N/A |
| Trades | N/A |
| Run Dir | `models/EXP-0004_IDEA-008` |

**Source**: CLAUDE
**Category**: features
**Hypothesis**: VVIX spikes signal regime changes before VIX does
**Result**: ERROR

---


This section is automatically updated by the Claude-Codex continuous optimizer.

### Summary Statistics

| Metric | Value |
|--------|-------|
| Best Win Rate | **59.8%** (dec_validation_v2) |
| Best Per-Trade P&L | **$338.86** (dec_validation_v2) |
| Best Total P&L | **+413.41%** (dec_validation_v2) |
| Parallel GPUs | 2x Tesla P40 |
| Experiments/Batch | 4 |

### Current Leaderboard

| Rank | Run | Win Rate | Per-Trade P&L | Total P&L | Trades | Date |
|------|-----|----------|---------------|-----------|--------|------|
| ðŸ¥‡ | **v3_10k_validation** | 34.5% | **$42.76** | **+1327%** | 1,552 | 2025-12-30 |
| ðŸ¥ˆ | **transformer_10k** | 34.5% | $17.73 | +801% | 2,260 | 2025-12-30 |
| 3 | dec_validation_v2 | 59.8% | $338.86 | +413% | 61 | 2025-12-24 |
| 4 | run_20251220_073149 | 40.9% | $1.40 | +85% | 7,407 | 2025-12-20 |

**Phase 28 Update**: V3 Multi-Horizon Predictor achieves +1327% P&L without pre-training!

### Automated Experiments Log

*Experiments will be logged here automatically as they complete.*

---

## Phase 22: Exit Reason Analysis (2025-12-29)

### Analysis Tool Created

`tools/analyze_exits.py` - Comprehensive exit reason analyzer that:
- Analyzes P&L distribution (buckets)
- Calculates win/loss asymmetry
- Infers exit reasons from SL/TP/hold time
- Identifies hold time patterns
- Provides actionable recommendations

### Key Findings

| Metric | Value | Issue |
|--------|-------|-------|
| Win Rate | 37.6% | Below 48.6% break-even |
| Avg Win | +$3.60 | OK |
| Avg Loss | -$3.41 | OK (similar to wins) |
| Win/Loss Ratio | 1.06:1 | Symmetric - need higher win rate |
| Loser Hold Time | 287 min | **2x longer than winners (138 min)** |
| Time Exits | ~87% | Most exits are NOT at SL/TP |

### Critical Insight

**The problem is NOT win/loss asymmetry.** With 1.06:1 ratio, we need 48.6% win rate.
We're getting 37.6%. The extra 10% gap comes from:

1. **Losers held too long** (287min vs 138min for winners)
2. **Time exits dominate** - trades exit mid-range, not at targets
3. **TP unreachable** - 12% target rarely hit within hold time

### Hold Time â†’ Win Rate Relationship

| Hold Time | Win Rate | Avg P&L | Implication |
|-----------|----------|---------|-------------|
| 15-30 min | 38.5% | -$0.71 | Near break-even |
| 30-45 min | 40.3% | -$0.55 | **Best window** |
| 2-4 hours | 25.0% | -$4.99 | Too long |
| 4+ hours | 21.9% | -$1.96 | Much too long |

### Proposed Controlled Experiments

**Path A: Exit Tuning (One Change)**

| Option | Change | Expected Impact |
|--------|--------|-----------------|
| A1 | TP: 12% â†’ 10% | More reachable target |
| A2 | max_hold: 20min â†’ 30min | Match best win rate window |

**Path B: Signal Quality (One Change)**

| Option | Change | Expected Impact |
|--------|--------|-----------------|
| B1 | min_confidence: 0.55 â†’ 0.65 | Fewer but higher quality |
| B2 | HMM threshold: 0.70 â†’ 0.75 | Stronger trend requirement |

### Fixes Applied

1. **Added exit_reason to database schema** - Future trades will track exact exit reason
2. **Fixed experiment runner regex** - Now handles `$+` format for positive P&L
3. **Resolved git conflicts** - RESULTS_TRACKER.md cleaned up

### Recommendation

Start with **A1 (TP: 10%)** as single controlled change against Phase 16 baseline.
Measure if per-trade P&L improves without degrading win rate.

---

## Phase 25: Extended Macro Features Test (2025-12-29)

### Goal
Test if adding 27 extended macro ETF symbols improves trading performance.

### Extended Macro Features
The extended macro features add 27 additional ETF symbols:
- **Index proxies**: IWM (small caps), SMH (semiconductors), RSP (equal weight)
- **Sector ETFs**: XLK, XLF, XLE, XLY, XLP, XLV, XLI, XLU, XLB, XLRE
- **Credit proxies**: HYG, LQD (credit spreads)
- **Commodities**: USO (oil), GLD (gold)
- **Mega-caps**: AAPL, MSFT, NVDA, AMZN, GOOGL, META

### Configuration Change
```json
"feature_pipeline": {
    "enable_extended_macro": true  // Was: false
}
```

### Test Results (5000 cycles)

| Metric | Baseline | Extended Macro | Improvement |
|--------|----------|----------------|-------------|
| **P&L** | +$25,465 (+509%) | **+$35,266 (+705%)** | **+38%** |
| **Trades** | 1,164 | 1,262 | +8% |
| **Per-Trade P&L** | ~$21.88 | **~$27.94** | **+28%** |
| **Final Balance** | $30,465 | **$40,266** | +32% |

### Key Findings

1. **Extended macro features provide significant improvement**
   - +38% higher total P&L
   - +28% higher per-trade P&L
   - More trades executed (better signal quality)

2. **Why extended macro works**
   - Sector rotation signals help identify market leadership
   - Credit spreads indicate risk appetite
   - Mega-cap moves often lead SPY
   - Breadth (RSP) signals confirm market health

3. **Data requirements**
   - Extended macro requires Data Manager to have 27 additional symbols
   - Feature dimension increases from ~50 to ~500

### Recommendation

**Enable extended macro features for improved performance.**

```json
"feature_pipeline": {
    "enable_extended_macro": true
}
```

### Run Directories
- Baseline: `models/phase25_baseline`
- Extended Macro: `models/phase25_extended_macro`

---

## Phase 25b: V3 Direction Predictor Test (2025-12-29)

### Goal
Test if V3 direction predictor (56% validation accuracy) combined with extended macro improves performance.

### Test Results (1812 cycles)

| Metric | Extended Macro (bandit) | V3 + Extended Macro |
|--------|-------------------------|---------------------|
| **P&L** | **+$12,000 (+240%)** | -$4,623 (-92.5%) |
| **Trades** | ~305 | 631 |
| **Balance** | $17,000 | $377 |

### Key Findings

1. **V3 direction predictor significantly underperforms bandit**
   - Despite 56% direction accuracy, V3 loses money
   - V3 generates 2x more trades but much lower quality

2. **Why V3 fails**
   - Binary UP/DOWN output lacks nuance
   - Doesn't integrate well with HMM regime detection
   - May be overfit to training period
   - Bandit's strict HMM thresholds (0.70/0.30) filter better

3. **Recommendation: DO NOT use V3 entry controller**

### Final Phase 25 Summary

| Configuration | P&L (5K cycles) | Trades | Per-Trade P&L |
|---------------|-----------------|--------|---------------|
| **Baseline (bandit, no ext macro)** | +$25,465 (+509%) | 1,164 | $21.88 |
| **Extended Macro + Bandit** | **+$35,266 (+705%)** | 1,262 | **$27.94** |
| V3 + Extended Macro | -$4,623 (-92.5%) | 631+ | -$7.33 |

### Best Configuration Found

```json
{
    "entry_controller": {
        "type": "bandit"
    },
    "feature_pipeline": {
        "enable_extended_macro": true
    }
}
```

**Extended macro features with bandit entry = +38% improvement over baseline**

---

## Phase 25c: 20K Validation Test (2025-12-29)

### Results

| Metric | 5K Test | 20K Validation |
|--------|---------|----------------|
| **P&L** | +$35,266 (+705%) | **-$3,800 (-76%)** |
| **Trades** | 1,262 | 3,936 |
| **Final Balance** | $40,266 | $1,200 |
| **Per-Trade P&L** | +$27.94 | **-$0.97** |

### Key Findings

1. **20K validation FAILED** - Strategy loses 76% over extended period
2. **Extreme volatility observed**:
   - Peak drawdown: -99% (balance hit $42)
   - Peak recovery: balance oscillated wildly
3. **5K results NOT reproducible** - The +705% was period-specific
4. **Extended periods expose weakness** - Strategy profitable in some windows, devastating in others

### Balance Trajectory During 20K Test

| Cycles | Balance | P&L |
|--------|---------|-----|
| 0 | $5,000 | 0% |
| 1,000 | $1,200 | -76% |
| 4,700 | $42 | -99% |
| 6,000 | $1,885 | -62% |
| 8,400 | $42 | -99% |
| 12,000 | $620 | -88% |
| 14,350 | $1,446 | -71% |
| 16,700 | $2,519 | -50% |
| 19,000 | $658 | -87% |
| 20,000 | $1,200 | -76% |

### Conclusion

**The extended macro features do NOT provide a consistent edge over longer periods.**

While the 5K test showed extended macro outperforming baseline by +38%, the 20K validation reveals:
- Both configurations are highly period-sensitive
- No robust edge exists across market regimes
- The strategy needs fundamental changes to be viable

### Recommendations

1. **Do NOT deploy with extended macro alone** - It doesn't fix underlying issues
2. **Extended macro is still BETTER than baseline** - Compare over same periods
3. **Focus on reducing volatility** - The wild swings indicate poor risk management
4. **Consider regime-based position sizing** - Trade smaller during unfavorable periods

---

## Phase 33: Experiments Database & Pretrained Model Tests (2026-01-01)

### Goal
1. Create SQLite database for experiment tracking (replace fragmented markdown/JSON)
2. Retrain model on Sep-Nov data to reproduce 60% win rate
3. Test combinations of pretrained + V3 + RSI/MACD

### Experiments Database

Created `tools/experiments_db.py` - SQLite-based tracking system:

```bash
# Import all 240 model runs
python tools/experiments_db.py scan

# Show leaderboard by P&L
python tools/experiments_db.py leaderboard --limit 20

# Search by win rate
python tools/experiments_db.py search --win-rate-min 0.40

# Show run details
python tools/experiments_db.py show <run_name>
```

**Database schema:** run_name, timestamp, start_date, end_date, initial_balance, final_balance, pnl, pnl_pct, cycles, signals, trades, win_rate, wins, losses, per_trade_pnl, training_time_seconds

### Pretrained Model Approach

Retrained model on Sep-Nov 2025 data (20K cycles):
- **Goal**: Reproduce the 60% win rate from dec_validation_v2
- **Approach**: Train on Sep-Nov data â†’ conservative NN outputs â†’ test on December

**Training Results (train_sep_nov_v2):**
| Metric | Value |
|--------|-------|
| Cycles | 20,000 |
| Trades | 2,590 |
| Win Rate | 39.1% |
| P&L | -90.60% |
| Wins/Losses | 1012/1577 |

Model saved to `models/pretrained/` for use with `LOAD_PRETRAINED=1`.

### Test Results (5K cycles, December 2025)

| Configuration | Win Rate | P&L | Trades | Notes |
|---------------|----------|-----|--------|-------|
| test_dec_pretrained | 36.4% | -90.46% | 926 | Pretrained on Dec |
| **v3_rsi_macd** | 34.3% | **-7.34%** | 466 | **Best P&L** |
| pretrained_rsi_macd | **37.7%** | -96.43% | 1,085 | Best WR but worst P&L |

### Key Findings

1. **V3 + RSI/MACD has best P&L** (-7.34%) due to fewer trades (466 vs 926-1085)
2. **Pretrained model alone doesn't reproduce 60%** - Only achieves 36.4%
3. **Adding RSI/MACD to pretrained hurts P&L** - More trades = more losses
4. **Trade selectivity matters more than win rate** - 466 trades @ 34.3% beats 1085 trades @ 37.7%

### Leaderboard (Top 10 by Win Rate with >10 trades)

| Rank | Run Name | Win Rate | P&L % | Trades |
|------|----------|----------|-------|--------|
| 1 | dec_validation | 60.6% | +519% | 63 |
| 2 | dec_validation_v2 | 59.8% | +413% | 61 |
| 3 | baseline_dec2025 | 59.8% | +413% | 61 |
| 4 | baseline_restored | 45.3% | +1334% | 639 |
| 5 | phase22_baseline | 44.8% | +180753% | 50 |
| 6 | reproduce_823pct | 43.3% | +3754% | 4320 |

Note: Very high P&L% values (>10000%) are from before the P&L calculation bug fix.

### Conclusion

The 60% win rate from dec_validation_v2 is NOT reproducible with simple retraining. The original pretrained model had specific learned weights that caused conservative predictions. Current approaches achieve ~37-40% win rate maximum.

**Best configurations for different goals:**
- **Maximize P&L**: V3 + RSI/MACD filter (`RSI_MACD_FILTER=1`)
- **Maximize Win Rate**: dec_validation_v2 approach (pretrained) - but original model is lost
- **20K Stable**: V3 Multi-Horizon (`PREDICTOR_ARCH=v3_multi_horizon`)

---

## Phase 34: Jerry's Quantor-MTFuzz Integration (2026-01-01)

### Goal
Integrate concepts from Jerry's Quantor-MTFuzz research to improve trading performance.

### Implementations

1. **Fuzzy Position Sizing** (HIGH priority) - `backend/paper_trading_system.py`
   - Formula: `g(F_t, Ïƒ*_t) = F_t Ã— (1 - Î² Ã— Ïƒ*_t)`
   - Reduces position size when confidence low or VIX high
   - Enable: `FUZZY_SIZING_ENABLED=1`

2. **MTF Consensus Weighting** (MEDIUM) - `bot_modules/neural_networks.py`
   - Weights V3 horizons: 5m=10%, 15m=20%, 30m=30%, 45m=40%
   - Enable: `MTF_CONSENSUS_ENABLED=1`

3. **Stochastic Exit Timing** (MEDIUM) - `backend/unified_exit_manager.py`
   - Exits profitable trades at 50-75% of max hold time
   - Enable: `STOCHASTIC_EXIT_ENABLED=1`

### Architecture Comparison Tests (5K cycles)

| Test | Win Rate | P&L | Trades | Per-Trade |
|------|----------|-----|--------|-----------|
| **test_baseline_v3** | 39.3% | +$75,306 (+1506%) | 1,274 | +$59.11 |
| test_core_only (no extended macro) | 35.0% | +$62,470 (+1249%) | 1,194 | +$52.32 |
| test_5m_horizon | 39.5% | +$35,215 (+704%) | 1,620 | +$21.74 |
| **V3 + Jerry Features** | 27.8% | +$22,532 (+451%) | 269 | **+$83.76** |

**Findings:**
- V3 baseline with all features performs best (+1506% P&L)
- V3 + Jerry Features has highest per-trade P&L (+$83.76) but fewer trades
- Jerry filter makes model 5x more selective (269 vs 1,274 trades)

### Jerry Features Experiment (5K cycles)

| Test | P&L | Win Rate | Trades | vs Baseline |
|------|-----|----------|--------|-------------|
| Baseline (No Jerry) | -2.8% | 33.1% | 2,026 | - |
| Jerry Features Only | -2.4% | 32.3% | 2,026 | +0.4% P&L |
| Jerry Filter Only | -2.5% | **35.6%** | 2,026 | +2.5% WR |
| **Features + Filter** | **-2.3%** | **36.3%** | 2,026 | **+0.5% P&L, +3.2% WR** |

### All-Combined Test (5K cycles)

Tested ALL Jerry features together:
- Jerry fuzzy features (NN inputs)
- Jerry filter (quality gate)
- Fuzzy position sizing
- MTF consensus weighting
- Stochastic exit timing
- RSI/MACD filter

| Test | P&L | Win Rate | Trades | vs Baseline |
|------|-----|----------|--------|-------------|
| Baseline (No Jerry) | -2.8% | 33.1% | 2,026 | - |
| Features + Filter | -2.3% | 36.3% | 2,026 | +0.5% P&L, +3.2% WR |
| **All Combined** | **-26.27%** | 34.8% | 1,148 | **-23.5% P&L, +1.7% WR** |

**Finding:** Combining ALL features is WORSE than simpler combinations!

### Key Findings

1. **Simpler is better** - Features + Filter (-2.3% P&L) beats All Combined (-26.27% P&L)
2. **Feature interference** - Multiple adjustment features conflict with each other
3. **Fuzzy sizing + stochastic exit** - Together they reduce gains more than losses
4. **Filter improves win rate most** - RSI/MACD filter alone adds +2.5% win rate
5. **V3 baseline still strong** - Extended macro features provide value (+1506% vs +704% for 5m-only)

### Recommended Configuration

For best performance, use **Features + Filter only** (not all combined):
```bash
# Jerry features (NN inputs only)
JERRY_FEATURES=1
JERRY_FILTER=1

# RSI/MACD filter
RSI_MACD_FILTER=1
RSI_OVERSOLD=30
RSI_OVERBOUGHT=70
MACD_CONFIRM=1

# V3 predictor (when testing architecture)
PREDICTOR_ARCH=v3_multi_horizon
```

**DO NOT combine:** Fuzzy sizing + MTF consensus + Stochastic exit - these interfere with each other.

---

## Phase 35: Confidence Calibration Fix (2026-01-02) âš ï¸ CRITICAL BUG

### Discovery

**CRITICAL FINDING: Model confidence does NOT predict outcomes!**

Analysis of 1,596 trades from tuning data revealed an inverse correlation:

| Confidence | Win Rate | Expected |
|------------|----------|----------|
| 0.2 | 38.8% | Should be lowest |
| 0.3 | 37.5% | Should be ~37% |
| 0.4 | 36.6% | **Should be highest** |

**Win rate DECREASES as confidence increases!** This means using raw confidence to filter trades was counterproductive.

### Root Cause

Found in `backend/rl_enhancements.py`:
- Calibration penalty only triggered for confidence > 0.7
- But 99% of trades have confidence 0.2-0.4
- No BCE loss against actual outcomes
- No reward for correct calibration

The confidence head learned to predict something, but NOT probability of profit.

### Solution Implemented

Enabled the existing `CalibrationTracker` system by default:

1. **PNL_CAL_GATE enabled by default** (`train_time_travel.py`)
   - Changed from `'0'` to `'1'`
   - Gates trades based on calibrated P(profit) >= 42%

2. **Calibrated confidence tracking** (`paper_trading_system.py`)
   - Added `calibrated_confidence` field to Trade dataclass
   - Persisted to database for analysis

3. **Database migration** (`migrate_add_tuning_fields.py`)
   - Added `calibrated_confidence REAL` column

4. **Enhanced summary output**
   - Shows calibration curve in training summary
   - Displays both raw and calibrated confidence

### CalibrationTracker System

Located in `backend/calibration_tracker.py`:
- Uses hybrid Platt scaling + isotonic regression
- Learns mapping: raw_confidence â†’ P(profit)
- Requires min 50 samples before gating
- Updates online after each trade

### Configuration

```bash
# Enabled by default now
PNL_CAL_GATE=1           # Use calibrated probability for entry gate
PNL_CAL_MIN_PROB=0.42    # Minimum calibrated P(profit) to trade
PNL_CAL_MIN_SAMPLES=50   # Samples before gating activates
```

### Verification Query

Check calibration quality with:
```sql
SELECT
    ROUND(calibrated_confidence, 1) as conf_bucket,
    COUNT(*) as trades,
    SUM(CASE WHEN pnl > 0 THEN 1 ELSE 0 END) * 100.0 / COUNT(*) as actual_win_rate
FROM trades
WHERE calibrated_confidence IS NOT NULL
GROUP BY conf_bucket
ORDER BY conf_bucket;
```

A well-calibrated model should show win rate â‰ˆ confidence bucket.

### Impact

- **All experiments using confidence thresholds need re-evaluation**
- IDEA-092 (75% conf) and IDEA-093 (80% conf) were filtering on UNCALIBRATED values
- The calibration gate should now properly select higher-quality trades
- Existing experiments with `MIN_CONFIDENCE_TO_TRADE` were using broken filtering

### Next Steps

1. Run baseline test with calibration gate enabled
2. Let calibration tracker learn from 50+ trades
3. Compare gated vs ungated performance
4. Consider adding BCE loss to predictor training

---

---

## Phase 35: DEC_VALIDATION_V2 Improvement Tests (2026-01-02)

### Goal
Rebuild and improve upon the 59.8% win rate model (dec_validation_v2).

### Background
The original 59.8% win rate was achieved through:
1. Training 20K+ cycles â†’ conservative neural network predictions
2. Bandit gate (20% conf, 0.08% edge) rejects 98% of signals
3. Only 2% highest-quality signals trade â†’ 59.8% WR, +$339/trade

### Training Period Results (Sept-Nov 2025, 10K cycles)

| Experiment | Win Rate | P&L | Trades | Per-Trade P&L | Notes |
|------------|----------|-----|--------|---------------|-------|
| EXP-35.4 Transformer | 35.8% | +$138,844 (+2777%) | 1,706 | +$81.39 | Transformer temporal encoder |
| EXP-35.5 V3 Multi-Horizon | 34.5% | +$155,927 (+3119%) | 902 | +$172.87 | V3 multi-horizon predictor |

**Key Finding:** V3 Multi-Horizon has 2x higher per-trade P&L (+$173 vs +$81) with half the trades. More selective entry.

### In Progress
- 20K cycle pretrain on Sept-Nov (rebuilding long_run_20k equivalent)
- Waiting to test pretrained model on December 2025 data

### Planned Tests
1. Confidence threshold variations (15%, 25%, 30%)
2. Exit configuration (tighter: -6%/+10%, wider: -10%/+15%)
3. Max hold time variations (30, 45, 60 minutes)


### December Validation Results (Out-of-Sample)

**Key Finding: Training P&L does NOT predict out-of-sample performance!**

| Model | Training P&L (Sept-Nov) | December P&L | Dec WR | Dec Trades |
|-------|------------------------|--------------|--------|------------|
| V3 Multi-Horizon | +3119% | **-3.34%** | 28.0% | 50 |
| Transformer | +2777% | **+32.65%** | 27.4% | 61 |

**Insights:**
1. V3 had 2x higher training P&L but LOST money on December
2. Transformer generalizes better despite lower training P&L
3. Win rates dropped ~8% from training to out-of-sample (35% â†’ 27%)
4. Both models became very selective (50-61 trades in 3K cycles)
5. The +32.65% December P&L from Transformer suggests some edge exists

**Implication:** Must validate all strategies on out-of-sample period before deployment.


### 20K Pretrain Results

| Metric | Training (Sept-Nov) | December (OOS) |
|--------|---------------------|----------------|
| P&L | +$187,664 (+3753%) | **-$198 (-3.95%)** |
| Win Rate | 38.0% | **18.4%** |
| Trades | 5,190 | 38 |

**Critical Finding:** 20K training produces selective model (38 trades from 3412 signals = 1.1%) but predictions are WRONG (18.4% WR).

### Complete Phase 35 Comparison

| Model | Training P&L | Dec P&L | Dec WR | Dec Trades | Status |
|-------|--------------|---------|--------|------------|--------|
| Transformer (10K) | +2777% | **+32.65%** | 27.4% | 61 | âœ… **BEST OOS** |
| V3 Multi-Horizon (10K) | +3119% | -3.34% | 28.0% | 50 | âŒ |
| 20K Pretrain | +3753% | -3.95% | 18.4% | 38 | âŒ |

**Conclusion:** 
1. **The 59.8% win rate from dec_validation_v2 is NOT reproducible** - those specific learned weights are lost
2. **Transformer encoder generalizes best** - only model profitable on December (+32.65%)
3. **Higher training P&L does NOT mean better generalization** - V3 had 3119% training but lost on Dec
4. **20K training made model too selective with wrong predictions** - 18.4% WR is worse than random

**Recommendation:** Use Transformer temporal encoder for production - it shows real generalization ability.

---

## Phase 36: Code Fixes and dec_validation_v2 Verification (2026-01-02)

### Goal
Verify if dec_validation_v2's 59.8% win rate and +413% P&L were affected by the P&L calculation bug.

### Code Fixes Applied

#### 1. Database Schema Compatibility Fix
**File:** `scripts/train_time_travel.py` (line 1365-1374)
```python
# Fixed: Check if run_id column exists before DELETE query
cursor.execute("PRAGMA table_info(trades)")
columns = [col[1] for col in cursor.fetchall()]
if 'run_id' in columns:
    cursor.execute("DELETE FROM trades WHERE run_id = ?", (run_name,))
else:
    logger.info("[SKIP] run_id column not in trades table")
```
**Problem:** `sqlite3.OperationalError: no such column: run_id`

#### 2. Auto-detect Pretrained Model Feature Dimension
**File:** `scripts/train_time_travel.py` (line 1206-1245)
```python
# Fixed: Auto-detect feature_dim from checkpoint instead of hardcoding 59
pretrained_model_path = os.environ.get('PRETRAINED_MODEL_PATH', "models/pretrained/trained_model.pth")
checkpoint = torch.load(pretrained_model_path, map_location='cpu')
pretrained_feature_dim = checkpoint['temporal_encoder.input_proj.weight'].shape[1]
```
**Problem:** `size mismatch for temporal_encoder.input_proj.weight: torch.Size([128, 59]) vs torch.Size([128, 50])`

### Model Analysis

| Model | Feature Dim | Location |
|-------|-------------|----------|
| dec_validation_v2 | 50 | models/dec_validation_v2/state/ |
| models/pretrained/predictor_v2.pt | 59 | Old model (Dec 28) |

### Verification Run Status
- **Run ID:** dec_v2_bugfix_verify
- **Model:** dec_validation_v2 pretrained (50 features)
- **Cycles:** 3000
- **Status:** Running

**Expected behavior:** Low trade rate (~1-2%) due to conservative pretrained NN predictions.

### P&L Bug Context

The P&L calculation bug (fixed in Phase 29) was:
- Missing SQL placeholder in `_save_trade()` - 49 columns but only 48 `?` placeholders
- Caused trades to be credited ~165x their actual value
- Fixed on 2026-01-01 by adding missing placeholder

**dec_validation_v2 was created on 2025-12-24** - potentially affected by the bug.

### Verification Results (2026-01-02)

**Run: dec_v2_dec2025_retest** - Testing pretrained model on December 2025 data

| Metric | Original (Dec 24) | With Bug Fix | Delta |
|--------|-------------------|--------------|-------|
| Win Rate | 59.8% | N/A | - |
| P&L | +413% | $0.00 | - |
| Trades | 61 | **0** | -61 |
| Per-Trade P&L | +$339 | N/A | - |
| Cycles | 2,995 | 3,000 | +5 |

**CRITICAL FINDING: 0 trades executed in 3,000 cycles**

### Root Cause Analysis

All signals were blocked by the bandit controller's edge threshold:
```
[UNIFIED BANDIT] Skipping: |ret|<0.08% (conf=22.4%, edge=+0.07%)
```

| Issue | Detail |
|-------|--------|
| Predicted edge | 0.01% - 0.07% (consistently) |
| Required edge | 0.08% minimum |
| Gap | Model predicts ~0.05% below threshold |

### Why Original Run Had Trades

The original dec_validation_v2 run (Dec 24, 2025) likely had:
1. **Pre-warmed feature buffer** - 60 timesteps of prior data
2. **Calibrated HMM state** - From previous training cycles
3. **Different market volatility** - Predictions respond to recent conditions

Starting fresh means the neural network produces different (lower) edge estimates.

### Conclusion

**The 59.8% win rate is NOT reproducible** with the current architecture because:
1. The pretrained model requires specific feature buffer state
2. Starting fresh produces predictions below the entry threshold
3. The model learned to be conservative, which means it needs warmup

**Recommendation:** The dec_validation_v2 win rate was a one-time result tied to specific conditions. Focus on transformer encoder which showed +32.65% OOS generalization (Phase 35).

---

## Phase 37: Transformer Test with Trade Closure Fix (2026-01-02)

### Goal
Run transformer encoder test after fixing the database schema that was preventing trades from closing properly.

### Database Schema Fix

**Problem:** `_save_trade()` in `paper_trading_system.py` was missing 15 columns introduced in earlier updates.

**Columns Added:**
| Column | Type | Purpose |
|--------|------|---------|
| `run_id` | TEXT | Model run identifier |
| `sequence_id` | INTEGER | Trade sequence number |
| `predicted_direction` | REAL | Neural network direction prediction |
| `prediction_confidence` | REAL | Model confidence score |
| `hmm_trend` | REAL | HMM trend state (0-1) |
| `hmm_volatility` | REAL | HMM volatility state |
| `hmm_liquidity` | REAL | HMM liquidity state |
| `hmm_confidence` | REAL | HMM confidence score |
| `vix_at_entry` | REAL | VIX level at entry |
| `regime_at_entry` | TEXT | Market regime classification |
| `edge_at_entry` | REAL | Predicted edge at entry |
| `stop_loss_price` | REAL | Stop loss trigger price |
| `take_profit_price` | REAL | Take profit trigger price |
| `planned_exit_time` | TEXT | Planned max hold exit time |
| `model_version` | TEXT | Model architecture version |

**Impact:** Without these columns, all `_save_trade()` calls failed silently due to `except Exception: pass`, causing trades to never close properly.

### Test Configuration

```batch
set TEMPORAL_ENCODER=transformer
set MODEL_RUN_DIR=models/transformer_jan2_test
set TT_MAX_CYCLES=2000
set TT_PRINT_EVERY=200
set PAPER_TRADING=True
set TRAINING_START_DATE=2025-12-15
set TRAINING_END_DATE=2025-12-31
```

### Results

| Metric | Value |
|--------|-------|
| Cycles Processed | 196 (of 615 timestamps, 31.9%) |
| Trades Executed | 35 |
| Win Rate | 37.0% |
| Starting Balance | $5,000 |
| Ending Balance | $1,200.36 |
| P&L | -$3,799.64 (-76.0%) |
| Data Range | Dec 24-26, 2025 (holiday period) |

### Trade Closure Verification

**CONFIRMED WORKING:** Trades now close properly with force-close events visible:
```
[FORCE_CLOSE] OrderType.CALL | Age: 46.0min | Premium: $2.30â†’$1.89 | P&L: -$27.93 (-18.3%)
[TRADE] Closed CALL trade | Entry: $2.16 â†’ Exit: $1.89 | P&L: -17.50%
```

### Signal Rejection Analysis

| Rejection Reason | Count |
|------------------|-------|
| Edge < 0.08% threshold | 90 |
| HMM confidence too low | 47 |
| Neural/HMM disagreement | 12 |
| Other filters | 41 |

### RL Threshold Learner Adaptation

| Metric | Value |
|--------|-------|
| Starting Threshold | 0.228 |
| Ending Threshold | 0.268 |
| Total Decisions | 45 |
| Trades Executed | 44 |
| Win Rate | 33.1% |

The learner raised the threshold by +17.5% as it observed poor outcomes, becoming more selective.

### Key Findings

1. **Trade closure bug is FIXED** - Trades now save to database and remove from active_trades properly
2. **Holiday period data is limited** - Only 196 valid cycles from Dec 24-26 (thin volume days)
3. **Win rate dropped from Phase 35** - 37% vs 47.8% (likely due to limited data quality)
4. **Threshold learner is working** - Adapted from 0.228 to 0.268 based on outcomes

### Why Results Differ from Phase 35

| Factor | Phase 35 | Phase 37 |
|--------|----------|----------|
| Training Period | Sept-Nov 2025 | Dec 15-31, 2025 |
| Test Period | Dec 2025 | Dec 24-26 only |
| Market Conditions | Normal | Holiday/thin |
| Data Quality | Good | 31.9% valid |
| Win Rate | 47.8% | 37.0% |
| P&L | +32.65% | -76.0% |

### Conclusion

The database schema fix resolved the trade closure bug - trades now properly save and close. However, the Dec 24-26 holiday period is not representative for testing due to thin volume and limited data availability (only 31.9% of timestamps had complete data).

**Recommendation:** Run a proper validation test on a non-holiday period with the fixed schema to get representative results. The transformer encoder remains the recommended architecture based on Phase 35's OOS generalization results.

---

## Phase 36b: Skew-Optimized Exits Validation (2026-01-02) âœ… VALIDATED

### Summary

Testing skew-optimized exit strategy (partial TP + trailing runner) to capture fat-tail winners.

### 5K Experiment Results

| Experiment | P&L | Trades | $/Trade | vs Baseline |
|------------|-----|--------|---------|-------------|
| **v4_skew_partial** ðŸ† | **$8,817 (+176%)** | 66 | **$133.60** | **+69%** |
| v4_baseline (control) | $6,340 (+127%) | 80 | $79.25 | - |
| v4_skew_trailing | $5,568 (+111%) | 88 | $63.27 | -20% |
| v4_skew_trend_adaptive | $4,246 (+85%) | 72 | $58.98 | -26% |
| v4_ev_gate | -$1 | 5 | -$0.17 | âŒ too restrictive |
| v4_combined | -$83 | 69 | -$1.20 | âŒ |

### 20K Validation Results âœ…

| Metric | 5K Test | 20K Validation |
|--------|---------|----------------|
| **P&L** | +$8,817 (+176%) | **+$21,549 (+431%)** âœ… |
| **Trades** | 66 | 586 |
| **$/Trade** | $133.60 | $36.77 |
| **Win Rate** | 42.0% | 31.6% |

### Key Insights

1. **Win rate dropped from 42% to 31.6%, but P&L stayed strongly positive** - validates skew hypothesis
2. **Edge comes from fat-tail winners, not win rate** - partial TP + trailing runner captures outliers
3. **EV gate too restrictive** - only 5 trades in 5K cycles at -2% min threshold
4. **IDEA-134 filters didn't help** - inverted confidence + consensus produced -$22 (44 trades)

### Winning Configuration

```bash
SKEW_EXIT_ENABLED=1
SKEW_EXIT_MODE=partial
PARTIAL_TP_PCT=0.10          # Take 50% at 10% gain
PARTIAL_TAKE_FRACTION=0.50   # Take half
RUNNER_TRAIL_ACTIVATION=0.15 # Activate trailing at 15%
RUNNER_TRAIL_DISTANCE=0.05   # 5% trailing stop
```

### Components Reference

| Component | File | Purpose |
|-----------|------|---------|
| Skew Exit Manager | `backend/skew_exit_manager.py` | Partial TP + trailing runner |
| EV Gate | `backend/ev_gate.py` | EV gating (disabled - too restrictive) |
| Test Suite | `tests/test_architecture_v4.py` | Component tests |
| Presets | `configs/winning_presets.sh` | Pre-configured environments |
| Documentation | `docs/ARCHITECTURE_IMPROVEMENTS_V4.md` | Full docs |

---

## Phase 38: Transformer + Skew Exits Combined (2026-01-02)

### Goal

Test combining the two validated improvements:
1. **Transformer encoder** - Best OOS generalization (+32.65% on Dec 2025, Phase 35)
2. **Skew exits (partial)** - Best in-sample performance (+431% in 20K, Phase 36b)

### Test Results (5K cycles each)

| Configuration | P&L | Trades | $/Trade | Win Rate |
|---------------|-----|--------|---------|----------|
| **Transformer + Skew** | **+$4,399 (+88%)** | 115 | **$38.25** | 26.1% |
| Transformer only | +$1,772 (+35%) | 130 | $13.63 | 47.0% |

### Key Finding: Skew Exits Improve Transformer by 2.5x

- $/Trade increased from $13.63 to $38.25 (+180%)
- Total P&L increased from +35% to +88% (+151%)
- Win rate dropped from 47% to 26% (expected with skew strategy)

### Comparison with TCN Architecture

| Architecture | + Skew Exits | P&L | $/Trade |
|--------------|--------------|-----|---------|
| TCN (default) | Yes | +$8,817 (+176%) | $133.60 |
| **Transformer** | **Yes** | +$4,399 (+88%) | $38.25 |
| TCN (default) | No | +$6,340 (+127%) | $79.25 |
| Transformer | No | +$1,772 (+35%) | $13.63 |

### Insights

1. **TCN + Skew still leads** in absolute in-sample performance
2. **Skew exits improve BOTH architectures** - TCN by 69%, Transformer by 180%
3. **Transformer may generalize better OOS** - Phase 35 showed +32.65% OOS vs TCN's untested OOS
4. **Win rate is not the goal** - 26% WR with $38/trade beats 47% WR with $14/trade

### Recommended Configurations

**For In-Sample Performance (TCN + Skew):**
```bash
SKEW_EXIT_ENABLED=1
SKEW_EXIT_MODE=partial
python scripts/train_time_travel.py
```

**For OOS Generalization (Transformer + Skew):**
```bash
TEMPORAL_ENCODER=transformer
SKEW_EXIT_ENABLED=1
SKEW_EXIT_MODE=partial
python scripts/train_time_travel.py
```

### Next Steps

1. Run 20K validation of transformer + skew to confirm OOS behavior
2. Test on truly out-of-sample data (January 2026)
3. Consider live paper trading test with best configuration

---

## Current Best Configurations Summary

| Rank | Configuration | Validated P&L | P&L/DD | $/Trade | Best For |
|------|---------------|---------------|--------|---------|----------|
| **1** | **SKIP_MONDAY** | **+1630% (20K)** | **35.03** | **$276.31** | **BEST OVERALL** |
| 2 | TCN + Skew Partial | +431% (20K) | ~9.3 | $36.77 | In-sample |
| 3 | Transformer + Skew | +88% (5K) | ~2.0 | $38.25 | OOS potential |
| 4 | Transformer Only | +32.65% OOS | ~1.5 | $13.63 | Generalization |
| 5 | TCN Baseline | +127% (5K) | ~2.7 | $79.25 | Simplicity |

### NEW BEST: SKIP_MONDAY Configuration (2026-01-06)

**Model:** `models/COMBO_SKIP_MONDAY_20K`

| Metric | Value |
|--------|-------|
| **P&L** | +$81,512 (+1630.24%) |
| **P&L/DD Ratio** | **35.03** |
| **Max Drawdown** | 46.54% |
| **Win Rate** | 43.0% (165 W / 219 L) |
| **Total Trades** | 295 |
| **Cycles** | 20,000 |

**Environment Variables:**
```bash
USE_TRAILING_STOP=1
TRAILING_ACTIVATION_PCT=10
TRAILING_STOP_PCT=5
ENABLE_TDA=1
TDA_REGIME_FILTER=1
TRAIN_MAX_CONF=0.25
DAY_OF_WEEK_FILTER=1
SKIP_MONDAY=1
SKIP_FRIDAY=0
```

**Key Findings:**
1. Monday has only 23% WR historically - skipping it improves overall performance by ~10%
2. Low confidence filter (<25%) is counter-intuitively better - high confidence = overconfident on hard trades
3. Trailing stop (10% activation, 5% trail) locks in profits and reduces drawdowns
4. P&L/DD ratio of 35.03 is exceptional (35% return per 1% drawdown)

---

## Phase 39: Inverted Confidence Filter & Skew Exit Integration (2026-01-02)

### Key Finding: ML Confidence is Anti-Predictive

Analysis of confidence data from recent runs revealed a counter-intuitive pattern:

| Confidence Bucket | Trades | Win Rate | Avg P&L |
|-------------------|--------|----------|---------|
| Low (<0.3) | 294 | **38.4%** | **+$5.61** |
| Med-Low (0.3-0.5) | 301 | 25.2% | -$2.85 |

**Higher ML confidence = LOWER win rate and NEGATIVE P&L**

The model's high-confidence predictions are actually anti-predictive for intraday trades.

### Implementation: Inverted Confidence Filter

Added `TRAIN_MAX_CONF` environment variable to filter OUT high-confidence trades:

```bash
# Filter out trades with confidence > 35%
TRAIN_MAX_CONF=0.35 python scripts/train_time_travel.py
```

### Test Results (5K cycles)

| Configuration | P&L | Trades | $/Trade |
|---------------|-----|--------|---------|
| **Inverted (max=0.35)** | **+990%** | 813 | $60.90 |
| Baseline (no max) | +962% | 730 | $65.89 |

The inverted confidence filter shows a **+28 percentage point improvement** in total P&L while generating more trades.

### Skew Exit Integration Fix

Fixed the skew exit manager integration:
- **Issue**: SkewExitManager existed but was not wired into actual exit flow
- **Previous location**: `unified_exit_manager.py` (not used during training)
- **Fixed location**: `backend/paper_trading_system.py` (actual exit processing)

Changes:
1. Integrated skew exit check before XGBoost exit policy
2. Fixed None value handling for `current_premium` and `max_gain_pct`
3. Skew exit now properly evaluates partial TP + trailing runner logic

### Files Modified

| File | Changes |
|------|---------|
| `backend/safety_filter.py` | Added `veto_max_confidence` option + env override |
| `backend/arch_config.py` | Added `veto_max_confidence` config |
| `backend/arch_v2.py` | Pass `veto_max_confidence` to filter |
| `scripts/train_time_travel.py` | Added `TRAIN_MAX_CONF` quality gate |
| `backend/paper_trading_system.py` | Integrated SkewExitManager properly |
| `backend/unified_exit_manager.py` | Added skew exit (backup integration) |

### Commits

- `095d56d` - Add inverted confidence filter and proper skew exit integration
- `08198e2` - Fix skew exit integration - wire into paper_trading_system.py
- `4f12fe2` - Fix None value handling in skew exit integration

### Recommended Usage

```bash
# Best configuration: Inverted confidence filter
TRAIN_MAX_CONF=0.35 python scripts/train_time_travel.py

# Combined with skew exits (experimental)
TRAIN_MAX_CONF=0.35 SKEW_EXIT_ENABLED=1 SKEW_EXIT_MODE=partial python scripts/train_time_travel.py
```

### Next Steps

1. Test combined: inverted confidence + skew exits âœ… (see Phase 40)
2. Run 20K validation of inverted confidence filter
3. Consider setting `TRAIN_MAX_CONF=0.35` as default

---

## Phase 40: Confidence Threshold Tuning & Calibration Bug Fix (2026-01-02)

### Key Finding: Stricter Confidence = Better Per-Trade P&L

Tested different maximum confidence thresholds:

| Test | TRAIN_MAX_CONF | P&L | Trades | $/Trade | Notes |
|------|----------------|-----|--------|---------|-------|
| **conf_max_25** | 0.25 | **+104%** | 26 | **+$200.37** | Best $/trade |
| conf_max_30 | 0.30 | +0.04% | 60 | +$0.04 | Break-even |
| inverted_plus_skew | 0.35 | -0.83% | 75 | -$0.55 | Slight loss |

**Stricter thresholds (lower max confidence) = Fewer but higher quality trades**

The conf_max_25 configuration shows that:
- Only trading when confidence < 0.25 yields best per-trade P&L
- Very selective (26 trades in 3000 cycles)
- +$200/trade average (vs baseline ~$60/trade)

### Critical Bug Fix: PNL Calibration Not Learning

**Issue**: CalibrationTracker showed 0 samples despite trades closing.

**Root Cause**: `get_recent_closed_trades()` returned trades from ALL runs (ordered by exit_timestamp), but `record_trade_entry()` only tracked the CURRENT run's trade IDs. Result: trade_id mismatch â†’ calibration never learned.

**Fix Applied** in `backend/paper_trading_system.py`:
1. Added `run_id` parameter to `get_recent_closed_trades()`
2. Function now uses `current_run_id` to filter trades
3. Only returns trades from the current run, ensuring ID match

```python
def get_recent_closed_trades(self, limit: int = 10, run_id: Optional[str] = None) -> list:
    effective_run_id = run_id or getattr(self, 'current_run_id', None)
    if effective_run_id:
        cursor.execute('''SELECT ... WHERE ... AND run_id = ?''', (effective_run_id, limit,))
```

Also added `hold_time_minutes` to the returned trade dict for calibration tracking.

### Files Modified

| File | Changes |
|------|---------|
| `backend/paper_trading_system.py` | Fixed `get_recent_closed_trades()` to filter by run_id |

### Commits

- TBD - This commit

### Recommended Configuration

Based on Phase 39-40 findings:

```bash
# Best per-trade P&L: Ultra-strict confidence filter
TRAIN_MAX_CONF=0.25 python scripts/train_time_travel.py

# Balanced: More trades, still profitable
TRAIN_MAX_CONF=0.35 python scripts/train_time_travel.py
```

### Why Low Confidence = Better Trades

Hypothesis: The model's high confidence often signals:
- Obvious patterns that are already priced in
- Strong momentum that's about to reverse
- Crowd consensus that market makers fade

Low confidence signals:
- Uncertainty that creates edge opportunities
- Contrarian setups with asymmetric payoff
- Less crowded trades

---


## Phase 42: 65% Win Rate Achieved! (2026-01-02)

### Goal
Achieve 60%+ win rate through optimized filtering.

### Research-Backed Approach
Based on Codex research on 0DTE trading:
- **10% profit target** = highest win rates (~90%)
- **50% stop loss** = let trades breathe
- **First 1-2 hours best** for directional trades
- **Monday/Friday volatile** - skip these days

### Test Results (5K cycles each)

| Configuration | Win Rate | P&L | Trades | $/Trade | Notes |
|---------------|----------|-----|--------|---------|-------|
| **combo_dow** | **65.0%** | +11.5% | 19 | +$30.36 | ðŸŽ¯ **TARGET ACHIEVED!** |
| combo | 58.6% | +28.8% | 26 | +$55.37 | Strong |
| inv_conf_only | 52.0% | +41.3% | 21 | +$98.29 | Best $/trade |
| wide_small | 46.2% | +54.8% | 73 | +$37.55 | Best P&L |
| tp_5 | 43.1% | -0.9% | 58 | -$0.81 | 5% TP too tight |
| combo_tp8 | 33.3% | -0.3% | 21 | -$0.63 | 8% TP hurts |
| ultra_selective | 0% | 0% | 0 | N/A | 0.20 conf too strict |

### Winning Configuration: combo_dow

| Parameter | Value | Rationale |
|-----------|-------|-----------|
| HARD_STOP_LOSS_PCT | 50% | Wide stops let trades breathe |
| HARD_TAKE_PROFIT_PCT | 10% | Small TP = high win rate |
| TRAIN_MAX_CONF | 0.25 | Inverted confidence filter |
| DAY_OF_WEEK_FILTER | 1 | Skip volatile days |
| SKIP_MONDAY | 1 | Monday = volatile |
| SKIP_FRIDAY | 1 | Friday = volatile |

### Command to Run

```bash
HARD_STOP_LOSS_PCT=50 HARD_TAKE_PROFIT_PCT=10 TRAIN_MAX_CONF=0.25 \
DAY_OF_WEEK_FILTER=1 SKIP_MONDAY=1 SKIP_FRIDAY=1 \
python scripts/train_time_travel.py
```

### Key Insights

1. **Wide stops + small TP** is the key to high win rate
   - 50% stop prevents premature exits
   - 10% TP locks in small wins consistently

2. **Inverted confidence works** - trading low confidence signals yields better results

3. **Day of week matters** - Monday and Friday are noisier, Tue-Thu more predictable

4. **Trade-off exists**:
   - 65% win rate â†’ +11.5% P&L (combo_dow)
   - 46% win rate â†’ +54.8% P&L (wide_small)
   - Higher win rate = lower total P&L due to fewer trades

### Bugs Fixed in Phase 42

1. **VIX filter using wrong variable**: Changed from `signal.get('vix_level')` to `vix_for_rl`
2. **Momentum filter using wrong variable**: Changed from `signal.get('momentum_5m')` to `momentum_5min`

### Next Steps

1. Validate 65% win rate on 20K cycles
2. Test combo_dow in live trading
3. Consider 60% SL for even higher win rate

---

## Phase 43: Attempts to Improve 65% Win Rate (2026-01-02)

### Goal
Improve beyond the 65% win rate achieved by combo_dow configuration.

### Test Results (5K cycles each)

| Configuration | Win Rate | P&L | Trades | Change |
|---------------|----------|-----|--------|--------|
| **combo_dow (baseline)** | **65.0%** | +11.5% | 19 | - |
| tp12 (12% TP) | 47.1% | +22.1% | 17 | -18% |
| vix_filter (+VIX 12-28) | 46.7% | -0.01% | 30 | -18% |
| momentum (+momentum) | 46.2% | -5.7% | 13 | -19% |
| tue_wed (Tue-Wed only) | 42.4% | +20.8% | 33 | -23% |
| conf22 (conf<0.22) | 42.1% | +67.9% | 19 | -23% |
| tp6_sl40 (6%TP/40%SL) | 40.0% | +2.9% | 10 | -25% |
| tp15 (15% TP) | 30.4% | +43.9% | 23 | -35% |
| tp8 (8% TP) | 28.6% | +47.7% | 29 | -36% |
| wider_60 (60% SL) | 12.5% | +24.1% | 21 | -53% |

### Key Findings

1. **65% win rate is a local optimum** - No configuration tested improved on it
2. **Higher TP hurts win rate** - 12% and 15% TP both reduced win rate
3. **Lower TP also hurts** - 8% and 6% TP reduced win rate even more
4. **Additional filters hurt** - VIX and momentum filters reduced win rate
5. **More restrictive days hurt** - Tue-Wed only was worse than Tue-Wed-Thu
6. **Stricter confidence hurts** - 0.22 max worse than 0.25 max
7. **Wider stops hurt dramatically** - 60% SL was catastrophic (12.5% WR)

### Optimal Configuration Confirmed

```bash
# Best Win Rate (65%) - combo_dow
HARD_STOP_LOSS_PCT=50 HARD_TAKE_PROFIT_PCT=10 TRAIN_MAX_CONF=0.25 \
DAY_OF_WEEK_FILTER=1 SKIP_MONDAY=1 SKIP_FRIDAY=1 \
python scripts/train_time_travel.py
```

### Trade-off Analysis

| Goal | Configuration | Win Rate | P&L |
|------|---------------|----------|-----|
| Max Win Rate | combo_dow | 65% | +11.5% |
| Max P&L | conf22 | 42% | +67.9% |
| Balanced | wide_small | 46% | +54.8% |

### Next Steps

To improve beyond 65% would require:
1. Fundamental model improvements (better prediction accuracy)
2. Different market/asset (not 0DTE SPY options)
3. Different strategy (selling premium instead of buying)

---

## Phase 44: Advanced Signal Integration (2026-01-03)

### Goal
Test advanced signal techniques identified from research to improve beyond 65% win rate.

### Techniques Tested

1. **Multi-Indicator Stacking** - 8+ technical indicators (RSI, MACD, Bollinger, Stochastic, ATR, OBV, etc.)
2. **GEX/Gamma Signals** - Dealer positioning proxy using put/call ratios
3. **Order Flow Imbalance** - Buy/sell volume tracking (placeholder data)
4. **Combined** - All signals together

### Test Results (5K cycles each, combo_dow base config)

| Configuration | Win Rate | P&L | Trades | Per-Trade |
|---------------|----------|-----|--------|-----------|
| **Multi-Indicator** | **50.0%** | -$4.86 | 36 | -$0.14 |
| Combined (all) | 46.3% | +$0.44 | 41 | +$0.01 |
| GEX Signals | 44.4% | +$1.15 | 18 | +$0.06 |
| Baseline | 36.1% | -$35.82 | 36 | -$0.99 |
| Order Flow | 26.7% | -$8.17 | 15 | -$0.54 |

### Key Findings

1. **Multi-Indicator improved win rate by 14 percentage points** (36.1% â†’ 50.0%)
2. **GEX signals more selective** - Reduced trades from 36 to 18 with positive P&L
3. **Order flow hurt performance** - Placeholder data is noise, not signal
4. **Combined not better than multi-indicator alone** - Noisy signals dilute good ones

### Win Rate Variance Observed

Note: Baseline showed 36.1% vs Phase 42's 65% with same config. This variance (29 percentage points!) demonstrates:
- Significant run-to-run variance in 5K cycle tests
- 65% may have been a favorable sample
- Need longer tests (10K+) for reliable comparison

### Multi-Indicator Details

The multi-indicator stack uses:
- RSI (14) with normalized 0-1 score
- MACD signal crossover
- Bollinger Band position
- Stochastic %K/%D
- ATR normalized volatility
- OBV momentum
- Momentum (10-period)
- Moving average crossover (9/21 EMA)

Composite score: Average of all indicators, scaled -1 to +1

### Environment Variables

```bash
# Multi-Indicator Stacking (best result)
MULTI_INDICATOR_ENABLED=1 python scripts/train_time_travel.py

# GEX Signals
GEX_SIGNALS_ENABLED=1 python scripts/train_time_travel.py

# Order Flow (not recommended - needs real data)
ORDER_FLOW_ENABLED=1 python scripts/train_time_travel.py
```

### Ensemble Stacking Results (Added 2026-01-03)

| Configuration | Win Rate | P&L | Trades | Notes |
|---------------|----------|-----|--------|-------|
| **Pre-trained Ensemble** | **50.0%** | -$23.56 | 38 | Trained on 1.5M samples |
| Ensemble v2 (integrated) | 35.5% | -$9.69 | 31 | Untrained weights = noise |
| Ensemble v1 (not integrated) | 29.2% | -$16.27 | 24 | Code initialized but not used |

**Pre-training Details**:
- Loaded decision records from 200+ past experiments (1.5M samples)
- Trained TCN, LSTM, and XGBoost on feature sequences
- Labels: 15-minute momentum (actual price movement)
- Meta-learner combines all three predictions

**Result**: Pre-trained ensemble achieved 50% win rate - same as multi-indicator stack.

**Usage**:
```bash
# First pre-train (one-time)
python scripts/train_ensemble.py

# Then use pre-trained ensemble
ENSEMBLE_ENABLED=1 ENSEMBLE_PRETRAINED=1 python scripts/train_time_travel.py
```

### Variance Investigation

**Critical Finding**: Same combo_dow config produced vastly different results:
- Phase 42: 65% win rate (13W/7L, 19 trades)
- Phase 44: 36% win rate (13W/23L, 36 trades)

Same 13 wins, but 16 extra losses! The 65% may have been a favorable sample. 5K cycle tests show high variance.

### Conclusion

Both multi-indicator stacking and pre-trained ensemble achieved **50% win rate** - a 14pp improvement over the Phase 44 baseline (36.1%). However, there's high variance between runs.

Recommendation: Run 10K-20K cycle tests to get reliable metrics and investigate why Phase 42 had fewer total trades.

---

## Phase 45: Variance Investigation & Bug Fix (2026-01-03)

### Goal
Investigate why Phase 42's 65% win rate couldn't be reproduced in Phase 44 baseline tests (36%).

### Bug Found: Environment Variable Override

**Problem**: `TT_STOP_LOSS_PCT` and `TT_TAKE_PROFIT_PCT` env vars were being ignored!

**Root Cause**:
1. `ExitConfig` correctly reads env vars at startup
2. BUT `UnifiedOptionsBot.__init__()` overwrites with `config.json` values AFTER ExitConfig
3. Evidence: Logs showed `stop=50.0%` from ExitConfig but then `Set stop loss to 8.0%` from bot

**Fix Applied** (commit `04d70e5`):
Added explicit override after bot creation in `train_time_travel.py`:
```python
# Override stop_loss and take_profit from env vars (takes precedence over config.json)
if os.environ.get('TT_STOP_LOSS_PCT'):
    sl_pct = float(os.environ['TT_STOP_LOSS_PCT']) / 100.0
    bot.paper_trader.stop_loss_pct = sl_pct
if os.environ.get('TT_TAKE_PROFIT_PCT'):
    tp_pct = float(os.environ['TT_TAKE_PROFIT_PCT']) / 100.0
    bot.paper_trader.take_profit_pct = tp_pct
```

### Random Seed Support Added
Added reproducibility via `RANDOM_SEED` env var (defaults to 42):
```python
RANDOM_SEED = int(os.environ.get('RANDOM_SEED', '42'))
random.seed(RANDOM_SEED)
np.random.seed(RANDOM_SEED)
torch.manual_seed(RANDOM_SEED)
```

### Variance Test Results (5K cycles, combo_dow config)

| Run | Seed | Win Rate | P&L | Trades | Notes |
|-----|------|----------|-----|--------|-------|
| phase42_combo_dow | Unknown | 65.0% | +11.5% | 19 | Original (before fix) |
| seed42_test | 42 | 33.3% | -0.3% | 21 | After fix |
| variance_v1 | 42 | 29.4% | -0.1% | 17 | After fix |
| phase42_reload | 42 | 35.6% | -0.4% | 45 | Before fix (wrong stops) |

### Extended Test Results

| Run | Seed | Cycles | P&L | Win Rate | Trades | Notes |
|-----|------|--------|-----|----------|--------|-------|
| **combo_dow_10k** | 42 | 10,000 | **+48.8%** | 25.5% | 46 (13W/38L) | Best P&L |
| **seed123_test** | 123 | 5,000 | **-1.8%** | 40.3% | 67 (27W/40L) | More wins, lost money |

### Critical Insight: Win Rate vs P&L

| Metric | Seed 42 (10K) | Seed 123 (5K) |
|--------|---------------|---------------|
| **P&L** | **+48.8%** | -1.8% |
| Win Rate | 25.5% | 40.3% |
| Wins | 13 | **27** |
| Losses | 38 | 40 |

**Counterintuitive!** Seed 123 had:
- **2x more wins** (27 vs 13)
- **Higher win rate** (40% vs 25%)
- But **LOST money** (-1.8%) while seed 42 made +48.8%

This proves **win SIZE matters more than win COUNT**:
1. Seed 42's 13 wins were likely large (trending moves)
2. Seed 123's 27 wins were likely small (choppy market)
3. Win rate alone tells you NOTHING about profitability

### Key Findings

1. **Env var bug confirmed**: Before fix, 50% stop loss was being ignored, using 8% from config
2. **Trade count difference**: Phase 42 had 19 trades, 10K had 46 trades (same 13 wins!)
3. **Win rate is misleading**: 25% win rate made +48.8% P&L vs 65% making +11.5%
4. **65% win rate was lucky**: A favorable sequence of trades in the original run

### Implications

1. **Short backtests (5K cycles) are unreliable** - Results can vary Â±30% P&L based on random seed
2. **Win rate is highly variable** - Same config can show 29% to 65% depending on trade sequence
3. **Need 10K+ cycle tests** - To get statistically meaningful results
4. **Live trades affect backtests** - Paper trading system loads real trades from database

### Recommendations

1. Always use 10K+ cycle tests for reliable metrics
2. Run multiple seeds (42, 123, 456) and average results
3. Consider isolating backtest database from live trades
4. Focus on per-trade P&L consistency rather than absolute win rate

---

## Phase 48: Confidence Calibration Improvements (2026-01-04)

### Goal
Test 10 confidence calibration techniques to address the "inverted confidence" problem where low confidence trades often outperform high confidence ones.

### Background
Previous phases found that:
- Neural network outputs confidence in 0.20-0.35 range
- Bandit mode uses HMM thresholds (0.70/0.30), not neural confidence
- Low confidence trades sometimes have BETTER win rates (inverted signal)

### Techniques Tested (from Codex suggestions)

1. **Temperature Scaling** - Divide logits by temperature before softmax
2. **Entropy-Based Confidence** - Use prediction entropy as confidence proxy
3. **Margin-Based Confidence** - Gap between top two probabilities
4. **MC Dropout Variance** - Multiple forward passes for uncertainty
5. **BCE Loss Supervision** - Train confidence with trade outcomes
6. **Ranking Loss** - Learn to rank trade quality
7. **Selective Loss** - Penalize confident errors more heavily
8. **Per-Regime Calibration** - HMM-regime-specific calibration
9. **Beta Calibration** - Parametric calibration method
10. **Signal Stability Features** - Track prediction stability over time

### Implementations Added

**`bot_modules/neural_networks.py`:**
```python
# New environment variables
USE_ENTROPY_CONFIDENCE = os.environ.get('USE_ENTROPY_CONFIDENCE', '0') == '1'
CONFIDENCE_TEMPERATURE = float(os.environ.get('CONFIDENCE_TEMPERATURE', '1.0'))

# Entropy-based confidence (low entropy = high certainty)
def compute_entropy_confidence(probs):
    entropy = -sum(p * log(p))
    confidence = 1 - (entropy / max_entropy)
    return confidence

# Margin-based confidence (large margin = high certainty)
def compute_margin_confidence(probs):
    margin = top_prob - second_prob
    return margin
```

**`scripts/train_time_travel.py`:**
```python
# Verbose trade logging for debugging
TT_VERBOSE_TRADE_LOG = os.environ.get('TT_VERBOSE_TRADE_LOG', '1') == '1'

def _log_trade_details(action, price, confidence, hmm_state, ...):
    # Prints detailed trade info with confidence metrics
```

### Test Results

| Config | Cycles | P&L | Win Rate | Trades | Notes |
|--------|--------|-----|----------|--------|-------|
| Baseline | 2,000 | -0.41% | 33.3% | 42 | Reference |
| Temp 0.5 | 2,000 | -0.41% | 33.3% | 42 | No effect |
| Temp 1.5 | 2,000 | -0.41% | 33.3% | 42 | No effect |
| **Pure Entropy** | 2,000 | -0.45% | **42.5%** | 40 | **+9.2pp win rate!** |
| Entropy + Temp 1.5 | 2,000 | **+11.23%** | 29.2% | 23 | Fewer trades |
| **10K Validation** | 10,000 | -0.76% | 26.1% | 23 | Failed to reproduce |

### Key Findings

1. **Entropy-based confidence improves win rate by +9.2pp** (33.3% â†’ 42.5%)
   - Uses prediction distribution entropy as confidence proxy
   - Low entropy = model is certain = high confidence

2. **Temperature scaling has NO effect in bandit mode**
   - Bandit uses HMM thresholds (0.70/0.30), not neural confidence
   - Temperature only affects softmax probabilities, not HMM decisions

3. **Short tests (2K cycles) can show false positives**
   - Entropy + Temp 1.5 showed +11.23% at 2K cycles
   - Same config showed -0.76% at 10K cycles
   - Period-sensitive variance, not real improvement

4. **Entropy confidence addresses "inverted" problem**
   - Raw confidence from learned head has calibration issues
   - Entropy is mathematically grounded (information theory)
   - More interpretable: low entropy = model is sure

### Environment Variables Added

| Variable | Default | Description |
|----------|---------|-------------|
| `USE_ENTROPY_CONFIDENCE` | 0 | Use entropy-based instead of learned confidence |
| `CONFIDENCE_TEMPERATURE` | 1.0 | Temperature for softmax (>1 = softer, <1 = sharper) |
| `TT_VERBOSE_TRADE_LOG` | 1 | Print detailed trade info during simulation |

### Recommendations

1. **Enable entropy confidence** (`USE_ENTROPY_CONFIDENCE=1`) for improved win rate
2. **Don't use temperature scaling** in bandit mode (no effect)
3. **Always validate at 10K+ cycles** - 2K tests are unreliable
4. **Remaining techniques to test**: MC dropout, ranking loss, per-regime calibration

### Code Changes

- `bot_modules/neural_networks.py` - Entropy/margin confidence, supervision buffer, selective loss
- `scripts/train_time_travel.py` - Verbose trade logging
- `experiments/run_phase48_tests.sh` - Test runner script

---

## Phase 49: Trade Analysis â†’ Signal Filtering (2026-01-04) âœ… BEST RESULT

### Goal
Analyze actual trades to identify which signal types win/lose, then filter accordingly.

### Trade Analysis (from tp25_entropy_10k_validation)

Analyzed 38 trades to find patterns:

**WINNERS (+$1.50 to +$5.39/trade):**
- "Multi-timeframe consensus" signals
- Lower confidence (20-24%)

**LOSERS (-$4 to -$6/trade):**
- "15m momentum" signals
- "Low realized vol percentile" signals
- Higher confidence (27-33%)

### Implementation

Added `BLOCK_SIGNAL_STRATEGIES` environment variable:
```python
# Block trades with strategies containing these keywords
BLOCK_SIGNAL_STRATEGIES=MOMENTUM,VOLATILITY_EXPANSION
```

Also extended max hold time from 30 to 60 minutes to allow winners to develop.

### Test Results (10K cycles)

| Config | P&L | Win Rate | Trades | Per-Trade |
|--------|-----|----------|--------|-----------|
| Unfiltered (baseline) | -0.85% | 28.9% | 38 | -$1.11 |
| **Filtered + 60min hold** | **+561.17%** | **36.6%** | **179** | **+$156.75** |

### Exit Analysis

| Exit Type | Count | Avg P&L | Notes |
|-----------|-------|---------|-------|
| FORCE_CLOSE 60min | 106 | +$0.62 | Most common |
| **EMERGENCY EXIT: 250%+** | **2** | **+$1,292** | Massive winners! |
| RL FAST CUT (-2% to -3%) | ~20 | -$17 | Limiting losses |

**Key Finding:** Two trades reached 250%+ gains (+$1,304 and +$1,281) because extended hold time allowed them to develop.

### Environment Variables Added

| Variable | Default | Description |
|----------|---------|-------------|
| `BLOCK_SIGNAL_STRATEGIES` | "" | Comma-separated list of strategies to block |
| `TT_MAX_HOLD_MINUTES` | 30 | Extended to 60 for this test |

### Recommended Configuration

```bash
HARD_TAKE_PROFIT_PCT=25 \
USE_ENTROPY_CONFIDENCE=1 \
BLOCK_SIGNAL_STRATEGIES="MOMENTUM,VOLATILITY_EXPANSION" \
TT_MAX_HOLD_MINUTES=60 \
python scripts/train_time_travel.py
```

### Key Insights

1. **Signal type matters more than confidence** - Blocking MOMENTUM and VOLATILITY_EXPANSION eliminated worst losers
2. **Hold time is critical for wide TP** - 30 min too short for +25% TP, 60 min allows big winners
3. **Few big winners drive P&L** - Two 250%+ trades = +$2,585 of the +$28,058 total
4. **Trade analysis reveals actionable patterns** - Looking at actual trades shows what works

---

## Phase 50: Confidence Calibration Fixes (2026-01-04) - Codex Review

### Goal
Fix the inverted confidence issue identified in Phase 48/49 where lower confidence trades win more.

### Codex Analysis Findings

Codex reviewed our architecture and identified **4 critical issues**:

1. **HIGH: Confidence head never trained**
   - Location: `bot_modules/neural_networks.py:725-790`
   - The model defines a confidence head but no loss term trains it
   - Confidence outputs are essentially random noise

2. **MEDIUM: Entropy-based confidence not implemented**
   - Location: `unified_options_trading_bot.py:1843-1898`
   - Despite `USE_ENTROPY_CONFIDENCE` env var, the actual entropy calculation wasn't in the inference path

3. **MEDIUM: Confidence penalized by return variance**
   - Location: `unified_options_trading_bot.py:1877-1887`
   - `adjusted_conf = base_conf * (1.0 - min(mc_uncertainty * 10, 0.5))`
   - In high-volatility profitable moves, variance goes UP, pushing confidence DOWN when trades WIN

4. **LOW: Temperature scaling not applied**
   - Location: `unified_options_trading_bot.py:1848`
   - `CONFIDENCE_TEMPERATURE` wasn't applied to direction logits before softmax

### Fixes Implemented (All Opt-In)

| Variable | Default | Description |
|----------|---------|-------------|
| `TRAIN_CONFIDENCE_BCE` | 0 | Train confidence head with BCE loss targeting P(win) |
| `CONFIDENCE_BCE_WEIGHT` | 0.5 | Weight of BCE loss in total training loss |
| `USE_ENTROPY_CONFIDENCE_V2` | 0 | Use proper entropy-based confidence from direction probs |
| `DECOUPLE_UNCERTAINTY` | 0 | Don't penalize confidence by MC return variance |
| `DIRECTION_TEMPERATURE` | 1.0 | Temperature scaling for direction logits |
| `CONFIDENCE_DEBUG` | 0 | Log detailed confidence calculation info |

### Implementation Details

**1. BCE Confidence Loss (lines 2733-2744):**
```python
if TRAIN_CONFIDENCE_BCE:
    target_win = 1.0 if target_return > 0 else 0.0
    conf_loss = nn.BCELoss()(output["confidence"], target_win_tensor)
    total_loss = total_loss + conf_loss * CONFIDENCE_BCE_WEIGHT
```

**2. Entropy-Based Confidence V2 (lines 1915-1934):**
```python
if USE_ENTROPY_CONFIDENCE_V2:
    entropy = -np.sum(dirs_normalized * np.log(dirs_normalized))
    max_entropy = np.log(3)  # 3 classes
    entropy_conf = 1.0 - (entropy / max_entropy)
    margin_conf = sorted_probs[0] - sorted_probs[1]
    base_conf = 0.7 * entropy_conf + 0.3 * margin_conf
```

**3. Temperature Scaling (line 1869):**
```python
direction_logits = out["direction"] / DIRECTION_TEMPERATURE
```

**4. Uncertainty Decoupling (lines 1939-1946):**
```python
if DECOUPLE_UNCERTAINTY:
    adjusted_conf = base_conf  # Don't penalize by variance
```

### Test Ideas Added to Optimizer

- IDEA-264: BCE Confidence Training
- IDEA-265: Entropy Confidence V2 + Decoupled Uncertainty
- IDEA-266: All Codex Fixes Combined
- IDEA-267: Temperature Scaling Only (T=1.5)
- IDEA-268: Entropy V2 Only

### Recommended Test Configuration

```bash
# Test all Codex fixes with Phase 49 best config
TRAIN_CONFIDENCE_BCE=1 \
USE_ENTROPY_CONFIDENCE_V2=1 \
DECOUPLE_UNCERTAINTY=1 \
DIRECTION_TEMPERATURE=1.5 \
HARD_TAKE_PROFIT_PCT=25 \
TT_MAX_HOLD_MINUTES=60 \
BLOCK_SIGNAL_STRATEGIES="MOMENTUM,VOLATILITY_EXPANSION" \
python scripts/train_time_travel.py
```

---

## Phase 51: Mamba2 State Space Model Integration (2026-01-05)

### Overview

Added Mamba2 (State Space Model) as a swappable temporal encoder option.

### Why Mamba2?

1. **Linear Complexity**: O(L) vs O(LÂ²) for Transformers - better for long sequences
2. **Selective State Spaces**: Data-dependent parameters learn which information to remember/forget
3. **No Attention**: Avoids quadratic memory growth
4. **Proven Performance**: State-of-the-art on many sequence modeling benchmarks

### Implementation Details

**New Classes in `bot_modules/neural_networks.py`:**

1. `Mamba2Block` - Single Mamba2 layer with:
   - 1D convolution for local context
   - Selective state space (SSM) with learned A, B, C, D parameters
   - SiLU gating mechanism
   - Pre-norm residual connections

2. `OptionsMamba2` - Full encoder with:
   - Input projection to d_model
   - N Mamba2 blocks (default: 4)
   - Attention pooling for sequence â†’ vector
   - Context projection to 64-dim output

### Configuration

**Environment Variables:**
```bash
TEMPORAL_ENCODER=mamba2           # Enable Mamba2 encoder
MAMBA2_N_LAYERS=4                 # Number of Mamba2 layers (default: 4)
MAMBA2_D_STATE=64                 # SSM state dimension (default: 64)
MAMBA2_EXPAND=2                   # Expansion factor (default: 2)
```

### Encoder Options Summary

| Encoder | Env Var | Complexity | Notes |
|---------|---------|------------|-------|
| TCN (default) | `TEMPORAL_ENCODER=tcn` | O(L) | Best tested (+1327% P&L) |
| Transformer | `TEMPORAL_ENCODER=transformer` | O(LÂ²) | +801% P&L |
| LSTM | `TEMPORAL_ENCODER=lstm` | O(L) | Legacy fallback |
| **Mamba2** | `TEMPORAL_ENCODER=mamba2` | O(L) | **NEW - Phase 51** |

### Test Ideas Added to Optimizer

- IDEA-269: Mamba2 SSM baseline (4 layers, d_state=64)
- IDEA-270: Deep Mamba2 (6 layers, d_state=128)
- IDEA-271: Mamba2 + Signal Filtering (combine with best config)

### Example Test Command

```bash
TEMPORAL_ENCODER=mamba2 \
MAMBA2_N_LAYERS=4 \
MAMBA2_D_STATE=64 \
MODEL_RUN_DIR=models/mamba2_test \
TT_MAX_CYCLES=5000 \
PAPER_TRADING=True \
python scripts/train_time_travel.py
```

---

## Phase 51 Mamba2 Results (2026-01-05)

### Experiment Results

| ID | Configuration | P&L | Win Rate | $/Trade |
|----|---------------|-----|----------|---------|
| IDEA-269 | Mamba2 baseline (4 layers) | +4.21% | 38.8% | +$2.67 |
| IDEA-270 | Deep Mamba2 (6 layers) | -4.52% | 39.2% | -$2.86 |
| **IDEA-271** | **Mamba2 + signal filtering** | **+34.85%** | 39.8% | **+$22.06** |

### Key Finding

Mamba2 alone shows modest improvement (+4.21%), but combined with signal filtering (`BLOCK_SIGNAL_STRATEGIES=MOMENTUM,VOLATILITY_EXPANSION`) achieves **+34.85% P&L**.

Deeper Mamba2 (6 layers) performs worse than 4 layers, suggesting overfitting.

### Best Mamba2 Configuration

```bash
TEMPORAL_ENCODER=mamba2 \
MAMBA2_N_LAYERS=4 \
MAMBA2_D_STATE=64 \
BLOCK_SIGNAL_STRATEGIES=MOMENTUM,VOLATILITY_EXPANSION \
python scripts/train_time_travel.py
```

---

## Layer 2 Meta Optimizer Launch (2026-01-05)

### System Architecture Complete

Built two-layer automated optimization:

1. **Layer 1** (`continuous_optimizer.py`): Tests specific configs 24/7
2. **Layer 2** (`meta_optimizer.py`): Analyzes all experiments, suggests improvements

### Meta Analysis Findings (247 experiments)

| Metric | Value |
|--------|-------|
| Total experiments analyzed | 247 |
| Confidence inverted | 61% |
| NEURAL_BEARISH losing | 221 experiments (90%) |
| NEURAL_BULLISH losing | 159 experiments (64%) |

### Auto-Generated Ideas

- IDEA-272: Entropy confidence fix (`USE_ENTROPY_CONFIDENCE_V2=1`)
- IDEA-273: Block losing strategies (`BLOCK_SIGNAL_STRATEGIES=NEURAL_BEARISH,NEURAL_BULLISH,MOMENTUM_BEARISH`)

---

## Phase 52: Trade Pattern Analysis & SKIP_MONDAY Discovery (2026-01-06) - **NEW BEST!**

### Objective

Analyze trades from 20K validation to find patterns that improve win rate.

### Key Pattern Discoveries

| Pattern | Win Rate | Insight |
|---------|----------|---------|
| **Monday** | **23%** | Worst day - skip entirely |
| First 90 min | 28% | Opening volatility hurts |
| Midday (13-14) | 57% | Best trading window |
| Last hour (15:00+) | 10% CALLs | End-of-day reversals |
| Neg momentum + PUT | **0%** | Critical pattern to avoid |
| After 2 wins | 52.3% | Streak continuation |

### 20K Validation - SKIP_MONDAY - **NEW BEST**

| Metric | Value |
|--------|-------|
| **P&L** | **+$81,512 (+1630.24%)** |
| **P&L/DD Ratio** | **35.03** (previous best: 3.92) |
| Max Drawdown | 46.54% |
| Win Rate | 43.0% |
| Trades | 295 |
| $/Trade | $276.31 |
| Model | `models/COMBO_SKIP_MONDAY_20K` |

### Best Configuration

```bash
USE_TRAILING_STOP=1
TRAILING_ACTIVATION_PCT=10
TRAILING_STOP_PCT=5
ENABLE_TDA=1
TDA_REGIME_FILTER=1
TRAIN_MAX_CONF=0.25
DAY_OF_WEEK_FILTER=1
SKIP_MONDAY=1
SKIP_FRIDAY=0
```

### Launch Script

```bash
./run_live_skip_monday.sh
# For live: touch go_live.flag && ./run_live_skip_monday.sh
```

**This is now the recommended configuration for live trading.**

---

## Phase 35: Exit Improvements - Flat Trade & Profit Pullback (2026-01-06)

### Goal
Address finding that 86-100% of losses were trades that WERE profitable but reversed.
Free up liquidity from flat trades to capture better opportunities.

### Exit Rules Implemented
1. **FLAT_TRADE_EXIT**: Exit trades with Â±1% P&L after 15 min (free liquidity)
2. **PROFIT_PULLBACK_EXIT**: Exit when profit drops 50% from peak
3. **QUICK_PROFIT_EXIT**: Lock in +5% gains within 10 min
4. **TIME_DECAY_EXIT**: Exit at 60% of max hold with <3% profit
5. **CHOPPY_MARKET_FILTER**: ADX-based entry filter (tested separately)

### 5K Comparison Test Results

| Configuration | Trades | Win Rate | P&L | P&L/DD | Notes |
|---------------|--------|----------|-----|--------|-------|
| **BASELINE** | 52 | 46.2% | **-$15.48** | -0.00 | No exit rules (30 min max hold) |
| **EXIT_RULES** | 153 | 40.1% | **+$4,199.40 (+84%)** | 1.08 | âœ… **BEST** - 3x more trades, 15min flat exit |
| ALL_IMPROVED | 329 | 38.0% | **-$190.50 (-3.8%)** | -0.05 | Exit rules + choppy filter |

### Key Findings

1. **FLAT_TRADE exit at 15 min is the key improvement**
   - Frees up liquidity for 3x more trades (153 vs 52)
   - Lower win rate (40.1% vs 46.2%) but much better P&L

2. **Choppy market filter HURT performance**
   - ALL_IMPROVED with ADX filter: -$190 vs EXIT_RULES: +$4,199
   - The filter allowed MORE trades (329) but with worse quality

3. **Win rate is NOT the goal - P&L is**
   - BASELINE had highest win rate (46.2%) but negative P&L
   - EXIT_RULES had lower win rate but +84% P&L

### Exit Rule Statistics (EXIT_RULES config)

| Exit Type | Count | Notes |
|-----------|-------|-------|
| FLAT_TRADE | 153 | 100% of exits - trades not moving within Â±1% after 15 min |
| PROFIT_PULLBACK | 0 | Trades not reaching +2% peak before 15 min |
| QUICK_PROFIT | 0 | Trades not reaching +5% within 10 min |
| TIME_DECAY | 0 | FLAT_TRADE triggers first at 15 min |

### Tuned Settings Test (1K cycles)

| Setting | Original | Tuned | Result |
|---------|----------|-------|--------|
| FLAT_TRADE timeout | 15 min | 20 min | **+$538.91** vs -$563.70 |
| FLAT_TRADE threshold | Â±1% | Â±0.5% | Better P&L with less aggressive exit |

### Config Changes Made
```json
"exit_improvements": {
    "choppy_market_filter": {
        "enabled": false,  // DISABLED - hurts performance
        "_note": "Phase 35 test: ALL_IMPROVED -3.8% vs EXIT_RULES +84%"
    }
}
```

### Recommended Configuration
```bash
FLAT_TRADE_EXIT_ENABLED=1
FLAT_TRADE_TIMEOUT_MIN=15
FLAT_TRADE_THRESHOLD_PCT=1.0
PROFIT_PULLBACK_EXIT_ENABLED=1
PROFIT_PULLBACK_THRESHOLD_PCT=50
QUICK_PROFIT_EXIT_ENABLED=1
QUICK_PROFIT_THRESHOLD_PCT=5.0
TIME_DECAY_EXIT_ENABLED=1
CHOPPY_MARKET_FILTER_ENABLED=0  # DISABLED
```

### Files Modified
- `scripts/train_time_travel.py`: Added Phase 34 exit rules in force-close mechanism
- `backend/unified_exit_manager.py`: Added all exit rule implementations
- `integrations/quantor/regime_filter.py`: Added ADX and Choppiness Index computations
- `config.json`: Disabled choppy_market_filter

---

## Phase 36: CRITICAL - Confidence Head Is Broken & Inverted (2026-01-06)

### Discovery

**ROOT CAUSE FOUND**: The neural network's confidence head outputs **INVERTED** values because it has **NO LOSS FUNCTION** training it.

### Evidence: Confidence vs Actual Win Rate

Analysis of 4,638 CALL signals from HIGH_MIN_RET model:

| Confidence Range | Count | Actual Win Rate | Error |
|------------------|-------|-----------------|-------|
| 0-15% | 384 | 3.6% | OK |
| 15-20% | 824 | **7.2%** | +10% overconfident |
| 20-25% | 927 | 4.1% | +19% overconfident |
| 25-30% | 1,379 | 2.4% | +25% overconfident |
| 30-40% | 1,061 | 1.6% | +32% overconfident |
| **40%+** | 63 | **0%** | **+45% overconfident** |

**Key Finding**: Win rate DECREASES as confidence INCREASES. The relationship is completely inverted.

### Root Cause

From `core/unified_options_trading_bot.py` line 66-67:
```python
TRAIN_CONFIDENCE_BCE = os.environ.get('TRAIN_CONFIDENCE_BCE', '0') == '1'  # DISABLED BY DEFAULT!
```

The confidence head exists in the model:
```python
self.confidence_head = nn.Linear(64, 1)  # Outputs via sigmoid
```

But **no loss function trains it** unless `TRAIN_CONFIDENCE_BCE=1`. Instead, it learns backwards correlations through gradient leakage from other losses (return, direction).

### Why This Matters

When the model "works hard" on difficult patterns (high gradient flow), the untrained confidence head outputs high values. But those difficult cases are actually the ones that lose - hence the inversion.

### Solutions Implemented

#### 1. Offline Pretraining Script (`scripts/pretrain_confidence.py`)
```bash
# Pretrain confidence head with BCE loss on historical data
python scripts/pretrain_confidence.py --epochs 100 --output models/pretrained_bce.pt

# Then use pretrained model
LOAD_PRETRAINED=1 PRETRAINED_MODEL_PATH=models/pretrained_bce.pt python scripts/train_time_travel.py
```

#### 2. Direction Entropy Alternative (`USE_ENTROPY_CONFIDENCE=1`)
Replace broken confidence with entropy of direction probabilities:
```python
# Low entropy = certain about direction = high confidence
# High entropy = uncertain = low confidence
entropy = -sum(p * log(p) for p in direction_probs)
confidence = 1.0 - (entropy / max_entropy)
```

```bash
USE_ENTROPY_CONFIDENCE=1 python scripts/train_time_travel.py
```

#### 3. Max Confidence Filter (Workaround)
Filter OUT high confidence signals (which are actually the worst):
```bash
TRAIN_MAX_CONF=0.25 python scripts/train_time_travel.py
```

This is why HIGH_MIN_RET (+423% P&L) performed well - it inadvertently filtered out the broken high-confidence signals.

### Test Results

| Configuration | P&L | Win Rate | Trades | Notes |
|---------------|-----|----------|--------|-------|
| HIGH_MIN_RET (TRAIN_MAX_CONF=0.50) | **+423%** | 38.0% | 281 | Works around broken confidence |
| CONFIDENCE_BCE_TRAINED | +3.5% | 36.2% | 275 | BCE online training too slow |
| OPTIMIZED_DAY_TRADING | -31% | 46.7% | 273 | Hour/day filters hurt |
| MEAN_REVERSION_V2 | +102% | 35.1% | 26 | Low conf filter, few trades |

### Environment Variables Added

| Variable | Default | Description |
|----------|---------|-------------|
| `TRAIN_CONFIDENCE_BCE` | 0 | Train confidence head with BCE loss (P(win)) |
| `CONFIDENCE_BCE_WEIGHT` | 0.5 | Weight of BCE loss in training |
| `USE_ENTROPY_CONFIDENCE` | 0 | Use direction entropy instead of confidence head |
| `INVERT_CONFIDENCE` | 0 | Invert confidence (1 - conf) as workaround |
| `TRAIN_MAX_CONF` | 1.0 | Maximum confidence filter (use â‰¤0.25 to filter bad signals) |

### Recommendations

1. **For new deployments**: Run pretraining script first to calibrate confidence head
2. **For existing models**: Use `TRAIN_MAX_CONF=0.25` to filter out broken high-confidence signals
3. **For research**: Try `USE_ENTROPY_CONFIDENCE=1` to see if entropy is better predictor

### Files Modified
- `scripts/train_time_travel.py`: Added INVERT_CONFIDENCE and USE_ENTROPY_CONFIDENCE options
- `scripts/pretrain_confidence.py`: NEW - Offline BCE pretraining script
- `docs/RESULTS_TRACKER.md`: This documentation
- `CLAUDE.md`: Updated with confidence calibration findings

---

### Entropy Confidence Test Results (2026-01-06)

Using `USE_ENTROPY_CONFIDENCE=1` to replace broken confidence head with direction entropy:

| Metric | Value |
|--------|-------|
| P&L | **+18.10%** |
| Win Rate | 36.8% |
| Trades | 275 |
| P&L/DD | 0.22 |

**Conclusion**: Entropy confidence is an improvement over the broken confidence head (+18.1% vs potential losses), but not as effective as simply filtering with `TRAIN_MAX_CONF=0.25` (+423% for HIGH_MIN_RET).

**Recommended approach**: Use `TRAIN_MAX_CONF=0.25` to filter out broken high-confidence signals.

### Pretraining Script

`scripts/pretrain_confidence.py` created to offline-train confidence head with BCE loss.
Currently running on 2.87M samples from historical datasets.

Usage after pretraining completes:
```bash
LOAD_PRETRAINED=1 PRETRAINED_MODEL_PATH=models/pretrained_bce.pt python scripts/train_time_travel.py
```

---

## Phase 37: Confidence Fix + Combined Strategy (2026-01-06)

### Background
Phase 36 discovered the confidence head is INVERTED - high confidence correlates with LOW win rate.
This phase tests the confidence fix with our best strategies combined.

### Confidence Fix Comparison (2K cycles each)

| Config | Trades | Win Rate | P&L |
|--------|--------|----------|-----|
| BASELINE (no fix) | 200 | 40.5% | **-$121.89 (-2.44%)** |
| ENTROPY | 200 | 41.0% | -$120.43 (-2.41%) |
| INVERT | 322 | 39.8% | -$183.90 (-3.68%) |
| **MAX_25** | 72 | 40.3% | **-$17.32 (-0.35%)** âœ“ |

**Winner: TRAIN_MAX_CONF=0.25** - Filters out broken high-confidence signals.

### Strategy Comparison with Fixed Confidence (5K cycles each)

| Config | Trades | Win Rate | P&L | P&L/DD |
|--------|--------|----------|-----|--------|
| SKIP_MON_CONF_FIX | 100 | 39.0% | -$29.54 (-0.59%) | -0.01 |
| **COMBINED_BEST** | 90 | 38.5% | **+$329.89 (+6.60%)** | 0.14 |

### COMBINED_BEST Configuration (RECOMMENDED)
```bash
# Confidence fix
TRAIN_MAX_CONF=0.25

# Day filters
DAY_OF_WEEK_FILTER=1
SKIP_MONDAY=1

# Trailing stops
USE_TRAILING_STOP=1
TRAILING_ACTIVATION_PCT=10
TRAILING_STOP_PCT=5

# Regime filter
ENABLE_TDA=1
TDA_REGIME_FILTER=1

# Phase 35 Exit Rules
FLAT_TRADE_EXIT_ENABLED=1
FLAT_TRADE_TIMEOUT_MIN=15
FLAT_TRADE_THRESHOLD_PCT=1.0
PROFIT_PULLBACK_EXIT_ENABLED=1
QUICK_PROFIT_EXIT_ENABLED=1
TIME_DECAY_EXIT_ENABLED=1
```

### Key Findings

1. **Confidence fix is essential** - TRAIN_MAX_CONF=0.25 reduces losses from -2.44% to -0.35%
2. **Combined strategies work best** - Combining all improvements yields +6.60% P&L
3. **Win rate doesn't matter** - 38.5% WR with +6.60% P&L beats 40.5% WR with -2.44% P&L
4. **Exit rules critical** - Phase 35 flat trade exit frees liquidity for better trades

### Previous "Profitable" Results Explained
- Original SKIP_MONDAY showed +1630% P&L
- This was inflated by P&L calculation bug (Phase 36)
- Real performance with fixed P&L is +6.60% over 5K cycles
- This is ~5x better than break-even, which is realistic

---

---

## Multi-Seed Architecture Testing (2026-01-07)

### Summary
Comprehensive testing of RL policy architectures with multiple random seeds to find robust configurations.

### Best Performing Configurations

| Rank | Config | P&L | Win Rate | Trades | Consistency |
|------|--------|-----|----------|--------|-------------|
| 1 | h64_3L_gelu_s1 | +339.0% | 44.4% | 55 | - |
| 2 | h64_3L_gelu_s3 | +302.4% | 40.3% | 44 | - |
| 3 | **h96_3L_gelu_s1** | **+269.6%** | **53.0%** | 87 | **86%** |
| 4 | h128_2L_gelu_s2 | +264.0% | 41.5% | 38 | - |
| 5 | h96_3L_gelu_s3 | +262.3% | 37.5% | 53 | - |

### Multi-Seed Consistency Analysis

| Architecture | Seeds | Avg P&L | Avg WR | Consistency |
|--------------|-------|---------|--------|-------------|
| **h96_3L_gelu** | 3/3 | +241.4% | **46.6%** | **86%** |
| h64_3L_gelu | 3/3 | +276.1% | 38.6% | 76% |
| h128_2L_gelu | 3/3 | +196.5% | 37.1% | 75% |
| h128_3L_gelu | 3/3 | +178.1% | 33.8% | 72% |

**Winner: h96_3L_gelu** - Highest consistency (86%) AND highest average win rate (46.6%)

### Trade Pattern Analysis (Detailed)

Deep analysis of h96_3L_gelu_s1 trades (96 total, +$139.25 P&L, 53% WR) revealed critical correlations:

#### Key Finding: Empty Signal Trades Were Big Winners

| Signal Strategy | Trades | Total P&L | Win Rate | Insight |
|-----------------|--------|-----------|----------|---------|
| **Empty signal** | 9 | **+$132.51** | **66.7%** | ðŸ† THE JACKPOTS! |
| NEURAL_BULLISH | 81 | +$11.53 | 53.1% | Small winners |
| NEURAL_BEARISH | 6 | -$4.79 | 33.3% | Losers |

**Critical Insight**: 9 trades with empty signal_strategy generated 95% of total profit!

#### What Made Empty-Signal Trades Special?

1. **Held much longer** - Exited via "Emergency Max Hold (2h)" not FLAT_TRADE
2. **Entry time 1-3pm** - All 4 big winners entered 13:55-14:46
3. **All CALLs** - No successful empty-signal PUTs
4. **Medium confidence (0.26-0.41)** - Not high confidence

Top 4 Winning Trades (all empty-signal CALLs):
| Entry Time | P&L | Exit Reason | Hold Time |
|------------|-----|-------------|-----------|
| 13:56 | +$44.14 | Emergency Max Hold (2h) | 2+ hours |
| 14:07 | +$42.32 | Emergency Max Hold (2h) | 2+ hours |
| 14:46 | +$41.91 | Emergency Max Hold (2h) | 2+ hours |
| 13:55 | +$36.47 | MAX_HOLD: Held 1175min | 19.6 hours |

#### Exit Timing Analysis

| Exit Reason | Trades | Win Rate | Avg P&L | Insight |
|-------------|--------|----------|---------|---------|
| FLAT_TRADE (15min) | 83 | 53.1% | +$0.13 | Tiny winners |
| Emergency Max Hold (2h) | 3 | 100% | +$42.79 | ðŸ† BIG WINNERS |
| MAX_HOLD (long) | 2 | 50% | +$2.10 | Mixed |

**Root Cause**: FLAT_TRADE_TIMEOUT_MIN=15 exits positions too quickly. Winners need hours to develop.

#### Time-of-Day Analysis

| Hour | Trades | Win Rate | Total P&L | Note |
|------|--------|----------|-----------|------|
| 09 (open) | 2 | **0%** | -$1.29 | âš ï¸ AVOID |
| 10 | 16 | 62.5% | +$2.50 | Okay |
| 11 | 15 | 53.3% | +$2.39 | Okay |
| 12 | 12 | 41.7% | +$0.13 | Marginal |
| **13 (1pm)** | 21 | **66.7%** | **+$82.84** | ðŸ† BEST |
| 14 | 17 | 47.1% | +$50.62 | Second best |
| 15 | 13 | 46.2% | +$2.06 | Okay |

**Key Pattern**: 1-2pm generates 96% of profits despite having only 40% of trades.

#### Signal Strategy + Option Type Combo

| Combo | Trades | Total P&L | Win Rate |
|-------|--------|-----------|----------|
| **CALL + Empty** | 6 | **+$163.98** | **83.3%** |
| CALL + NEURAL_BULLISH | 81 | +$11.53 | 53.1% |
| PUT + NEURAL_BEARISH | 6 | -$4.79 | 33.3% |
| PUT + Empty | 3 | -$31.47 | 33.3% |

**By Option Type:**
- CALL: 55.2% WR, +$2.02/trade âœ“
- PUT: 33.3% WR, -$4.03/trade âœ—

**By Confidence:**
- LOW (<30%): 42.3% WR
- MEDIUM (30-50%): **65.9% WR** â˜…

**By Signal Strategy:**
- NEURAL_BULLISH: 53.1% WR
- NEURAL_BEARISH: 33.3% WR âœ—

### Filtering Experiments (FAILED)

Attempted to improve win rate by filtering bad patterns:

| Filter | P&L | Win Rate | Result |
|--------|-----|----------|--------|
| CALLS_ONLY=1 | -0.12% | 43.7% | WORSE |
| BLOCK_SIGNAL_STRATEGIES=NEURAL_BEARISH | -0.50% | 45.2% | WORSE |
| TT_TRAIN_MIN_CONF=0.30 TRAIN_MAX_CONF=0.50 | -0.91% | 37.8% | WORSE |

**Conclusion: Filtering is counterproductive** - restricts learning signal

### Architecture Improvement Experiments (FAILED)

Tested various architecture changes:

| Config | P&L | Win Rate | Result |
|--------|-----|----------|--------|
| h192_4L (more capacity) | -0.6% | 39.0% | WORSE |
| TEMPORAL_ENCODER=transformer | +78.1% | 40.7% | WORSE |
| RL_USE_ATTENTION=1 | +0.2% | 54.2% | WORSE |
| PREDICTOR_ARCH=v3_multi_horizon | -0.8% | 27.8% | WORSE |
| TEMPORAL_ENCODER=lstm | -1.4% | 39.2% | WORSE |

**Conclusion: h96_3L_gelu with default TCN is already optimal!**

### Exit Timing Experiments (2026-01-07)

Tested modifying exit timing to let winners run longer:

| Config | P&L | Win Rate | Trades | Result |
|--------|-----|----------|--------|--------|
| Baseline h96_3L_gelu_s1 | +269.6% | 53.0% | 87 | Reference |
| FLAT_TRADE_EXIT_ENABLED=0 | -0.75% | 31.8% | 44 | WORSE |
| FLAT_TRADE_TIMEOUT_MIN=30 | -0.75% | 31.8% | 44 | WORSE |

**Note**: Exit experiments ran on different data period than original. Results not directly comparable.

### Why All Improvement Attempts Failed

1. **Learning Signal Loss**: Filtering removes examples the RL policy needs to learn from
2. **Data Period Sensitivity**: Same config on different dates produces different results
3. **Stochastic Nature**: Random seed heavily influences outcomes
4. **Sample Size**: 87 trades is small for statistical significance
5. **Overfitting Risk**: Architecture changes may overfit to specific market conditions

### Actionable Conclusions

| Action | Recommendation | Rationale |
|--------|----------------|-----------|
| âœ… Use h96_3L_gelu | **DO** | Best consistency (86%) and win rate (46.6%) |
| âŒ Filter signals | **DON'T** | Hurts learning, restricts adaptation |
| âŒ Change architecture | **DON'T** | TCN encoder is optimal for this task |
| âš ï¸ Watch 1-2pm | **OBSERVE** | 96% of profits from afternoon trades |
| âš ï¸ Avoid 9am | **CAUTION** | 0% win rate at market open |
| âš ï¸ Hold times | **INVESTIGATE** | Big winners needed 2+ hours |

### Recommended Production Config

```bash
RL_HIDDEN_DIM=96 \
RL_NUM_LAYERS=3 \
RL_ACTIVATION=gelu \
python scripts/train_time_travel.py
```

Expected: +190-270% P&L, 46-53% Win Rate, 86% consistency across seeds

### Research Sources

- [RL Financial Decision Making Survey](https://arxiv.org/html/2512.10913v1)
- [Expert Systems with Applications - RL Investment Survey 2025](https://www.sciencedirect.com/science/article/abs/pii/S0957417425011625)
- [Deep RL Trading Strategies](https://blog.mlq.ai/deep-reinforcement-learning-trading-strategies-automl/)

---

## âš ï¸ CRITICAL BUG: Neural Predictions IGNORED (2026-01-07)

### Summary
**The neural network predictions are completely filtered out and NEVER used for trading decisions!**

### Evidence from h96_3L_gelu_s1 Trade Analysis

| Metric | Value | Problem |
|--------|-------|---------|
| MIN_DIRECTION_THRESHOLD | 0.5 (50 bps) | Way too high |
| Actual predictions | 8-15 bps | All below threshold |
| bandit_mode_trades | 100,000 | Never exits bandit mode |
| Predictions filtered | **100%** | None reach RL policy |

### How We Discovered It

Analysis of h96_3L_gelu_s1 trades revealed:
```
pred_direction  trades  win_rate
--------------  ------  --------
-0.12           6       33.3%    â† Bearish predictions
0.08            79      53.2%    â† Bullish predictions
0.15            2       50.0%    â† Bullish predictions
```

All values are below MIN_DIRECTION_THRESHOLD (0.5), so all predictions trigger:
```python
if abs(state.predicted_direction) < MIN_DIRECTION_THRESHOLD:
    return self.HOLD, 0.85, {'reason': 'weak_direction'}  # ALWAYS!
```

### Root Cause

In `backend/unified_rl_policy.py`:

1. **Threshold mismatch** (line ~698):
   - `predicted_direction = predicted_return * 100`
   - Prediction of 0.001 (10 bps) becomes 0.1
   - Threshold is 0.5 â†’ **ALL predictions filtered!**

2. **Permanent bandit mode** (line ~300):
   - `bandit_mode_trades = 100,000`
   - We never get 100K trades â†’ **RL never activates!**

### Impact

- **All "successful" runs were HMM-based, not prediction-based**
- The neural network trains but its outputs are discarded
- Entry decisions come from "Multi-timeframe consensus" not predictions
- Past architecture comparisons are invalid - they compared HMM performance, not NN performance

### Fixes Required

```python
# unified_rl_policy.py

# Fix 1: Lower threshold (line ~698)
MIN_DIRECTION_THRESHOLD = 0.05  # was 0.5

# Fix 2: Lower bandit mode trades (line ~300)
bandit_mode_trades: int = 100  # was 100000
```

### Tests to Rerun (With Fixed Thresholds)

All previous tests need re-running with:
```bash
MIN_DIRECTION_THRESHOLD=0.05 BANDIT_MODE_TRADES=100 python scripts/train_time_travel.py
```

| Test | Original Result | Needs Rerun |
|------|-----------------|-------------|
| h96_3L_gelu | +269.6% P&L | âœ… Yes |
| h64_3L_gelu | +339.0% P&L | âœ… Yes |
| h96_mamba2 | -1.39% P&L | âœ… Yes |
| All architecture tests | Various | âœ… Yes |

### Status
âš ï¸ **UNFIXED** - Requires code changes to `unified_rl_policy.py`


---

## âš ï¸ IMPORTANT: Baseline +269% Was Statistical Fluke (2026-01-07)

### Summary
**The h96_3L_gelu "baseline" +269% P&L was NOT from neural predictions - it came from 4 accidental overnight trades on a single day.**

### Investigation Timeline

We initially suspected "signal inversion" because:
- Fixed thresholds showed 33.3% win rate with NEURAL_BEARISH signals
- This suggested predictions were inversely correlated with outcomes

But deeper analysis revealed a completely different story.

### Key Evidence

**1. Exit Reason Analysis (h96_tcn_fixed)**
```
Exit Reason                                    | Trades | Win Rate
-----------------------------------------------|--------|----------
FLAT_TRADE: P&L 0.0% after 15min              | 18     | 66.7%
FLAT_TRADE: P&L -0.0% after 15min             | 16     | 0.0%
FLAT_TRADE: P&L -0.1% after 15min             | 6      | 0.0%
FLAT_TRADE: P&L 0.1% after 15min              | 4      | 100.0%
```

**ALL trades exit as FLAT_TRADE at 15 minutes** - none hit stop loss or take profit!

**2. Baseline's Profit Source (h96_3L_gelu_s1)**
```sql
SELECT signal_strategy, option_type, COUNT(*), SUM(profit_loss), AVG(profit_loss), win_rate
FROM trades WHERE run_id = 'h96_3L_gelu_s1'
GROUP BY signal_strategy, option_type
```

| Signal | Option | Trades | Total P&L | Avg P&L | Win % |
|--------|--------|--------|-----------|---------|-------|
| **EMPTY** | CALL | 6 | **+$164** | +$27.33 | 83.3% |
| NEURAL_BULLISH | CALL | 81 | +$11.53 | +$0.14 | 53.1% |
| NEURAL_BEARISH | PUT | 6 | -$4.79 | -$0.80 | 33.3% |
| EMPTY | PUT | 3 | -$31.47 | -$10.49 | 33.3% |

**95% of P&L came from 6 trades with EMPTY signal - NOT from neural predictions!**

**3. The Overnight Trades**
```
timestamp            | option | profit_loss | exit_reason              | hold_minutes
---------------------|--------|-------------|--------------------------|-------------
2025-06-26T13:56:00  | CALL   | +$44.14    | Emergency Max Hold (2h)  | 1174
2025-06-26T14:07:00  | CALL   | +$42.32    | Emergency Max Hold (2h)  | 1163
2025-06-26T14:46:00  | CALL   | +$41.91    | Emergency Max Hold (2h)  | 1124
2025-06-26T13:55:00  | CALL   | +$36.47    | MAX_HOLD: Held 1175min   | 1175
```

- All 4 big winners were on **ONE DAY** (June 26, 2025)
- All held **OVERNIGHT** (1100-1175 minutes)
- All had **EMPTY signal_strategy** (not from neural network)
- They accidentally caught a big market move

### Root Cause

The +269% "baseline" was a statistical fluke:
1. 4 trades bypassed normal signal generation (empty strategy)
2. They held overnight due to "Emergency Max Hold" logic
3. They happened to catch June 26-27's market rally
4. Neural predictions (NEURAL_BULLISH/BEARISH) contributed only **$7 of $164 total profit**

### Why 33.3% Win Rate is NOT Inversion

The "fixed threshold" run showed 33.3% win rate with NEURAL_BEARISH, but this is NOT signal inversion:

1. **All trades exit at 15 minutes via FLAT_TRADE** (before direction plays out)
2. **P&L distribution is symmetric around zero** (-7 to +6, peak at 0)
3. **33% is noise within Â±$5 P&L range**, not meaningful signal
4. **The 15-min prediction horizon = 15-min FLAT_TRADE exit** (self-defeating)

### Actual State of Neural Predictions

| Metric | NEURAL_BULLISH | NEURAL_BEARISH |
|--------|----------------|----------------|
| Trades | 81 | 6 |
| Total P&L | +$11.53 | -$4.79 |
| Avg P&L/Trade | **+$0.14** | **-$0.80** |
| Win Rate | 53.1% | 33.3% |

Neural predictions provide **marginal directional edge at best** (~$0.14/trade for bullish, negative for bearish).

### Implications

1. **Don't trust +269% baseline** - it was luck, not skill
2. **Neural predictions need improvement** - not just threshold fixes
3. **FLAT_TRADE exit strategy defeats predictions** - trades close before direction plays out
4. **Architecture comparisons were invalid** - comparing HMM luck, not NN performance
5. **Focus areas**: Exit strategy, conviction signals, letting winners run

### Status
âœ… **ROOT CAUSE IDENTIFIED** - No signal inversion bug, baseline was statistical fluke

## Phase 53: HMM Alignment Gate Fix & Architecture Retest (2026-01-07)

### Key Discovery

The **HMM Alignment Gate (Gate 4)** was blocking GOOD signals, not inverting them!

### Hypothesis vs Reality

| Hypothesis | Test Result | Verdict |
|------------|-------------|---------|
| Model is anti-predictive (33% WR â†’ 67% contrarian) | Contrarian: 28% WR | **DISPROVEN** |
| Skip HMM gate will improve | Normal: 43.8% WR | **CONFIRMED** |

### Test Results

**Contrarian vs Normal (with HMM gate skipped):**

| Test | Win Rate | P&L | Trades |
|------|----------|-----|--------|
| Normal (SKIP_HMM_ALIGNMENT=1) | **43.8%** | -0.05% | 64 |
| Contrarian (INVERT_NEURAL_SIGNAL=1) | 28.0% | -1.40% | 50 |

**The model IS slightly predictive** - trading WITH predictions beats trading AGAINST!

### Architecture Comparison (with SKIP_HMM_ALIGNMENT=1)

| Architecture | P&L | Win Rate | Trades | Per-Trade P&L |
|--------------|-----|----------|--------|---------------|
| **Transformer** | **+8.72%** | 31.2% | 47 | **+$9.27** |
| **TCN** | +7.72% | **43.1%** | 64 | +$6.03 |
| LSTM | -1.44% | 37.0% | 81 | -$0.89 |

### Key Findings

1. **Transformer wins on P&L** (+8.72%) despite LOWEST win rate (31.2%)
   - Has bigger winners that offset more losses
   - Per-trade P&L: +$9.27 (best)

2. **TCN wins on consistency** (43.1% WR)
   - Most consistent win rate
   - Second-best per-trade P&L: +$6.03

3. **LSTM is worst** with HMM gate skipped
   - More trades (81) but losing money
   - Previous LSTM success was due to HMM gate filtering

### Root Cause Analysis

The HMM Alignment Gate (Gate 4 in unified_rl_policy.py) requires:
- Bullish prediction + Bullish HMM â†’ Trade allowed
- Bearish prediction + Bearish HMM â†’ Trade allowed
- **Any disagreement â†’ Trade BLOCKED**

This was too restrictive - the neural network had legitimate edge even when disagreeing with HMM.

### Fix Implemented

New environment variable `SKIP_HMM_ALIGNMENT=1`:
- Bypasses Gate 4 alignment check
- Allows neural predictions to trade freely
- Results: 43.8% WR (up from ~33%)

### Recommended Configuration

```bash
# Best architecture (Transformer) with HMM gate skipped
SKIP_HMM_ALIGNMENT=1 TEMPORAL_ENCODER=transformer python scripts/train_time_travel.py

# Alternative: TCN for consistency
SKIP_HMM_ALIGNMENT=1 TEMPORAL_ENCODER=tcn python scripts/train_time_travel.py
```

### Implications

1. **Previous architecture tests were invalid** - all affected by HMM gate
2. **Transformer is now best** (was LSTM in previous tests due to HMM filtering)
3. **Contrarian trading does NOT work** - 28% WR proves model is predictive
4. **SKIP_HMM_ALIGNMENT should be default** for neural-based trading
